{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: mps\n"
     ]
    }
   ],
   "source": [
    "# 设定设备\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Device being used: {device}\")\n",
    "\n",
    "# 文件路径\n",
    "data_path = \"../data/processed/test_data.csv\"\n",
    "model_path = \"../src/model/best_model_batch_2.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: (20, 6)\n",
      "       PMID                                      Text_combined  \\\n",
      "0  27798626  Stabilizing mutations of KLHL24 ubiquitin liga...   \n",
      "1  20015111  GGA autoinhibition revisited. The cytosolic ad...   \n",
      "2   2068106  Bacterial chemotaxis signaling complexes: form...   \n",
      "3  14722083  Comparative analyses of the three-dimensional ...   \n",
      "4  23449916  Biochemical analysis of three putative KaiC cl...   \n",
      "\n",
      "                 Terms  \n",
      "0   autoubiquitination  \n",
      "1       autoinhibition  \n",
      "2  autophosphorylation  \n",
      "3  autophosphorylation  \n",
      "4  autophosphorylation  \n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Test dataset size: {df.shape}\")\n",
    "\n",
    "# 打印样本数据\n",
    "print(df[['PMID', 'Text_combined', 'Terms']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Labels (15 fixed): ['non-autoregulatory', 'autophosphorylation', 'autocatalytic', 'autoregulation', 'autoubiquitination', 'autoinhibition', 'autoregulatory', 'autoinducer', 'autolysis', 'autoinhibitory', 'autoactivation', 'autocatalysis', 'autofeedback', 'autoinduction', 'autokinase']\n",
      "Number of labels in model: 15\n"
     ]
    }
   ],
   "source": [
    "# 固定标签顺序，与模型训练时保持一致\n",
    "model_labels = [\n",
    "    \"non-autoregulatory\", \"autophosphorylation\", \"autocatalytic\", \"autoregulation\",\n",
    "    \"autoubiquitination\", \"autoinhibition\", \"autoregulatory\", \"autoinducer\",\n",
    "    \"autolysis\", \"autoinhibitory\", \"autoactivation\", \"autocatalysis\",\n",
    "    \"autofeedback\", \"autoinduction\", \"autokinase\"\n",
    "]\n",
    "\n",
    "print(f\"Model Labels (15 fixed): {model_labels}\")\n",
    "print(f\"Number of labels in model: {len(model_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1h/csb8qjzj1sv0jtrd6ccllm8c0000gn/T/ipykernel_88450/1024552187.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded to mps.\n"
     ]
    }
   ],
   "source": [
    "# 设备映射：优先加载到 CPU，然后再转移到 MPS\n",
    "map_location = \"cpu\"\n",
    "\n",
    "try:\n",
    "    # 加载模型权重到 CPU\n",
    "    state_dict = torch.load(model_path, map_location=map_location)\n",
    "\n",
    "    # 初始化模型，输出层大小固定为 15\n",
    "    model = PubMedBERTClassifier(n_classes=15)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # 将模型转移到 MPS\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"Model successfully loaded to {device}.\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext')\n",
    "\n",
    "def preprocess_text(text, tokenizer, max_length=512):\n",
    "    \"\"\"\n",
    "    预处理输入文本\n",
    "    \"\"\"\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID: 27798626 | Actual Label: autoubiquitination | Predicted Labels: []\n",
      "PMID: 20015111 | Actual Label: autoinhibition | Predicted Labels: ['autoregulatory']\n",
      "PMID: 2068106 | Actual Label: autophosphorylation | Predicted Labels: []\n",
      "PMID: 14722083 | Actual Label: autophosphorylation | Predicted Labels: []\n",
      "PMID: 23449916 | Actual Label: autophosphorylation | Predicted Labels: []\n",
      "PMID: 20519438 | Actual Label: autoinhibition | Predicted Labels: ['autoregulatory']\n",
      "PMID: 22216903 | Actual Label: autophosphorylation | Predicted Labels: ['autophosphorylation']\n",
      "PMID: 9856465 | Actual Label: autoregulatory | Predicted Labels: []\n",
      "PMID: 7871721 | Actual Label: autocatalytic | Predicted Labels: ['autocatalytic']\n",
      "PMID: 19812038 | Actual Label: autophosphorylation | Predicted Labels: []\n",
      "PMID: 11889109 | Actual Label: nan | Predicted Labels: []\n",
      "PMID: 19690332 | Actual Label: nan | Predicted Labels: []\n",
      "PMID: 15815621 | Actual Label: nan | Predicted Labels: []\n",
      "PMID: 12384590 | Actual Label: nan | Predicted Labels: []\n",
      "PMID: 23757397 | Actual Label: nan | Predicted Labels: []\n",
      "PMID: 27862469 | Actual Label: nan | Predicted Labels: []\n",
      "PMID: 16878126 | Actual Label: nan | Predicted Labels: []\n",
      "PMID: 23696453 | Actual Label: nan | Predicted Labels: []\n",
      "PMID: 18522941 | Actual Label: nan | Predicted Labels: []\n",
      "PMID: 16914037 | Actual Label: nan | Predicted Labels: []\n"
     ]
    }
   ],
   "source": [
    "# 设置阈值\n",
    "threshold = 0.5\n",
    "\n",
    "# 从数据集中获取实际出现的标签\n",
    "actual_labels_set = df['Terms'].dropna().unique().tolist()\n",
    "actual_labels_set.insert(0, \"non-autoregulatory\")\n",
    "actual_labels_set = sorted(set(actual_labels_set))\n",
    "\n",
    "\n",
    "# 逐行进行预测\n",
    "for idx, row in df.iterrows():\n",
    "    # 使用 Text_combined 列进行预测\n",
    "    text = str(row['Text_combined'])\n",
    "    actual_label = row['Terms']\n",
    "    \n",
    "    # 预处理\n",
    "    encoding = preprocess_text(text, tokenizer)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # 模型预测\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        probabilities = torch.sigmoid(outputs).squeeze().cpu().numpy()\n",
    "\n",
    "    # 检查形状匹配性\n",
    "    if len(probabilities) != len(model_labels):\n",
    "        print(f\"Shape mismatch: Probabilities length = {len(probabilities)}, Label names length = {len(model_labels)}\")\n",
    "        continue\n",
    "\n",
    "    # 映射回标签（仅输出实际出现的标签）\n",
    "    predicted_labels = [\n",
    "        model_labels[i] for i, prob in enumerate(probabilities)\n",
    "        if prob >= threshold and model_labels[i] in actual_labels_set\n",
    "    ]\n",
    "    \n",
    "    # 打印预测结果\n",
    "    print(f\"PMID: {row['PMID']} | Actual Label: {actual_label} | Predicted Labels: {predicted_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoregulatory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
