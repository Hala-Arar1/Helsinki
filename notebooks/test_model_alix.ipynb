{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fiatlux/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# initialize nltk stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Device being used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1h/csb8qjzj1sv0jtrd6ccllm8c0000gn/T/ipykernel_43444/2514190708.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Terms_List'] = df_cleaned['Terms'].apply(lambda x: [term.strip() for term in x.split(',')])\n",
      "/var/folders/1h/csb8qjzj1sv0jtrd6ccllm8c0000gn/T/ipykernel_43444/2514190708.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Terms_List'] = df_cleaned['Terms_List'].apply(lambda x: list(set(x)))\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/processed/train_data.csv\"\n",
    "test_path = \"../data/processed/test_data.csv\"\n",
    "model_dir = \"../src/model/\"\n",
    "\n",
    "# data preprocessing\n",
    "df = pd.read_csv(data_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "    text = \" \".join([word.strip() for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "if 'Text_Cleaned' not in df:\n",
    "    df['Text_Cleaned'] = df['Text_combined'].apply(clean_text)\n",
    "\n",
    "df['Terms'] = df['Terms'].fillna('non-autoregulatory')\n",
    "\n",
    "columns_to_keep = ['batch_number', 'Text_Cleaned', 'Terms']\n",
    "df_cleaned = df[columns_to_keep]\n",
    "\n",
    "df_cleaned['Terms_List'] = df_cleaned['Terms'].apply(lambda x: [term.strip() for term in x.split(',')])\n",
    "df_cleaned['Terms_List'] = df_cleaned['Terms_List'].apply(lambda x: list(set(x)))\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(df_cleaned['Terms_List'])\n",
    "label_columns = mlb.classes_\n",
    "\n",
    "df_test['Text_Cleaned'] = df_test['Text_combined'].apply(clean_text)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubMedBERTClassifier(torch.nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(PubMedBERTClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext')\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_thresholds(model_path, thresholds_path):\n",
    "    model = PubMedBERTClassifier(n_classes=len(label_columns))\n",
    "    state_dict = torch.load(model_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    if os.path.exists(thresholds_path):\n",
    "        with open(thresholds_path, \"r\") as f:\n",
    "            thresholds = json.load(f)\n",
    "    else:\n",
    "        thresholds = [0.5] * len(label_columns)\n",
    "\n",
    "    return model, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, df, tokenizer, thresholds):\n",
    "    predictions = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        text = str(row['Text_Cleaned']).strip()\n",
    "        encoding = preprocess_text(text, tokenizer)\n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            probabilities = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "\n",
    "        predicted_labels = [label_columns[i] for i in range(len(label_columns)) if probabilities[i] >= thresholds[i]]\n",
    "        if not predicted_labels:\n",
    "            predicted_labels = [\"non-autoregulatory\"]\n",
    "\n",
    "        predictions.append(\", \".join(sorted(predicted_labels)))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>if_contain_keyterm</th>\n",
       "      <th>Terms</th>\n",
       "      <th>Text_combined</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2G2U4</td>\n",
       "      <td>17827301</td>\n",
       "      <td>New insights into the WalK/WalR (YycG/YycF) es...</td>\n",
       "      <td>The highly conserved WalK/WalR (also known as ...</td>\n",
       "      <td>0</td>\n",
       "      <td>autolysis</td>\n",
       "      <td>New insights into the WalK/WalR (YycG/YycF) es...</td>\n",
       "      <td>new insights walkwalr yycgyycf essential signa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P00520</td>\n",
       "      <td>20072125</td>\n",
       "      <td>Targeting Bcr-Abl by combining allosteric with...</td>\n",
       "      <td>In an effort to find new pharmacological modal...</td>\n",
       "      <td>0</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>Targeting Bcr-Abl by combining allosteric with...</td>\n",
       "      <td>targeting bcrabl combining allosteric atpbindi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q8RXD3</td>\n",
       "      <td>15998807</td>\n",
       "      <td>The AIP2 E3 ligase acts as a novel negative re...</td>\n",
       "      <td>The phytohormone abscisic acid (ABA) mediates ...</td>\n",
       "      <td>0</td>\n",
       "      <td>autoubiquitination</td>\n",
       "      <td>The AIP2 E3 ligase acts as a novel negative re...</td>\n",
       "      <td>aip e ligase acts novel negative regulator aba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0FLN1</td>\n",
       "      <td>18281398</td>\n",
       "      <td>Isolation and characterization of an autoinduc...</td>\n",
       "      <td>The opportunistic human pathogen Acinetobacter...</td>\n",
       "      <td>0</td>\n",
       "      <td>autoinduction</td>\n",
       "      <td>Isolation and characterization of an autoinduc...</td>\n",
       "      <td>isolation characterization autoinducer synthas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P00519</td>\n",
       "      <td>16543148</td>\n",
       "      <td>Organization of the SH3-SH2 unit in active and...</td>\n",
       "      <td>The tyrosine kinase c-Abl is inactivated by in...</td>\n",
       "      <td>0</td>\n",
       "      <td>autoinhibition</td>\n",
       "      <td>Organization of the SH3-SH2 unit in active and...</td>\n",
       "      <td>organization shsh unit active inactive forms c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AC      PMID                                              Title  \\\n",
       "0  Q2G2U4  17827301  New insights into the WalK/WalR (YycG/YycF) es...   \n",
       "1  P00520  20072125  Targeting Bcr-Abl by combining allosteric with...   \n",
       "2  Q8RXD3  15998807  The AIP2 E3 ligase acts as a novel negative re...   \n",
       "3  B0FLN1  18281398  Isolation and characterization of an autoinduc...   \n",
       "4  P00519  16543148  Organization of the SH3-SH2 unit in active and...   \n",
       "\n",
       "                                            Abstract  if_contain_keyterm  \\\n",
       "0  The highly conserved WalK/WalR (also known as ...                   0   \n",
       "1  In an effort to find new pharmacological modal...                   0   \n",
       "2  The phytohormone abscisic acid (ABA) mediates ...                   0   \n",
       "3  The opportunistic human pathogen Acinetobacter...                   0   \n",
       "4  The tyrosine kinase c-Abl is inactivated by in...                   0   \n",
       "\n",
       "                 Terms                                      Text_combined  \\\n",
       "0            autolysis  New insights into the WalK/WalR (YycG/YycF) es...   \n",
       "1  autophosphorylation  Targeting Bcr-Abl by combining allosteric with...   \n",
       "2   autoubiquitination  The AIP2 E3 ligase acts as a novel negative re...   \n",
       "3        autoinduction  Isolation and characterization of an autoinduc...   \n",
       "4       autoinhibition  Organization of the SH3-SH2 unit in active and...   \n",
       "\n",
       "                                        Text_Cleaned  \n",
       "0  new insights walkwalr yycgyycf essential signa...  \n",
       "1  targeting bcrabl combining allosteric atpbindi...  \n",
       "2  aip e ligase acts novel negative regulator aba...  \n",
       "3  isolation characterization autoinducer synthas...  \n",
       "4  organization shsh unit active inactive forms c...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize results df\n",
    "results_df = pd.DataFrame()\n",
    "results_df[['AC', 'PMID', 'Actual Terms']] = df_test[['AC', 'PMID', 'Terms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1h/csb8qjzj1sv0jtrd6ccllm8c0000gn/T/ipykernel_43444/1758071081.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PubMedBERTClassifier:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([15, 768]) from checkpoint, the shape in current model is torch.Size([11, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([15]) from checkpoint, the shape in current model is torch.Size([11]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model_batch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m thresholds_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_thresholds_batch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m model, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_and_thresholds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresholds_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m pred_column_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPred Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m results_df[pred_column_name] \u001b[38;5;241m=\u001b[39m predict(model, df_test, tokenizer, thresholds)\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mload_model_and_thresholds\u001b[0;34m(model_path, thresholds_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m PubMedBERTClassifier(n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(label_columns))\n\u001b[1;32m      3\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/miniforge3/envs/autoregulatory/lib/python3.10/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PubMedBERTClassifier:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([15, 768]) from checkpoint, the shape in current model is torch.Size([11, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([15]) from checkpoint, the shape in current model is torch.Size([11])."
     ]
    }
   ],
   "source": [
    "# predict\n",
    "for i in range(1, 5):\n",
    "    model_path = os.path.join(model_dir, f\"best_model_batch_{i}.pt\")\n",
    "    thresholds_path = os.path.join(model_dir, f\"best_thresholds_batch_{i}.json\")\n",
    "\n",
    "    model, thresholds = load_model_and_thresholds(model_path, thresholds_path)\n",
    "    pred_column_name = f\"Pred Batch {i}\"\n",
    "    results_df[pred_column_name] = predict(model, df_test, tokenizer, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Actual Terms</th>\n",
       "      <th>Pred Batch 1</th>\n",
       "      <th>Pred Batch 2</th>\n",
       "      <th>Pred Batch 3</th>\n",
       "      <th>Pred Batch 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q6TFL4</td>\n",
       "      <td>27798626</td>\n",
       "      <td>autoubiquitination</td>\n",
       "      <td>autoubiquitination</td>\n",
       "      <td>autoubiquitination</td>\n",
       "      <td>autoubiquitination</td>\n",
       "      <td>autoubiquitination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q92673</td>\n",
       "      <td>20015111</td>\n",
       "      <td>autoinhibition</td>\n",
       "      <td>autoinhibition, autoinhibitory</td>\n",
       "      <td>autoinhibition, autoinhibitory</td>\n",
       "      <td>autoinhibition, autoinhibitory</td>\n",
       "      <td>autoinhibition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0A964</td>\n",
       "      <td>2068106</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autokinase, autophosphorylation</td>\n",
       "      <td>autocatalysis, autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q13557</td>\n",
       "      <td>14722083</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P74646</td>\n",
       "      <td>23449916</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q9JK25</td>\n",
       "      <td>20519438</td>\n",
       "      <td>autoinhibition</td>\n",
       "      <td>autoinhibition, autoinhibitory</td>\n",
       "      <td>autoinhibition, autoinhibitory</td>\n",
       "      <td>autoinhibition</td>\n",
       "      <td>autoinhibition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O00418</td>\n",
       "      <td>22216903</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q9R1X4</td>\n",
       "      <td>9856465</td>\n",
       "      <td>autoregulatory</td>\n",
       "      <td>autoregulation, autoregulatory</td>\n",
       "      <td>autoregulatory</td>\n",
       "      <td>autoregulatory</td>\n",
       "      <td>autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q65652</td>\n",
       "      <td>7871721</td>\n",
       "      <td>autocatalytic</td>\n",
       "      <td>autocatalysis, autocatalytic</td>\n",
       "      <td>autocatalytic</td>\n",
       "      <td>autocatalytic</td>\n",
       "      <td>autocatalytic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>O14965</td>\n",
       "      <td>19812038</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>autophosphorylation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Q8RG52</td>\n",
       "      <td>11889109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Q9ULD2</td>\n",
       "      <td>19690332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P35968</td>\n",
       "      <td>15815621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Q7UC29</td>\n",
       "      <td>12384590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C1K5M2</td>\n",
       "      <td>23757397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P57751</td>\n",
       "      <td>27862469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Q0VND7</td>\n",
       "      <td>16878126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P52788</td>\n",
       "      <td>23696453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Q86DU6</td>\n",
       "      <td>18522941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Q0SNQ5</td>\n",
       "      <td>16914037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AC      PMID         Actual Terms                     Pred Batch 1  \\\n",
       "0   Q6TFL4  27798626   autoubiquitination               autoubiquitination   \n",
       "1   Q92673  20015111       autoinhibition   autoinhibition, autoinhibitory   \n",
       "2   P0A964   2068106  autophosphorylation  autokinase, autophosphorylation   \n",
       "3   Q13557  14722083  autophosphorylation              autophosphorylation   \n",
       "4   P74646  23449916  autophosphorylation              autophosphorylation   \n",
       "5   Q9JK25  20519438       autoinhibition   autoinhibition, autoinhibitory   \n",
       "6   O00418  22216903  autophosphorylation              autophosphorylation   \n",
       "7   Q9R1X4   9856465       autoregulatory   autoregulation, autoregulatory   \n",
       "8   Q65652   7871721        autocatalytic     autocatalysis, autocatalytic   \n",
       "9   O14965  19812038  autophosphorylation              autophosphorylation   \n",
       "10  Q8RG52  11889109                  NaN               non-autoregulatory   \n",
       "11  Q9ULD2  19690332                  NaN               non-autoregulatory   \n",
       "12  P35968  15815621                  NaN               non-autoregulatory   \n",
       "13  Q7UC29  12384590                  NaN               non-autoregulatory   \n",
       "14  C1K5M2  23757397                  NaN               non-autoregulatory   \n",
       "15  P57751  27862469                  NaN               non-autoregulatory   \n",
       "16  Q0VND7  16878126                  NaN               non-autoregulatory   \n",
       "17  P52788  23696453                  NaN               non-autoregulatory   \n",
       "18  Q86DU6  18522941                  NaN               non-autoregulatory   \n",
       "19  Q0SNQ5  16914037                  NaN               non-autoregulatory   \n",
       "\n",
       "                          Pred Batch 2                    Pred Batch 3  \\\n",
       "0                   autoubiquitination              autoubiquitination   \n",
       "1       autoinhibition, autoinhibitory  autoinhibition, autoinhibitory   \n",
       "2   autocatalysis, autophosphorylation             autophosphorylation   \n",
       "3                  autophosphorylation             autophosphorylation   \n",
       "4                  autophosphorylation             autophosphorylation   \n",
       "5       autoinhibition, autoinhibitory                  autoinhibition   \n",
       "6                  autophosphorylation             autophosphorylation   \n",
       "7                       autoregulatory                  autoregulatory   \n",
       "8                        autocatalytic                   autocatalytic   \n",
       "9                  autophosphorylation             autophosphorylation   \n",
       "10                  non-autoregulatory              non-autoregulatory   \n",
       "11                  non-autoregulatory              non-autoregulatory   \n",
       "12                  non-autoregulatory              non-autoregulatory   \n",
       "13                  non-autoregulatory              non-autoregulatory   \n",
       "14                  non-autoregulatory              non-autoregulatory   \n",
       "15                  non-autoregulatory              non-autoregulatory   \n",
       "16                  non-autoregulatory              non-autoregulatory   \n",
       "17                  non-autoregulatory              non-autoregulatory   \n",
       "18                  non-autoregulatory              non-autoregulatory   \n",
       "19                  non-autoregulatory              non-autoregulatory   \n",
       "\n",
       "           Pred Batch 4  \n",
       "0    autoubiquitination  \n",
       "1        autoinhibition  \n",
       "2   autophosphorylation  \n",
       "3   autophosphorylation  \n",
       "4   autophosphorylation  \n",
       "5        autoinhibition  \n",
       "6   autophosphorylation  \n",
       "7        autoregulatory  \n",
       "8         autocatalytic  \n",
       "9   autophosphorylation  \n",
       "10   non-autoregulatory  \n",
       "11   non-autoregulatory  \n",
       "12   non-autoregulatory  \n",
       "13   non-autoregulatory  \n",
       "14   non-autoregulatory  \n",
       "15   non-autoregulatory  \n",
       "16   non-autoregulatory  \n",
       "17   non-autoregulatory  \n",
       "18   non-autoregulatory  \n",
       "19   non-autoregulatory  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Batch | Micro-F1 | Macro-F1 | Weighted-F1 | Samples-F1 | Sample-Precision | Sample-Recall |\n",
    "|-------|----------|----------|-------------|------------|------------------|---------------|\n",
    "|   1   |  0.8573  |  0.5921  |    0.9067   |   0.8808   |      0.8608      |     0.9290    |\n",
    "|   2   |  0.9047  |  0.6748  |    0.9306   |   0.9215   |      0.9105      |     0.9471    |\n",
    "|   3   |  0.9355  |  0.8356  |    0.9417   |   0.9381   |      0.9342      |     0.9477    |\n",
    "|   4   |  0.9550  |  0.8430  |    0.9605   |   0.9613   |      0.9581      |     0.9692    |\n",
    "|   5   |----------|----------|-------------|------------|------------------|---------------|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoregulatory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
