{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46fcac3",
   "metadata": {},
   "source": [
    "# PubMed BERT Model + Attention Mechanism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "19186769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os, random, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "617f1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "49a7a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    torch.device(\"mps\")\n",
    "    if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cuda\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3723fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "learning_rate = 5e-6  # Smaller learning rate for PubMedBERT\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d2812e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories for saving models and results\n",
    "MODEL_DIR = \"model\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)  # Create the base model directory\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485aa656",
   "metadata": {},
   "source": [
    "## 1. Read in Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5ef715f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26235, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Terms</th>\n",
       "      <th>Text_combined</th>\n",
       "      <th>batch_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q0TPM5</td>\n",
       "      <td>16825665</td>\n",
       "      <td>Skewed genomic variability in strains of the t...</td>\n",
       "      <td>Clostridium perfringens is a Gram-positive, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Skewed genomic variability in strains of the t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q06904</td>\n",
       "      <td>16882723</td>\n",
       "      <td>A KaiC-associating SasA-RpaA two-component reg...</td>\n",
       "      <td>KaiA, KaiB, and KaiC clock proteins from cyano...</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>A KaiC-associating SasA-RpaA two-component reg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q9MTL7</td>\n",
       "      <td>10852478</td>\n",
       "      <td>Complete nucleotide sequence of the Oenothera ...</td>\n",
       "      <td>We describe the 159,443-bp [corrected] sequenc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Complete nucleotide sequence of the Oenothera ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9ZAH5</td>\n",
       "      <td>9756984</td>\n",
       "      <td>Sequence of the putative alanine racemase oper...</td>\n",
       "      <td>A gene cluster comprising the alanine racemase...</td>\n",
       "      <td>autolysis</td>\n",
       "      <td>Sequence of the putative alanine racemase oper...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P48308</td>\n",
       "      <td>7509368</td>\n",
       "      <td>Sequence and structural analysis of murine ade...</td>\n",
       "      <td>The genomic region encoding the major capsid p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sequence and structural analysis of murine ade...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AC      PMID                                              Title  \\\n",
       "0  Q0TPM5  16825665  Skewed genomic variability in strains of the t...   \n",
       "1  Q06904  16882723  A KaiC-associating SasA-RpaA two-component reg...   \n",
       "2  Q9MTL7  10852478  Complete nucleotide sequence of the Oenothera ...   \n",
       "3  Q9ZAH5   9756984  Sequence of the putative alanine racemase oper...   \n",
       "4  P48308   7509368  Sequence and structural analysis of murine ade...   \n",
       "\n",
       "                                            Abstract                Terms  \\\n",
       "0  Clostridium perfringens is a Gram-positive, an...                  NaN   \n",
       "1  KaiA, KaiB, and KaiC clock proteins from cyano...  autophosphorylation   \n",
       "2  We describe the 159,443-bp [corrected] sequenc...                  NaN   \n",
       "3  A gene cluster comprising the alanine racemase...            autolysis   \n",
       "4  The genomic region encoding the major capsid p...                  NaN   \n",
       "\n",
       "                                       Text_combined  batch_number  \n",
       "0  Skewed genomic variability in strains of the t...             1  \n",
       "1  A KaiC-associating SasA-RpaA two-component reg...             1  \n",
       "2  Complete nucleotide sequence of the Oenothera ...             1  \n",
       "3  Sequence of the putative alanine racemase oper...             1  \n",
       "4  Sequence and structural analysis of murine ade...             1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/processed/train_data.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea4f48e",
   "metadata": {},
   "source": [
    "## 2. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c11d8441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Terms</th>\n",
       "      <th>Text_combined</th>\n",
       "      <th>batch_number</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q0TPM5</td>\n",
       "      <td>16825665</td>\n",
       "      <td>Skewed genomic variability in strains of the t...</td>\n",
       "      <td>Clostridium perfringens is a Gram-positive, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Skewed genomic variability in strains of the t...</td>\n",
       "      <td>1</td>\n",
       "      <td>skewed genomic variability strains toxigenic b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q06904</td>\n",
       "      <td>16882723</td>\n",
       "      <td>A KaiC-associating SasA-RpaA two-component reg...</td>\n",
       "      <td>KaiA, KaiB, and KaiC clock proteins from cyano...</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>A KaiC-associating SasA-RpaA two-component reg...</td>\n",
       "      <td>1</td>\n",
       "      <td>kaic-associating sasa-rpaa two-component regul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q9MTL7</td>\n",
       "      <td>10852478</td>\n",
       "      <td>Complete nucleotide sequence of the Oenothera ...</td>\n",
       "      <td>We describe the 159,443-bp [corrected] sequenc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Complete nucleotide sequence of the Oenothera ...</td>\n",
       "      <td>1</td>\n",
       "      <td>complete nucleotide sequence oenothera elata p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9ZAH5</td>\n",
       "      <td>9756984</td>\n",
       "      <td>Sequence of the putative alanine racemase oper...</td>\n",
       "      <td>A gene cluster comprising the alanine racemase...</td>\n",
       "      <td>autolysis</td>\n",
       "      <td>Sequence of the putative alanine racemase oper...</td>\n",
       "      <td>1</td>\n",
       "      <td>sequence putative alanine racemase operon stap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P48308</td>\n",
       "      <td>7509368</td>\n",
       "      <td>Sequence and structural analysis of murine ade...</td>\n",
       "      <td>The genomic region encoding the major capsid p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sequence and structural analysis of murine ade...</td>\n",
       "      <td>1</td>\n",
       "      <td>sequence structural analysis murine adenovirus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26230</th>\n",
       "      <td>G0FS62</td>\n",
       "      <td>11278540</td>\n",
       "      <td>Mutational analysis and reconstituted expressi...</td>\n",
       "      <td>To investigate a novel branch of the shikimate...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mutational analysis and reconstituted expressi...</td>\n",
       "      <td>5</td>\n",
       "      <td>mutational analysis reconstituted expression b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26231</th>\n",
       "      <td>P40957</td>\n",
       "      <td>10837255</td>\n",
       "      <td>Complex formation between Mad1p, Bub1p and Bub...</td>\n",
       "      <td>The spindle checkpoint delays the metaphase to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Complex formation between Mad1p, Bub1p and Bub...</td>\n",
       "      <td>5</td>\n",
       "      <td>complex formation mad1p bub1p bub3p crucial sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26232</th>\n",
       "      <td>Q15303</td>\n",
       "      <td>10867024</td>\n",
       "      <td>Ligand discrimination in signaling through an ...</td>\n",
       "      <td>The epidermal growth factor (EGF)-like family ...</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>Ligand discrimination in signaling through an ...</td>\n",
       "      <td>5</td>\n",
       "      <td>ligand discrimination signaling erbb4 receptor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26233</th>\n",
       "      <td>Q96RL1</td>\n",
       "      <td>23186163</td>\n",
       "      <td>Toward a comprehensive characterization of a h...</td>\n",
       "      <td>Mass spectrometry (MS)-based phosphoproteomics...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toward a comprehensive characterization of a h...</td>\n",
       "      <td>5</td>\n",
       "      <td>toward comprehensive characterization human ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26234</th>\n",
       "      <td>A0RX10</td>\n",
       "      <td>17114289</td>\n",
       "      <td>Genomic analysis of the uncultivated marine cr...</td>\n",
       "      <td>Crenarchaeota are ubiquitous and abundant micr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Genomic analysis of the uncultivated marine cr...</td>\n",
       "      <td>5</td>\n",
       "      <td>genomic analysis uncultivated marine crenarcha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26235 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AC      PMID                                              Title  \\\n",
       "0      Q0TPM5  16825665  Skewed genomic variability in strains of the t...   \n",
       "1      Q06904  16882723  A KaiC-associating SasA-RpaA two-component reg...   \n",
       "2      Q9MTL7  10852478  Complete nucleotide sequence of the Oenothera ...   \n",
       "3      Q9ZAH5   9756984  Sequence of the putative alanine racemase oper...   \n",
       "4      P48308   7509368  Sequence and structural analysis of murine ade...   \n",
       "...       ...       ...                                                ...   \n",
       "26230  G0FS62  11278540  Mutational analysis and reconstituted expressi...   \n",
       "26231  P40957  10837255  Complex formation between Mad1p, Bub1p and Bub...   \n",
       "26232  Q15303  10867024  Ligand discrimination in signaling through an ...   \n",
       "26233  Q96RL1  23186163  Toward a comprehensive characterization of a h...   \n",
       "26234  A0RX10  17114289  Genomic analysis of the uncultivated marine cr...   \n",
       "\n",
       "                                                Abstract                Terms  \\\n",
       "0      Clostridium perfringens is a Gram-positive, an...                  NaN   \n",
       "1      KaiA, KaiB, and KaiC clock proteins from cyano...  autophosphorylation   \n",
       "2      We describe the 159,443-bp [corrected] sequenc...                  NaN   \n",
       "3      A gene cluster comprising the alanine racemase...            autolysis   \n",
       "4      The genomic region encoding the major capsid p...                  NaN   \n",
       "...                                                  ...                  ...   \n",
       "26230  To investigate a novel branch of the shikimate...                  NaN   \n",
       "26231  The spindle checkpoint delays the metaphase to...                  NaN   \n",
       "26232  The epidermal growth factor (EGF)-like family ...  autophosphorylation   \n",
       "26233  Mass spectrometry (MS)-based phosphoproteomics...                  NaN   \n",
       "26234  Crenarchaeota are ubiquitous and abundant micr...                  NaN   \n",
       "\n",
       "                                           Text_combined  batch_number  \\\n",
       "0      Skewed genomic variability in strains of the t...             1   \n",
       "1      A KaiC-associating SasA-RpaA two-component reg...             1   \n",
       "2      Complete nucleotide sequence of the Oenothera ...             1   \n",
       "3      Sequence of the putative alanine racemase oper...             1   \n",
       "4      Sequence and structural analysis of murine ade...             1   \n",
       "...                                                  ...           ...   \n",
       "26230  Mutational analysis and reconstituted expressi...             5   \n",
       "26231  Complex formation between Mad1p, Bub1p and Bub...             5   \n",
       "26232  Ligand discrimination in signaling through an ...             5   \n",
       "26233  Toward a comprehensive characterization of a h...             5   \n",
       "26234  Genomic analysis of the uncultivated marine cr...             5   \n",
       "\n",
       "                                            Text_Cleaned  \n",
       "0      skewed genomic variability strains toxigenic b...  \n",
       "1      kaic-associating sasa-rpaa two-component regul...  \n",
       "2      complete nucleotide sequence oenothera elata p...  \n",
       "3      sequence putative alanine racemase operon stap...  \n",
       "4      sequence structural analysis murine adenovirus...  \n",
       "...                                                  ...  \n",
       "26230  mutational analysis reconstituted expression b...  \n",
       "26231  complex formation mad1p bub1p bub3p crucial sp...  \n",
       "26232  ligand discrimination signaling erbb4 receptor...  \n",
       "26233  toward comprehensive characterization human ca...  \n",
       "26234  genomic analysis uncultivated marine crenarcha...  \n",
       "\n",
       "[26235 rows x 8 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Standardized text preprocessing function for all models\n",
    "    \"\"\"\n",
    "    # Handle NaN values\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    # Keep hyphens as they may be important in biomedical terms\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "    # Keep numbers that might be part of important terms\n",
    "    text = \" \".join([word.strip() for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "print(\"Cleaning text...\")\n",
    "df['Text_Cleaned'] = df['Text_combined'].apply(preprocess_text)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f3d5b818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarizing labels...\n",
      "Found 10 unique labels: ['autoactivation' 'autocatalysis' 'autofeedback' 'autoinduction'\n",
      " 'autoinhibition' 'autokinase' 'autolysis' 'autophosphorylation'\n",
      " 'autoregulation' 'autoubiquitination']\n",
      "Final cleaned data shape: (26235, 12)\n"
     ]
    }
   ],
   "source": [
    "# Binarize the Terms column\n",
    "print(\"Binarizing labels...\")\n",
    "df['Terms_List'] = df['Terms'].apply(\n",
    "    lambda x: [term.strip() for term in str(x).split(',')] if pd.notna(x) and x != '' else []\n",
    ")\n",
    "\n",
    "# Initialize and fit the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "binary_labels = mlb.fit_transform(df['Terms_List'])\n",
    "\n",
    "# Get the class names\n",
    "label_columns = mlb.classes_\n",
    "print(f\"Found {len(label_columns)} unique labels: {label_columns}\")\n",
    "\n",
    "# Create a DataFrame with the binary labels\n",
    "labels_df = pd.DataFrame(binary_labels, columns=label_columns)\n",
    "\n",
    "# Save label columns for later use\n",
    "with open('label_columns.json', 'w') as f:\n",
    "    json.dump(list(label_columns), f)\n",
    "\n",
    "# Keep only essential columns\n",
    "df_cleaned = df[['batch_number', 'Text_Cleaned']].copy()\n",
    "df_cleaned = pd.concat([df_cleaned, labels_df], axis=1)\n",
    "\n",
    "print(f\"Final cleaned data shape: {df_cleaned.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4ac85503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26235, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_number</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>autoactivation</th>\n",
       "      <th>autocatalysis</th>\n",
       "      <th>autofeedback</th>\n",
       "      <th>autoinduction</th>\n",
       "      <th>autoinhibition</th>\n",
       "      <th>autokinase</th>\n",
       "      <th>autolysis</th>\n",
       "      <th>autophosphorylation</th>\n",
       "      <th>autoregulation</th>\n",
       "      <th>autoubiquitination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>skewed genomic variability strains toxigenic b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>kaic-associating sasa-rpaa two-component regul...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>complete nucleotide sequence oenothera elata p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sequence putative alanine racemase operon stap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>sequence structural analysis murine adenovirus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_number                                       Text_Cleaned  \\\n",
       "0             1  skewed genomic variability strains toxigenic b...   \n",
       "1             1  kaic-associating sasa-rpaa two-component regul...   \n",
       "2             1  complete nucleotide sequence oenothera elata p...   \n",
       "3             1  sequence putative alanine racemase operon stap...   \n",
       "4             1  sequence structural analysis murine adenovirus...   \n",
       "\n",
       "   autoactivation  autocatalysis  autofeedback  autoinduction  autoinhibition  \\\n",
       "0               0              0             0              0               0   \n",
       "1               0              0             0              0               0   \n",
       "2               0              0             0              0               0   \n",
       "3               0              0             0              0               0   \n",
       "4               0              0             0              0               0   \n",
       "\n",
       "   autokinase  autolysis  autophosphorylation  autoregulation  \\\n",
       "0           0          0                    0               0   \n",
       "1           0          0                    1               0   \n",
       "2           0          0                    0               0   \n",
       "3           0          1                    0               0   \n",
       "4           0          0                    0               0   \n",
       "\n",
       "   autoubiquitination  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_cleaned.shape)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5a6b4",
   "metadata": {},
   "source": [
    "## 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6db7b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Instantiate the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a8d8eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Dataset and DataLoader classes\n",
    "class PubMedDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.FloatTensor(label)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "85862f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined loss function with more BCE influence\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, pos_weights, gamma=0.5, alpha=0.8):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.pos_weights = pos_weights\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # Higher alpha = more weight on BCE\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # Weighted BCE loss\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(\n",
    "            inputs, targets, pos_weight=self.pos_weights, reduction='none'\n",
    "        )\n",
    "        \n",
    "        # Focal component (lighter weight)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_component = (1 - pt) ** self.gamma * BCE_loss\n",
    "        \n",
    "        # Combine both losses (80% BCE, 20% Focal)\n",
    "        combined = self.alpha * BCE_loss + (1 - self.alpha) * focal_component\n",
    "        \n",
    "        return combined.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "05fd9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "def create_dataset_and_loader(X, y, batch_size, tokenizer, train=True):\n",
    "    dataset = PubMedDataset(X, y, tokenizer)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=train)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "331fc11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Training and Evaluation Functions\n",
    "def train_epoch(model, data_loader, optimizer, criterion, scheduler=None):\n",
    "    \"\"\"\n",
    "    Train the model for a single epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model to train\n",
    "        data_loader: DataLoader containing the training data\n",
    "        optimizer: Optimizer for updating model weights\n",
    "        criterion: Loss function\n",
    "        scheduler: Optional learning rate scheduler\n",
    "        \n",
    "    Returns:\n",
    "        Average loss value for the epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_batches = 0\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        try:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Check for NaN loss\n",
    "            if torch.isnan(loss):\n",
    "                print(\"WARNING: NaN loss detected, skipping batch\")\n",
    "                continue\n",
    "                \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch processing: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Protect against division by zero\n",
    "    if total_batches == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    return total_loss / total_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "53478a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_thresholds(model, val_loader, n_labels):\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Optimizing thresholds\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            \n",
    "            all_outputs.append(probs)\n",
    "            all_labels.append(labels.numpy())\n",
    "    \n",
    "    all_outputs = np.vstack(all_outputs)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    optimal_thresholds = []\n",
    "    \n",
    "    for i in range(n_labels):\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in np.arange(0.3, 0.7, 0.05):\n",
    "            preds = (all_outputs[:, i] >= threshold).astype(int)\n",
    "            f1 = f1_score(all_labels[:, i], preds, zero_division=0)\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        optimal_thresholds.append(best_threshold)\n",
    "        \n",
    "    return optimal_thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9b5a4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, data_loader, criterion, thresholds):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "            \n",
    "            # Apply thresholds per label\n",
    "            predictions = np.array([\n",
    "                (probabilities[:, i] >= thresholds[i]).astype(int) for i in range(len(thresholds))\n",
    "            ]).T\n",
    "\n",
    "            all_predictions.extend(predictions)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    if all_predictions and all_labels:\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_labels = np.array(all_labels)\n",
    "    else:\n",
    "        return {'loss': float('inf')} \n",
    "\n",
    "    # Samples metrics\n",
    "    samples_precision = precision_score(all_labels, all_predictions, average='samples', zero_division=0)\n",
    "    samples_recall = recall_score(all_labels, all_predictions, average='samples', zero_division=0)\n",
    "    samples_f1 = f1_score(all_labels, all_predictions, average='samples', zero_division=0)\n",
    "\n",
    "    # F1 metrics\n",
    "    micro_f1 = f1_score(all_labels, all_predictions, average='micro', zero_division=0)\n",
    "    macro_f1 = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "    weighted_f1 = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    # Average loss\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    metrics = {\n",
    "        'loss': avg_loss,\n",
    "        'micro_f1': micro_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'weighted_f1': weighted_f1,\n",
    "        'samples_f1': samples_f1,\n",
    "        'samples_precision': samples_precision,\n",
    "        'samples_recall': samples_recall\n",
    "    }\n",
    "    \n",
    "    # Output results\n",
    "    print(f\"Loss: {avg_loss:.4f} | Micro F1: {micro_f1:.4f} | Macro F1: {macro_f1:.4f} | Weighted F1: {weighted_f1:.4f} | Samples F1: {samples_f1:.4f}\")\n",
    "    print(f\"Samples Precision: {samples_precision:.4f} | Samples Recall: {samples_recall:.4f}\")\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0ae18c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_moderate_sampler(y):\n",
    "    \"\"\"\n",
    "    Create a weighted sampler with moderate class balancing\n",
    "    \"\"\"\n",
    "    class_sample_count = np.sum(y, axis=0)\n",
    "    # Square root scaling makes weights less extreme\n",
    "    weight_per_class = 1.0 / np.sqrt(np.clip(class_sample_count, 5, np.inf))\n",
    "    \n",
    "    sample_weights = np.zeros(len(y))\n",
    "    for i in range(len(y)):\n",
    "        if np.sum(y[i]) > 0:\n",
    "            positive_indices = np.where(y[i] == 1)[0]\n",
    "            sample_weights[i] = np.mean(weight_per_class[positive_indices])\n",
    "        else:\n",
    "            # Give negative examples lower weight (they're 67% of dataset)\n",
    "            sample_weights[i] = 0.5 / max(1, (len(y) - np.sum(np.any(y, axis=1))))\n",
    "    \n",
    "    sample_weights = torch.FloatTensor(sample_weights)\n",
    "    return WeightedRandomSampler(sample_weights, len(sample_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ade5531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedPubMedBERTClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, dropout1=0.1, dropout2=0.2):\n",
    "        super(ImprovedPubMedBERTClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.intermediate = nn.Linear(self.bert.config.hidden_size, 512)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        self.classifier = nn.Linear(512, n_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.xavier_normal_(self.intermediate.weight)\n",
    "        nn.init.zeros_(self.intermediate.bias)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        pooled_output = self.dropout1(pooled_output)\n",
    "        intermediate = self.intermediate(pooled_output)\n",
    "        intermediate = self.activation(intermediate)\n",
    "        intermediate = self.dropout2(intermediate)\n",
    "        logits = self.classifier(intermediate)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8184dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 8: Main Training Function\n",
    "def train_model(batch_number, n_epochs, learning_rate, batch_size, use_optimal_thresholds=True):\n",
    "    print(f\"\\nTraining model on batch {batch_number}\")\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = pd.read_csv('../data/processed/test_data.csv')\n",
    "    \n",
    "    # Apply same preprocessing to test data\n",
    "    test_data['Text_Cleaned'] = test_data['Text_combined'].apply(preprocess_text)\n",
    "    \n",
    "    # Need to binarize test data labels\n",
    "    test_data['Terms_List'] = test_data['Terms'].apply(\n",
    "        lambda x: [term.strip() for term in str(x).split(',')] if pd.notna(x) and x != '' else []\n",
    "    )\n",
    "    test_labels = mlb.transform(test_data['Terms_List'])  # Use same mlb as training\n",
    "    \n",
    "    # Filter training data for the specified batch\n",
    "    batch_data = df_cleaned[df_cleaned['batch_number'] == batch_number].copy()\n",
    "    if len(batch_data) == 0:\n",
    "        print(f\"No data found for batch {batch_number}\")\n",
    "        return None, 0\n",
    "        \n",
    "    # Prepare features and labels\n",
    "    X_train = batch_data['Text_Cleaned']\n",
    "    y_train = batch_data[label_columns].values\n",
    "    \n",
    "    X_test = test_data['Text_Cleaned']\n",
    "    y_test = test_labels\n",
    "    \n",
    "    print(f\"Train set: {len(X_train)} samples, Test set: {len(X_test)} samples\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    # Create dataset\n",
    "    train_dataset = PubMedDataset(X_train, y_train, tokenizer)\n",
    "\n",
    "    # Create balanced sampler\n",
    "    sampler = create_moderate_sampler(y_train)\n",
    "\n",
    "    # Create data loader with sampler\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "    test_loader = create_dataset_and_loader(X_test, y_test, batch_size, tokenizer, train=False)\n",
    "    \n",
    "    # Calculate class weights for loss function\n",
    "    pos_weights = []\n",
    "    for i in range(y_train.shape[1]):\n",
    "        neg_count = len(y_train) - np.sum(y_train[:, i])\n",
    "        pos_count = np.sum(y_train[:, i])\n",
    "        weight = neg_count / pos_count if pos_count > 0 else 1.0\n",
    "        weight = min(max(weight, 0.1), 10.0)  # Clip between 0.1 and 10\n",
    "        pos_weights.append(weight)\n",
    "    \n",
    "    pos_weights = torch.FloatTensor(pos_weights).to(device)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ImprovedPubMedBERTClassifier(n_classes=len(label_columns)).to(device)\n",
    "    \n",
    "    # Set up loss, optimizer, and scheduler\n",
    "    \n",
    "    criterion = CombinedLoss(pos_weights, gamma=0.5, alpha=0.8)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    # Set up scheduler with warmup\n",
    "    total_steps = len(train_loader) * n_epochs\n",
    "    warmup_steps = int(total_steps * 0.1)  # 10% warmup\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Initial thresholds\n",
    "    initial_thresholds = [0.5] * len(label_columns)\n",
    "    \n",
    "    # Training loop\n",
    "    best_f1 = 0.0\n",
    "    all_metrics = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'micro_f1': [],\n",
    "        'macro_f1': [],\n",
    "        'weighted_f1': [],\n",
    "        'samples_f1': [],\n",
    "        'samples_precision': [],\n",
    "        'samples_recall': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, scheduler)\n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        all_metrics['train_loss'].append(train_loss)\n",
    "        \n",
    "        # Optimize thresholds after first epoch\n",
    "        thresholds = initial_thresholds\n",
    "        if use_optimal_thresholds and epoch >= 1:\n",
    "            try:\n",
    "                print(\"Optimizing thresholds...\")\n",
    "                thresholds = optimize_thresholds(model, test_loader, len(label_columns))\n",
    "                print(f\"Optimized Thresholds: {[f'{t:.2f}' for t in thresholds]}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error optimizing thresholds: {e}\")\n",
    "                print(\"Using default thresholds\")\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = evaluate(model, test_loader, criterion, thresholds)\n",
    "        \n",
    "        # Store metrics\n",
    "        for k, v in metrics.items():\n",
    "            key = 'test_loss' if k == 'loss' else k\n",
    "            if key in all_metrics:\n",
    "                all_metrics[key].append(v)\n",
    "        \n",
    "        # Check if this is the best model\n",
    "        current_f1 = metrics['samples_f1']\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            \n",
    "            # Create model directory\n",
    "            model_dir = f\"model/batch_{batch_number}\"\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            \n",
    "            # Save model\n",
    "            model_path = os.path.join(model_dir, \"best_model.pt\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"New best model saved to {model_path}\")\n",
    "            \n",
    "            # Save thresholds\n",
    "            thresholds_path = f\"{model_dir}/best_thresholds.json\"\n",
    "            with open(thresholds_path, \"w\") as f:\n",
    "                json.dump(thresholds, f)\n",
    "            print(f\"Thresholds saved to {thresholds_path}\")\n",
    "    \n",
    "    # Save metrics\n",
    "    metrics_path = f\"results/metrics_batch_{batch_number}.json\"\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(all_metrics, f)\n",
    "    \n",
    "    return model, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aad9763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1394fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Inference Class\n",
    "class PubMedBERTInference:\n",
    "    def __init__(self, model_path, thresholds_path, label_columns_path):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Load label columns\n",
    "        with open(label_columns_path, 'r') as f:\n",
    "            self.label_columns = json.load(f)\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = ImprovedPubMedBERTClassifier(n_classes=len(self.label_columns))\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Load thresholds\n",
    "        with open(thresholds_path, 'r') as f:\n",
    "            self.thresholds = json.load(f)\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        return preprocess_text(text)\n",
    "    \n",
    "    def predict(self, text):\n",
    "        processed_text = self.preprocess(text)\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            processed_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(self.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids, attention_mask)\n",
    "            probabilities = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "        \n",
    "        # Apply thresholds and get predicted labels\n",
    "        predictions = {}\n",
    "        for i, label in enumerate(self.label_columns):\n",
    "            if probabilities[i] >= self.thresholds[i]:\n",
    "                predictions[label] = float(probabilities[i])\n",
    "        \n",
    "        return {\n",
    "        'predictions': predictions,\n",
    "        'top_3': {self.label_columns[i]: float(probabilities[i]) \n",
    "                  for i in np.argsort(probabilities)[::-1][:3]},\n",
    "        'attended_tokens': []  # Empty for original model\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "36281281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model on batch 1\n",
      "Train set: 5247 samples, Test set: 20 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1312/1312 [47:32<00:00,  2.17s/it, loss=0.2257] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7706 | Micro F1: 0.7000 | Macro F1: 0.4689 | Weighted F1: 0.6922 | Samples F1: 0.6167\n",
      "Samples Precision: 0.7000 | Samples Recall: 0.5750\n",
      "New best model saved to model/batch_1/best_model.pt\n",
      "Thresholds saved to model/batch_1/best_thresholds.json\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1312/1312 [47:14<00:00,  2.16s/it, loss=0.0057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0795\n",
      "Optimizing thresholds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing thresholds: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Thresholds: ['0.50', '0.30', '0.50', '0.30', '0.30', '0.50', '0.50', '0.30', '0.30', '0.30']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9311 | Micro F1: 0.7179 | Macro F1: 0.4707 | Weighted F1: 0.6786 | Samples F1: 0.6167\n",
      "Samples Precision: 0.7000 | Samples Recall: 0.5750\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1312/1312 [47:37<00:00,  2.18s/it, loss=0.0017] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0337\n",
      "Optimizing thresholds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing thresholds: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Thresholds: ['0.50', '0.45', '0.50', '0.30', '0.30', '0.50', '0.50', '0.35', '0.50', '0.30']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3056 | Micro F1: 0.7568 | Macro F1: 0.4943 | Weighted F1: 0.7057 | Samples F1: 0.6167\n",
      "Samples Precision: 0.7000 | Samples Recall: 0.5750\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1312/1312 [46:26<00:00,  2.12s/it, loss=0.1656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0293\n",
      "Optimizing thresholds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing thresholds: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Thresholds: ['0.50', '0.60', '0.50', '0.30', '0.30', '0.50', '0.50', '0.30', '0.30', '0.30']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0258 | Micro F1: 0.7895 | Macro F1: 0.5029 | Weighted F1: 0.7429 | Samples F1: 0.6333\n",
      "Samples Precision: 0.7000 | Samples Recall: 0.6000\n",
      "New best model saved to model/batch_1/best_model.pt\n",
      "Thresholds saved to model/batch_1/best_thresholds.json\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1312/1312 [47:22<00:00,  2.17s/it, loss=0.0322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0223\n",
      "Optimizing thresholds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing thresholds: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Thresholds: ['0.50', '0.55', '0.50', '0.30', '0.30', '0.50', '0.50', '0.60', '0.40', '0.30']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9668 | Micro F1: 0.8000 | Macro F1: 0.5133 | Weighted F1: 0.7367 | Samples F1: 0.6167\n",
      "Samples Precision: 0.7000 | Samples Recall: 0.5750\n",
      "Batch 1 training complete. Best F1 score: 0.6333\n",
      "\n",
      "Training model on batch 2\n",
      "Train set: 5247 samples, Test set: 20 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1312/1312 [48:17<00:00,  2.21s/it, loss=0.0302] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.25it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train models for all batches\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_num \u001b[38;5;129;01min\u001b[39;00m batch_numbers:\n\u001b[0;32m----> 6\u001b[0m     model, f1_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_optimal_thresholds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m training complete. Best F1 score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[127], line 109\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(batch_number, n_epochs, learning_rate, batch_size, use_optimal_thresholds)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing default thresholds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresholds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Store metrics\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[124], line 36\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader, criterion, thresholds)\u001b[0m\n\u001b[1;32m     34\u001b[0m samples_precision \u001b[38;5;241m=\u001b[39m precision_score(all_labels, all_predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     35\u001b[0m samples_recall \u001b[38;5;241m=\u001b[39m recall_score(all_labels, all_predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m samples_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msamples\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# F1 metrics\u001b[39;00m\n\u001b[1;32m     39\u001b[0m micro_f1 \u001b[38;5;241m=\u001b[39m f1_score(all_labels, all_predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get all unique batch numbers\n",
    "batch_numbers = df_cleaned['batch_number'].unique()\n",
    "\n",
    "# Train models for all batches\n",
    "for batch_num in batch_numbers:\n",
    "    model, f1_score = train_model(\n",
    "        batch_number=batch_num,\n",
    "        n_epochs=n_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        use_optimal_thresholds=True\n",
    "    )\n",
    "    print(f\"Batch {batch_num} training complete. Best F1 score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these analysis functions\n",
    "def analyze_class_performance(model, test_loader, label_columns, thresholds):\n",
    "    \"\"\"Analyze per-class performance of the model\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            if isinstance(outputs, tuple):  # Handle enhanced model\n",
    "                outputs = outputs[0]\n",
    "                \n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            preds = (probs >= np.array(thresholds)).astype(int)\n",
    "            \n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    print(\"\\nPER-CLASS METRICS:\")\n",
    "    print(f\"{'Class':<20} {'Precision':<10} {'Recall':<10} {'F1':<10} {'Support':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, cls in enumerate(label_columns):\n",
    "        # Calculate metrics\n",
    "        if np.sum(all_labels[:, i]) > 0:  # Skip classes with no positive samples\n",
    "            precision = precision_score(all_labels[:, i], all_preds[:, i], zero_division=0)\n",
    "            recall = recall_score(all_labels[:, i], all_preds[:, i], zero_division=0)\n",
    "            f1 = f1_score(all_labels[:, i], all_preds[:, i], zero_division=0)\n",
    "            support = np.sum(all_labels[:, i])\n",
    "            \n",
    "            print(f\"{cls:<20} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {support:<10}\")\n",
    "        else:\n",
    "            print(f\"{cls:<20} {'N/A':<10} {'N/A':<10} {'N/A':<10} {0:<10}\")\n",
    "    \n",
    "    return all_preds, all_labels\n",
    "\n",
    "def plot_multilabel_confusion(all_preds, all_labels, label_columns):\n",
    "    \"\"\"Plot confusion-like information for multi-label data\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Create a matrix of co-occurrences between predictions and true labels\n",
    "    n_classes = len(label_columns)\n",
    "    confusion = np.zeros((n_classes, 2, 2))  # Class x [TN, FP, FN, TP]\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        # True Positives\n",
    "        confusion[i, 1, 1] = np.sum((all_preds[:, i] == 1) & (all_labels[:, i] == 1))\n",
    "        # False Positives\n",
    "        confusion[i, 1, 0] = np.sum((all_preds[:, i] == 1) & (all_labels[:, i] == 0))\n",
    "        # False Negatives\n",
    "        confusion[i, 0, 1] = np.sum((all_preds[:, i] == 0) & (all_labels[:, i] == 1))\n",
    "        # True Negatives\n",
    "        confusion[i, 0, 0] = np.sum((all_preds[:, i] == 0) & (all_labels[:, i] == 0))\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(2, 5, figsize=(18, 8))\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for i, cls in enumerate(label_columns):\n",
    "        sns.heatmap(confusion[i], annot=True, fmt='.0f', cmap='Blues', \n",
    "                   xticklabels=['Neg', 'Pos'], yticklabels=['Neg', 'Pos'], ax=ax[i])\n",
    "        ax[i].set_title(f'{cls}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_errors(model, tokenizer, examples, label_columns, thresholds):\n",
    "    \"\"\"Analyze specific examples where the model makes errors\"\"\"\n",
    "    model.eval()\n",
    "    results = []\n",
    "    \n",
    "    for text in examples:\n",
    "        # Preprocess\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            input_ids = encoding['input_ids'].to(device)\n",
    "            attention_mask = encoding['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            if isinstance(outputs, tuple):  # Handle enhanced model\n",
    "                outputs, attention = outputs\n",
    "                attention = attention.squeeze().cpu().numpy()\n",
    "            else:\n",
    "                attention = None\n",
    "                \n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "            preds = (probs >= np.array(thresholds)).astype(int)\n",
    "        \n",
    "        # Get predictions and attended tokens\n",
    "        predictions = {}\n",
    "        for i, (label, prob, pred) in enumerate(zip(label_columns, probs, preds)):\n",
    "            if pred == 1:\n",
    "                predictions[label] = float(prob)\n",
    "        \n",
    "        # Get top tokens if attention is available\n",
    "        attended_tokens = []\n",
    "        if attention is not None:\n",
    "            tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "            for i in range(1, min(len(tokens)-1, len(attention))):\n",
    "                if attention[i] > 0.05:  # Significant attention\n",
    "                    attended_tokens.append((tokens[i], float(attention[i])))\n",
    "            \n",
    "            attended_tokens.sort(key=lambda x: x[1], reverse=True)\n",
    "            attended_tokens = attended_tokens[:5]  # Top 5\n",
    "        \n",
    "        results.append({\n",
    "            'text': text,\n",
    "            'predictions': predictions,\n",
    "            'probabilities': {label: float(prob) for label, prob in zip(label_columns, probs)},\n",
    "            'attended_tokens': attended_tokens\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea420f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this code after your training loop completes for a batch\n",
    "# (e.g., right before you move to the next batch in your batch_numbers loop)\n",
    "\n",
    "def run_model_analysis(model, batch_number):\n",
    "    \"\"\"Run comprehensive analysis on trained model\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ANALYZING MODEL FOR BATCH {batch_number}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = pd.read_csv('../data/processed/test_data.csv')\n",
    "    test_data['Text_Cleaned'] = test_data['Text_combined'].apply(preprocess_text)\n",
    "    test_data['Terms_List'] = test_data['Terms'].apply(\n",
    "        lambda x: [term.strip() for term in str(x).split(',')] if pd.notna(x) and x != '' else []\n",
    "    )\n",
    "    test_labels = mlb.transform(test_data['Terms_List'])\n",
    "    \n",
    "    # Create test loader\n",
    "    X_test = test_data['Text_Cleaned']\n",
    "    y_test = test_labels\n",
    "    test_loader = create_dataset_and_loader(X_test, y_test, batch_size=8, tokenizer=tokenizer, train=False)\n",
    "    \n",
    "    # Load thresholds\n",
    "    try:\n",
    "        with open(os.path.join(MODEL_DIR, f\"batch_{batch_number}\", \"best_thresholds.json\"), 'r') as f:\n",
    "            thresholds = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Thresholds file not found. Using default threshold of 0.5\")\n",
    "        thresholds = [0.5] * len(label_columns)\n",
    "    \n",
    "    # Run class performance analysis\n",
    "    print(\"Analyzing per-class performance...\")\n",
    "    all_preds, all_labels = analyze_class_performance(model, test_loader, label_columns, thresholds)\n",
    "    \n",
    "    # Plot confusion matrices\n",
    "    print(\"\\nGenerating confusion matrices...\")\n",
    "    plot_multilabel_confusion(all_preds, all_labels, label_columns)\n",
    "    \n",
    "    # Analyze specific challenging examples\n",
    "    print(\"\\nAnalyzing challenging examples...\")\n",
    "    challenging_examples = [\n",
    "        \"The protein binds to its own regulatory region, creating a feedback loop.\",\n",
    "        \"The enzyme can activate additional copies of itself through phosphorylation.\",\n",
    "        \"Upon binding the ligand, the receptor undergoes a conformational change that enables signaling.\",\n",
    "        \"The kinase domain transfers phosphate groups to residues within the protein structure.\"\n",
    "    ]\n",
    "    error_analysis = analyze_errors(model, tokenizer, challenging_examples, label_columns, thresholds)\n",
    "    \n",
    "    # Print results for challenging examples\n",
    "    for i, result in enumerate(error_analysis):\n",
    "        print(f\"\\nExample {i+1}: \\\"{result['text']}\\\"\")\n",
    "        print(\"  Predictions:\")\n",
    "        if result['predictions']:\n",
    "            for label, prob in sorted(result['predictions'].items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"    - {label}: {prob:.4f}\")\n",
    "        else:\n",
    "            print(\"    No classes above threshold\")\n",
    "        \n",
    "        if result['attended_tokens']:\n",
    "            print(\"  Top attended tokens:\")\n",
    "            for token, weight in result['attended_tokens']:\n",
    "                print(f\"    - {token}: {weight:.4f}\")\n",
    "    \n",
    "    return all_preds, all_labels, error_analysis\n",
    "\n",
    "# Add this line right after your training loop for a batch completes\n",
    "# (after you get the model and f1_score from train_model)\n",
    "all_preds, all_labels, error_analysis = run_model_analysis(model, batch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ce48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EnhancedPubMedBERTClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, dropout1=0.1, dropout2=0.2):\n",
    "        super(EnhancedPubMedBERTClassifier, self).__init__()\n",
    "        # Load base PubMedBERT\n",
    "        self.bert = AutoModel.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "        \n",
    "        # Add relation attention mechanism\n",
    "        self.relation_query = nn.Parameter(torch.randn(768, 1))\n",
    "        self.relation_key = nn.Linear(768, 768)\n",
    "        self.relation_value = nn.Linear(768, 768)\n",
    "        \n",
    "        # Main classification path\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.intermediate = nn.Linear(768 * 2, 512)  # Doubled for concatenation\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        self.classifier = nn.Linear(512, n_classes)\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        nn.init.xavier_normal_(self.intermediate.weight)\n",
    "        nn.init.zeros_(self.intermediate.bias)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get PubMedBERT embeddings\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Get sequence outputs\n",
    "        sequence_output = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "        cls_token = sequence_output[:, 0, :]  # [batch_size, hidden_size]\n",
    "        \n",
    "        # Apply relation attention\n",
    "        attention_mask_expanded = attention_mask.unsqueeze(-1)  # [batch_size, seq_len, 1]\n",
    "        \n",
    "        # Calculate relation-aware attention weights\n",
    "        relation_keys = self.relation_key(sequence_output)  # [batch_size, seq_len, hidden_size]\n",
    "        query = self.relation_query.unsqueeze(0).expand(input_ids.size(0), -1, -1)  # [batch_size, hidden_size, 1]\n",
    "        \n",
    "        # Get attention scores and mask padding tokens\n",
    "        attention_scores = torch.bmm(relation_keys, query)  # [batch_size, seq_len, 1]\n",
    "        attention_scores = attention_scores.masked_fill(attention_mask_expanded == 0, -10000.0)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)  # [batch_size, seq_len, 1]\n",
    "        \n",
    "        # Get relation-aware context vector\n",
    "        relation_values = self.relation_value(sequence_output)  # [batch_size, seq_len, hidden_size]\n",
    "        relation_context = torch.sum(attention_weights * relation_values, dim=1)  # [batch_size, hidden_size]\n",
    "        \n",
    "        # Combine CLS token with relation context\n",
    "        pooled_output = torch.cat([cls_token, relation_context], dim=1)  # [batch_size, hidden_size*2]\n",
    "        pooled_output = self.dropout1(pooled_output)\n",
    "        \n",
    "        # Classification\n",
    "        intermediate = self.intermediate(pooled_output)\n",
    "        intermediate = self.activation(intermediate)\n",
    "        intermediate = self.dropout2(intermediate)\n",
    "        logits = self.classifier(intermediate)\n",
    "        \n",
    "        return logits, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Functions for Enhanced Model\n",
    "def convert_to_enhanced_model(original_model_path):\n",
    "    \"\"\"\n",
    "    Load the existing model and convert it to the enhanced model\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load label columns\n",
    "    try:\n",
    "        with open('label_columns.json', 'r') as f:\n",
    "            label_columns = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Label columns file not found. Using default labels.\")\n",
    "        label_columns = [\n",
    "            'autoactivation', 'autocatalysis', 'autofeedback', 'autoinduction', \n",
    "            'autoinhibition', 'autokinase', 'autolysis', 'autophosphorylation', \n",
    "            'autoregulation', 'autoubiquitination'\n",
    "        ]\n",
    "    \n",
    "    # Load original model\n",
    "    original_model = ImprovedPubMedBERTClassifier(n_classes=len(label_columns)).to(device)\n",
    "    original_model.load_state_dict(torch.load(original_model_path, map_location=device))\n",
    "    print(\"Original model loaded successfully!\")\n",
    "    \n",
    "    # Create enhanced model\n",
    "    enhanced_model = EnhancedPubMedBERTClassifier(n_classes=len(label_columns)).to(device)\n",
    "    \n",
    "    # Transfer weights from original model to enhanced model\n",
    "    # 1. BERT weights\n",
    "    enhanced_model.bert.load_state_dict(original_model.bert.state_dict())\n",
    "    \n",
    "    print(\"Enhanced model created and initialized with original PubMedBERT weights!\")\n",
    "    return enhanced_model, device, label_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579aa8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_for_implicit_relations(model, batch_size=4, learning_rate=1e-5, epochs=3):\n",
    "    \"\"\"\n",
    "    Fine-tune the model to detect implicit relations using augmented examples\n",
    "    \"\"\"\n",
    "    # Set up tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    \n",
    "    # Create examples that paraphrase autoregulatory mechanisms without using \"auto\" terms\n",
    "    implicit_examples = [\n",
    "        # Text describing autoregulation without \"auto\" terms\n",
    "        (\"The transcription factor binds to its own promoter region.\", \"autoregulation\"),\n",
    "        (\"The enzyme activates itself through conformational change.\", \"autoactivation\"),\n",
    "        (\"The protein phosphorylates itself on a tyrosine residue.\", \"autophosphorylation\"),\n",
    "        (\"The protease cleaves itself to generate the active form.\", \"autocatalysis\"),\n",
    "        (\"The cell produces molecules that signal itself to change behavior.\", \"autoinduction\"),\n",
    "        (\"The receptor signals to reduce its own expression level.\", \"autoinhibition\"),\n",
    "        # More challenging and diverse examples\n",
    "        (\"Upon binding ligand, the receptor undergoes a conformational change that enables phosphorylation of its cytoplasmic domain.\", \"autophosphorylation\"),\n",
    "        (\"The transcription factor negatively controls expression of its own gene.\", \"autoregulation\"),\n",
    "        (\"The kinase domain transfers phosphate groups to residues within the same protein.\", \"autophosphorylation\"),\n",
    "        (\"This bacterial system uses cell-to-cell signaling to coordinate population behavior.\", \"autoinduction\"),\n",
    "        (\"The peptide recognizes and binds specifically to the same protein it was derived from.\", \"autofeedback\"),\n",
    "        (\"The dimeric protein activates by cross-phosphorylation between the two identical subunits.\", \"autoactivation\"),\n",
    "        # New examples\n",
    "        (\"AGPCRs uniquely contain large, self-proteolyzing extracellular regions that range from hundreds to thousands of residues in length.\", \"autocatalysis\"),\n",
    "        (\"GAIN domain-mediated self-cleavage is constitutive and produces two-fragment holoreceptors that remain bound at the cell surface.\", \"autocatalysis\"),\n",
    "        (\"GPR114 was found to be expressed in an eosinophilic-like cancer cell line (EoL-1 cells) and endogenous GPR114 was efficiently self-cleaved.\", \"autocatalysis\"),\n",
    "        (\"All this suggests that human eL29 regulates its own synthesis via a feedback mechanism by binding to the cognate mRNA, preventing its translation.\", \"autoregulation\"),\n",
    "        (\"Here, we examine the influence of nucleotides, nucleotide analogs, peptides, and unfolded proteins on the self-association properties of this protein.\", \"autoregulation\"),\n",
    "        (\"We also show that the PEDV N protein functions by recruiting the E3 ubiquitin ligase COP1 and suppressing COP1 self-ubiquitination and protein degradation, thereby augmenting COP1-mediated degradation of p53.\", \"autoubiquitination\"),\n",
    "        (\"In this study, we demonstrate that the self-repression function of IbpA is conserved in other Î³-proteobacterial IbpAs.\", \"autoinhibition\"),\n",
    "        (\"Moreover, we show a cationic residue-rich region in the Î±-crystallin domain of IbpA, which is not conserved in IbpB, is critical for the self-suppression activity.\", \"autoinhibition\"),\n",
    "        (\"RTK feedback regulation is also important for human disease research; for example, germline mutations in genes that encode RTK signaling pathway components cause numerous human congenital syndromes.\", \"autoregulation\"),\n",
    "        (\"We propose a negative feedback loop, in which sphingosine inhibits GBA2 activity in Gaucher cells, preventing further sphingosine accumulation and, thereby, cytotoxicity.\", \"autoinhibition\"),\n",
    "        (\"In this study, we show that DNA damage-induced activation of p53 initiates a negative-feedback loop which rapidly downregulates RAG1 levels.\", \"autoregulation\")\n",
    "    ]\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    class ImplicitRelationDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, examples, tokenizer, max_length=512):\n",
    "            self.examples = examples\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "            \n",
    "            # Map labels to indices\n",
    "            self.label_map = {\n",
    "                'autoactivation': 0,\n",
    "                'autocatalysis': 1,\n",
    "                'autofeedback': 2,\n",
    "                'autoinduction': 3,\n",
    "                'autoinhibition': 4,\n",
    "                'autokinase': 5,\n",
    "                'autolysis': 6,\n",
    "                'autophosphorylation': 7,\n",
    "                'autoregulation': 8,\n",
    "                'autoubiquitination': 9\n",
    "            }\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.examples)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            text, label = self.examples[idx]\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # Create one-hot encoded label\n",
    "            label_index = self.label_map[label]\n",
    "            label_tensor = torch.zeros(len(self.label_map))\n",
    "            label_tensor[label_index] = 1.0\n",
    "            \n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                'labels': label_tensor\n",
    "            }\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = ImplicitRelationDataset(implicit_examples, tokenizer)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Set up optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            # Get batch data\n",
    "            input_ids = batch['input_ids'].to(model.bert.device)\n",
    "            attention_mask = batch['attention_mask'].to(model.bert.device)\n",
    "            labels = batch['labels'].to(model.bert.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            logits, attention_weights = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(dataloader):.4f}\")\n",
    "    \n",
    "    print(\"Fine-tuning complete!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39abcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention(model, text, tokenizer):\n",
    "    \"\"\"\n",
    "    Visualize which parts of the text the model attends to for relation detection\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    # ADD error handling for text that's too long:\n",
    "    if len(text) > 512:\n",
    "        print(\"Warning: Text is too long and will be truncated for visualization\")\n",
    "        text = text[:512]\n",
    "    # Tokenize the text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoding['input_ids'].to(model.bert.device)\n",
    "    attention_mask = encoding['attention_mask'].to(model.bert.device)\n",
    "    \n",
    "    # Get tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    \n",
    "    # Forward pass to get attention weights\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, attention_weights = model(input_ids, attention_mask)\n",
    "    \n",
    "    # Convert attention weights to numpy\n",
    "    attention_weights = attention_weights.squeeze().cpu().numpy()\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    sns.heatmap([attention_weights[1:len(tokens)-1]], \n",
    "                xticklabels=tokens[1:len(tokens)-1],\n",
    "                yticklabels=['Attention'],\n",
    "                cmap='viridis',\n",
    "                cbar_kws={'label': 'Attention Weight'})\n",
    "    plt.title(f'Relation Attention for: \"{text}\"')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find top 5 attended tokens\n",
    "    top_indices = attention_weights.argsort()[-5:][::-1]\n",
    "    top_tokens = [tokens[i+1] for i in top_indices if i+1 < len(tokens)-1]\n",
    "    print(f\"Top attended tokens: {', '.join(top_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edf253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_and_test_model(batch_number=1):\n",
    "    \"\"\"\n",
    "    Convert the original model to enhanced version, fine-tune it, and test it\n",
    "    \n",
    "    Args:\n",
    "        batch_number: The batch number to use for loading the original model\n",
    "    \"\"\"\n",
    "    # Step 1: Convert existing model to enhanced model\n",
    "    model_path = os.path.join(MODEL_DIR, f\"batch_{batch_number}\", \"best_model.pt\")\n",
    "    thresholds_path = os.path.join(MODEL_DIR, f\"batch_{batch_number}\", \"best_thresholds.json\")\n",
    "    \n",
    "    print(f\"Enhancing model from batch {batch_number}...\")\n",
    "    enhanced_model, device, label_columns = convert_to_enhanced_model(model_path)\n",
    "    \n",
    "    # Step 2: Fine-tune for implicit relations\n",
    "    enhanced_model = finetune_for_implicit_relations(enhanced_model, batch_size=4, learning_rate=1e-5, epochs=3)\n",
    "    \n",
    "    # Step 3: Load thresholds (or use defaults)\n",
    "    try:\n",
    "        with open(thresholds_path, 'r') as f:\n",
    "            thresholds = json.load(f)\n",
    "        print(\"Thresholds loaded successfully!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Thresholds file not found at {thresholds_path}. Using default threshold of 0.3.\")\n",
    "        thresholds = [0.3] * len(label_columns)  # Lower thresholds for higher sensitivity\n",
    "    \n",
    "    # Step 4: Save the enhanced model\n",
    "    enhanced_model_dir = os.path.join(MODEL_DIR, \"enhanced\")\n",
    "    os.makedirs(enhanced_model_dir, exist_ok=True)\n",
    "    enhanced_model_path = os.path.join(enhanced_model_dir, f\"enhanced_pubmedbert_model_batch_{batch_number}.pt\")\n",
    "    torch.save(enhanced_model.state_dict(), enhanced_model_path)\n",
    "    \n",
    "    # Save thresholds\n",
    "    enhanced_thresholds_path = os.path.join(enhanced_model_dir, f\"enhanced_thresholds_batch_{batch_number}.json\")\n",
    "    with open(enhanced_thresholds_path, 'w') as f:\n",
    "        json.dump(thresholds, f)\n",
    "    \n",
    "    print(f\"Enhanced model saved to {enhanced_model_path}\")\n",
    "    print(f\"Enhanced thresholds saved to {enhanced_thresholds_path}\")\n",
    "    \n",
    "    # Step 5: Test on implicit examples\n",
    "    implicit_test_examples = [\n",
    "        \"The protein binds to its own regulatory region, creating a negative feedback loop.\",\n",
    "        \"The enzyme can activate other copies of itself, creating a cascade effect.\",\n",
    "        \"Upon binding ligand, the receptor undergoes a conformational change that enables phosphorylation of its cytoplasmic domain.\",\n",
    "        \"The kinase domain transfers phosphate groups to residues within the same protein structure.\",\n",
    "        \"The transcription factor controls expression of its own gene, maintaining homeostasis.\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize tokenizer for testing\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    \n",
    "    # Test and visualize\n",
    "    for i, text in enumerate(implicit_test_examples):\n",
    "        # Forward pass for predictions\n",
    "        enhanced_model.eval()\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits, attention_weights = enhanced_model(input_ids, attention_mask)\n",
    "            probabilities = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "        \n",
    "        # Get predictions above threshold\n",
    "        predictions = {}\n",
    "        for i, label in enumerate(label_columns):\n",
    "            if probabilities[i] >= thresholds[i]:\n",
    "                predictions[label] = float(probabilities[i])\n",
    "        \n",
    "        # Extract attention for relation understanding\n",
    "        attention = attention_weights.squeeze().cpu().numpy()\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        attended_tokens = []\n",
    "        for i in range(1, min(len(tokens)-1, len(attention))):\n",
    "            if attention[i] > 0.05:  # Threshold for significant attention\n",
    "                attended_tokens.append((tokens[i], float(attention[i])))\n",
    "        \n",
    "        attended_tokens.sort(key=lambda x: x[1], reverse=True)\n",
    "        attended_tokens = attended_tokens[:5]  # Top 5 attended tokens\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nExample: \\\"{text}\\\"\")\n",
    "        \n",
    "        if predictions:\n",
    "            print(\"  Predicted autoregulatory classes:\")\n",
    "            for label, prob in sorted(predictions.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"    - {label}: {prob:.4f}\")\n",
    "        else:\n",
    "            print(\"  No autoregulatory classes detected\")\n",
    "        \n",
    "        print(\"  Top 3 probabilities:\")\n",
    "        for label, prob in sorted(zip(label_columns, probabilities), key=lambda x: x[1], reverse=True)[:3]:\n",
    "            print(f\"    - {label}: {prob:.4f}\")\n",
    "        \n",
    "        print(\"  Top attended tokens (relation clues):\")\n",
    "        for token, weight in attended_tokens:\n",
    "            print(f\"    - {token}: {weight:.4f}\")\n",
    "    \n",
    "    # Visualize attention for a sample\n",
    "    visualize_attention(enhanced_model, implicit_test_examples[0], tokenizer)\n",
    "    \n",
    "    return enhanced_model, label_columns, thresholds\n",
    "\n",
    "# To enhance and test models for all batches\n",
    "batch_numbers = df_cleaned['batch_number'].unique()\n",
    "for batch_num in batch_numbers:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Enhancing and testing model for batch {batch_num}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    enhanced_model, label_columns, thresholds = enhance_and_test_model(batch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed40f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Enhanced Model Inference\n",
    "class EnhancedPubMedBERTInference:\n",
    "    def __init__(self, model_path, thresholds_path, label_columns_path):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Load label columns\n",
    "        with open(label_columns_path, 'r') as f:\n",
    "            self.label_columns = json.load(f)\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = EnhancedPubMedBERTClassifier(n_classes=len(self.label_columns))\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Load thresholds\n",
    "        with open(thresholds_path, 'r') as f:\n",
    "            self.thresholds = json.load(f)\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        # Handle NaN values\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text).lower()\n",
    "        # Keep hyphens as they may be important in biomedical terms\n",
    "        text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "        # Keep numbers that might be part of important terms\n",
    "        # text = re.sub(r'\\d+', '', text)\n",
    "        text = \" \".join([word.strip() for word in text.split() if word not in stop_words])\n",
    "        return text\n",
    "    \n",
    "    def predict(self, text):\n",
    "        processed_text = self.preprocess(text)\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            processed_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(self.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits, attention_weights = self.model(input_ids, attention_mask)\n",
    "            probabilities = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "        \n",
    "        # Apply thresholds and get predicted labels\n",
    "        predictions = {}\n",
    "        for i, label in enumerate(self.label_columns):\n",
    "            if probabilities[i] >= self.thresholds[i]:\n",
    "                predictions[label] = float(probabilities[i])\n",
    "        \n",
    "        # Extract attention for relation understanding\n",
    "        attention = attention_weights.squeeze().cpu().numpy()\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        attended_tokens = []\n",
    "        for i in range(1, min(len(tokens)-1, len(attention))):\n",
    "            if attention[i] > 0.05:  # Threshold for significant attention\n",
    "                attended_tokens.append((tokens[i], float(attention[i])))\n",
    "        \n",
    "        attended_tokens.sort(key=lambda x: x[1], reverse=True)\n",
    "        attended_tokens = attended_tokens[:5]  # Top 5 attended tokens\n",
    "        \n",
    "        return {\n",
    "            'predictions': predictions,\n",
    "            'top_3': {self.label_columns[i]: float(probabilities[i]) \n",
    "                     for i in np.argsort(probabilities)[::-1][:3]},\n",
    "            'attended_tokens': attended_tokens\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d980de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Set MODEL_DIR constant\n",
    "MODEL_DIR = \"model\"\n",
    "\n",
    "def load_model_and_predict(text_samples, batch_number=1, model_type=\"base\"):\n",
    "    \"\"\"\n",
    "    Load the saved model and make predictions on text samples\n",
    "    \n",
    "    Args:\n",
    "        text_samples: List of text samples to predict\n",
    "        batch_number: Batch number to use for model loading\n",
    "        model_type: Type of model to use (\"base\" or \"enhanced\")\n",
    "    \"\"\"\n",
    "    # Load label columns\n",
    "    try:\n",
    "        with open('label_columns.json', 'r') as f:\n",
    "            label_columns = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        # Fallback if file not found\n",
    "        label_columns = [\n",
    "            'autoactivation', 'autocatalysis', 'autofeedback', 'autoinduction',\n",
    "            'autoinhibition', 'autokinase', 'autolysis', 'autophosphorylation',\n",
    "            'autoregulation', 'autoubiquitination'\n",
    "        ]\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    \n",
    "    # Set model paths based on type and batch\n",
    "    if model_type == \"base\":\n",
    "        model_path = os.path.join(MODEL_DIR, f\"batch_{batch_number}\", \"best_model.pt\")\n",
    "        thresholds_path = os.path.join(MODEL_DIR, f\"batch_{batch_number}\", \"best_thresholds.json\")\n",
    "        # Initialize model - use the class defined earlier in the notebook\n",
    "        model = ImprovedPubMedBERTClassifier(n_classes=len(label_columns)).to(device)\n",
    "    else:  # enhanced\n",
    "        model_path = os.path.join(MODEL_DIR, \"enhanced\", f\"enhanced_pubmedbert_model_batch_{batch_number}.pt\")\n",
    "        thresholds_path = os.path.join(MODEL_DIR, \"enhanced\", f\"enhanced_thresholds_batch_{batch_number}.json\")\n",
    "        # Initialize model - use the class defined earlier in the notebook\n",
    "        model = EnhancedPubMedBERTClassifier(n_classes=len(label_columns)).to(device)\n",
    "    \n",
    "    # Load model weights\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(f\"Model loaded successfully from {model_path}!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Model file not found at {model_path}. Make sure you have saved the model properly.\")\n",
    "        return None\n",
    "    \n",
    "    # Load thresholds\n",
    "    try:\n",
    "        with open(thresholds_path, 'r') as f:\n",
    "            thresholds = json.load(f)\n",
    "        print(f\"Thresholds loaded successfully from {thresholds_path}!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Thresholds file not found at {thresholds_path}. Using default threshold of 0.5.\")\n",
    "        thresholds = [0.5] * len(label_columns)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess and predict for each text\n",
    "    results = []\n",
    "    \n",
    "    for text in text_samples:\n",
    "        # Tokenize\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Move to device\n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "        \n",
    "        # Predict (handle both model types)\n",
    "        with torch.no_grad():\n",
    "            if model_type == \"base\":\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                probabilities = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "                attended_tokens = []  # No attention for base model\n",
    "            else:  # enhanced\n",
    "                outputs, attention_weights = model(input_ids, attention_mask)\n",
    "                probabilities = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "                \n",
    "                # Extract attention info\n",
    "                attention = attention_weights.squeeze().cpu().numpy()\n",
    "                tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "                attended_tokens = []\n",
    "                for i in range(1, min(len(tokens)-1, len(attention))):\n",
    "                    if attention[i] > 0.05:  # Threshold for significant attention\n",
    "                        attended_tokens.append((tokens[i], float(attention[i])))\n",
    "                \n",
    "                attended_tokens.sort(key=lambda x: x[1], reverse=True)\n",
    "                attended_tokens = attended_tokens[:5]  # Top 5 attended tokens\n",
    "        \n",
    "        # Get predictions above threshold\n",
    "        predictions = {}\n",
    "        for i, label in enumerate(label_columns):\n",
    "            if probabilities[i] >= thresholds[i]:\n",
    "                predictions[label] = float(probabilities[i])\n",
    "        \n",
    "        # Get top 3 probabilities regardless of threshold\n",
    "        top_indices = np.argsort(probabilities)[::-1][:3]\n",
    "        top_3 = {label_columns[i]: float(probabilities[i]) for i in top_indices}\n",
    "        \n",
    "        # Append results in standardized format\n",
    "        results.append({\n",
    "            'text': text,\n",
    "            'predictions': predictions,\n",
    "            'top_3': top_3,\n",
    "            'attended_tokens': attended_tokens,\n",
    "            'all_probs': {label_columns[i]: float(probabilities[i]) for i in range(len(label_columns))}\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Now, let's create diverse test cases\n",
    "\n",
    "# Category 1: Obvious examples with \"auto\" terms in them\n",
    "obvious_examples = [\n",
    "    \"The receptor undergoes autophosphorylation upon ligand binding, which triggers a signaling cascade.\",\n",
    "    \"Transcription factors exhibiting autoregulation can bind to their own promoters to control expression levels.\",\n",
    "    \"The protein kinase shows autoactivation through conformational changes in its catalytic domain.\",\n",
    "    \"Bacterial quorum sensing relies on autoinducers that accumulate in the environment.\",\n",
    "    \"Apoptosis involves proteases that undergo autocatalytic activation through proteolytic cleavage.\"\n",
    "]\n",
    "\n",
    "# Category 2: Less obvious examples (no \"auto\" terms)\n",
    "less_obvious_examples = [\n",
    "    \"The transcription factor binds to its own promoter region, creating a negative feedback loop.\",\n",
    "    \"Upon phosphorylation, the enzyme can activate additional copies of itself, creating a positive feedback circuit.\",\n",
    "    \"The receptor dimerizes and cross-phosphorylates residues in the intracellular domain.\",\n",
    "    \"The repressor protein inhibits its own gene expression when concentrations exceed a threshold.\",\n",
    "    \"Bacterial cells produce signaling molecules that, when detected, stimulate further production of the same molecule.\"\n",
    "]\n",
    "\n",
    "# Category 3: Challenging cases with ambiguous regulatory mechanisms\n",
    "challenging_examples = [\n",
    "    \"The protein shows increased activity following binding to its interaction partner, which itself is regulated by the same signaling pathway.\",\n",
    "    \"Enzyme activity decreases following substrate binding, potentially through an allosteric mechanism involving the active site.\",\n",
    "    \"Regulatory T cells suppress immune responses through multiple feedback mechanisms involving cytokine signaling.\",\n",
    "    \"The gene locus contains binding sites for both activating and repressing factors that are co-expressed with the gene itself.\",\n",
    "    \"Proteolytic processing of the prohormone yields bioactive peptides that modulate receptor sensitivity.\"\n",
    "]\n",
    "\n",
    "# Category 4: Negative cases (non-autoregulatory)\n",
    "negative_examples = [\n",
    "    \"The housekeeping gene is constitutively expressed under normal cellular conditions.\",\n",
    "    \"Protein translation is initiated at the ribosome following mRNA binding.\",\n",
    "    \"Cell division requires the coordinated action of multiple cytoskeletal proteins.\",\n",
    "    \"Passive diffusion of ions occurs through the membrane channel following a concentration gradient.\",\n",
    "    \"The monoclonal antibody binds specifically to the epitope on the target antigen.\"\n",
    "]\n",
    "\n",
    "# Run prediction on both base and enhanced models\n",
    "print(\"Testing base model on obvious examples...\")\n",
    "obvious_results_base = load_model_and_predict(obvious_examples, batch_number=1, model_type=\"base\")\n",
    "\n",
    "print(\"\\nTesting enhanced model on obvious examples...\")\n",
    "obvious_results_enhanced = load_model_and_predict(obvious_examples, batch_number=1, model_type=\"enhanced\")\n",
    "\n",
    "print(\"\\nTesting base model on less obvious examples...\")\n",
    "less_obvious_results_base = load_model_and_predict(less_obvious_examples, batch_number=1, model_type=\"base\")\n",
    "\n",
    "print(\"\\nTesting enhanced model on less obvious examples...\")\n",
    "less_obvious_results_enhanced = load_model_and_predict(less_obvious_examples, batch_number=1, model_type=\"enhanced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb66237",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display results in a clear format\n",
    "def display_test_results(results, category_name, model_type):\n",
    "    print(f\"\\n=== {category_name} - {model_type.upper()} MODEL ===\\n\")\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Example {i+1}: \\\"{result['text']}\\\"\")\n",
    "        \n",
    "        if result['predictions']:\n",
    "            print(\"  Predicted classes (above threshold):\")\n",
    "            for label, prob in sorted(result['predictions'].items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"    - {label}: {prob:.4f}\")\n",
    "        else:\n",
    "            print(\"  No classes above threshold\")\n",
    "        \n",
    "        print(\"  Top 3 probabilities:\")\n",
    "        for label, prob in sorted(result['top_3'].items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"    - {label}: {prob:.4f}\")\n",
    "            \n",
    "        # Add attended tokens for enhanced model\n",
    "        if model_type == \"enhanced\" and result['attended_tokens']:\n",
    "            print(\"  Top attended tokens:\")\n",
    "            for token, weight in result['attended_tokens']:\n",
    "                print(f\"    - {token}: {weight:.4f}\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "# Display results\n",
    "if obvious_results_base:\n",
    "    display_test_results(obvious_results_base, \"Obvious Examples\", \"base\")\n",
    "    \n",
    "if obvious_results_enhanced:\n",
    "    display_test_results(obvious_results_enhanced, \"Obvious Examples\", \"enhanced\")\n",
    "    \n",
    "if less_obvious_results_base:\n",
    "    display_test_results(less_obvious_results_base, \"Less Obvious Examples\", \"base\")\n",
    "    \n",
    "if less_obvious_results_enhanced:\n",
    "    display_test_results(less_obvious_results_enhanced, \"Less Obvious Examples\", \"enhanced\")\n",
    "\n",
    "# Compare base vs enhanced model\n",
    "def compare_models(base_results, enhanced_results, category_name):\n",
    "    print(f\"\\n=== Comparing Base vs Enhanced Model on {category_name} ===\\n\")\n",
    "    \n",
    "    for i, (base_result, enhanced_result) in enumerate(zip(base_results, enhanced_results)):\n",
    "        print(f\"Example {i+1}: \\\"{base_result['text']}\\\"\")\n",
    "        \n",
    "        print(\"  BASE MODEL:\")\n",
    "        if base_result['predictions']:\n",
    "            print(\"    Predicted classes:\")\n",
    "            for label, prob in sorted(base_result['predictions'].items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"      - {label}: {prob:.4f}\")\n",
    "        else:\n",
    "            print(\"    No classes above threshold\")\n",
    "        \n",
    "        print(\"  ENHANCED MODEL:\")\n",
    "        if enhanced_result['predictions']:\n",
    "            print(\"    Predicted classes:\")\n",
    "            for label, prob in sorted(enhanced_result['predictions'].items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"      - {label}: {prob:.4f}\")\n",
    "            \n",
    "            print(\"    Relation cues (attended tokens):\")\n",
    "            for token, weight in enhanced_result['attended_tokens']:\n",
    "                print(f\"      - {token}: {weight:.4f}\")\n",
    "        else:\n",
    "            print(\"    No classes above threshold\")\n",
    "            \n",
    "        # Compare performance\n",
    "        base_classes = set(base_result['predictions'].keys())\n",
    "        enhanced_classes = set(enhanced_result['predictions'].keys())\n",
    "        \n",
    "        new_classes = enhanced_classes - base_classes\n",
    "        if new_classes:\n",
    "            print(f\"  IMPROVEMENT: Enhanced model detected {len(new_classes)} additional classes: {', '.join(new_classes)}\")\n",
    "        \n",
    "        # Check confidence improvements for common classes\n",
    "        common_classes = base_classes.intersection(enhanced_classes)\n",
    "        for cls in common_classes:\n",
    "            base_conf = base_result['predictions'][cls]\n",
    "            enh_conf = enhanced_result['predictions'][cls]\n",
    "            diff = enh_conf - base_conf\n",
    "            if abs(diff) > 0.05:  # Only show significant differences\n",
    "                print(f\"  {cls}: Base {base_conf:.4f} vs Enhanced {enh_conf:.4f} (Diff: {diff:+.4f})\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "# Run comparison\n",
    "if obvious_results_base and obvious_results_enhanced:\n",
    "    compare_models(obvious_results_base, obvious_results_enhanced, \"Obvious Examples\")\n",
    "    \n",
    "if less_obvious_results_base and less_obvious_results_enhanced:\n",
    "    compare_models(less_obvious_results_base, less_obvious_results_enhanced, \"Less Obvious Examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(test_examples, batch_number=1):\n",
    "    \"\"\"\n",
    "    Compare predictions from original and enhanced models on the same examples\n",
    "    \n",
    "    Args:\n",
    "        test_examples: List of text examples to test\n",
    "        batch_number: Batch number to use for model loading\n",
    "    \"\"\"\n",
    "    print(f\"=== Model Comparison on Test Examples (Batch {batch_number}) ===\\n\")\n",
    "    \n",
    "    # Load original model\n",
    "    try:\n",
    "        original_inference = PubMedBERTInference(\n",
    "            model_path=os.path.join(MODEL_DIR, f\"batch_{batch_number}\", \"best_model.pt\"),\n",
    "            thresholds_path=os.path.join(MODEL_DIR, f\"batch_{batch_number}\", \"best_thresholds.json\"),\n",
    "            label_columns_path=\"label_columns.json\"\n",
    "        )\n",
    "        print(\"Original model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading original model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Load enhanced model\n",
    "    try:\n",
    "        enhanced_inference = EnhancedPubMedBERTInference(\n",
    "            model_path=os.path.join(MODEL_DIR, \"enhanced\", f\"enhanced_pubmedbert_model_batch_{batch_number}.pt\"),\n",
    "            thresholds_path=os.path.join(MODEL_DIR, f\"batch_{batch_number}\", \"best_thresholds.json\"),  # Use same thresholds for fair comparison\n",
    "            label_columns_path=\"label_columns.json\"\n",
    "        )\n",
    "        print(\"Enhanced model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading enhanced model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Compare predictions\n",
    "    for i, text in enumerate(test_examples):\n",
    "        print(f\"\\nExample {i+1}: \\\"{text}\\\"\")\n",
    "        \n",
    "        # Original model prediction\n",
    "        original_preds = original_inference.predict(text)\n",
    "        print(\"  ORIGINAL MODEL:\")\n",
    "        if original_preds['predictions']:\n",
    "            print(\"    Predicted classes:\")\n",
    "            for label, prob in sorted(original_preds['predictions'].items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"      - {label}: {prob:.4f}\")\n",
    "        else:\n",
    "            print(\"    No classes above threshold\")\n",
    "        \n",
    "        # Enhanced model prediction\n",
    "        enhanced_preds = enhanced_inference.predict(text)\n",
    "        print(\"  ENHANCED MODEL:\")\n",
    "        if enhanced_preds['predictions']:\n",
    "            print(\"    Predicted classes:\")\n",
    "            for label, prob in sorted(enhanced_preds['predictions'].items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"      - {label}: {prob:.4f}\")\n",
    "            \n",
    "            print(\"    Relation cues (attended tokens):\")\n",
    "            for token, weight in enhanced_preds['attended_tokens']:\n",
    "                print(f\"      - {token}: {weight:.4f}\")\n",
    "        else:\n",
    "            print(\"    No classes above threshold\")\n",
    "        \n",
    "        print(\"  COMPARISON:\")\n",
    "        # Check if enhanced model found classes the original didn't\n",
    "        original_classes = set(original_preds['predictions'].keys())\n",
    "        enhanced_classes = set(enhanced_preds['predictions'].keys())\n",
    "        \n",
    "        new_classes = enhanced_classes - original_classes\n",
    "        if new_classes:\n",
    "            print(f\"    Enhanced model detected {len(new_classes)} additional classes: {', '.join(new_classes)}\")\n",
    "        \n",
    "        # Check if confidence improved for common classes\n",
    "        common_classes = original_classes.intersection(enhanced_classes)\n",
    "        for cls in common_classes:\n",
    "            orig_conf = original_preds['predictions'][cls]\n",
    "            enh_conf = enhanced_preds['predictions'][cls]\n",
    "            diff = enh_conf - orig_conf\n",
    "            print(f\"    {cls}: Original {orig_conf:.4f} vs Enhanced {enh_conf:.4f} (Diff: {diff:+.4f})\")\n",
    "\n",
    "# Test examples for comparison\n",
    "test_examples = [\n",
    "    # Obvious examples (with \"auto\" terms)\n",
    "    \"The receptor undergoes autophosphorylation upon ligand binding.\",\n",
    "    \n",
    "    # Less obvious examples (without \"auto\" terms)\n",
    "    \"The transcription factor binds to its own promoter, creating a feedback loop.\",\n",
    "    \"The kinase transfers phosphate groups to residues within the same protein.\",\n",
    "    \"The enzyme can activate other copies of itself, creating a cascade effect.\",\n",
    "    \n",
    "    # Challenging examples\n",
    "    \"Binding of the ligand causes a conformational change that leads to activation of the protein's catalytic domain.\",\n",
    "    \"The dimeric protein complex enables cross-phosphorylation between the two identical subunits.\"\n",
    "]\n",
    "\n",
    "# Compare models for batch 1\n",
    "compare_models(test_examples, batch_number=1)\n",
    "\n",
    "# Compare models for other batches\n",
    "for batch_num in [2, 3, 4, 5]:\n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "    compare_models(test_examples, batch_number=batch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_model_performance(base_results_dict, enhanced_results_dict):\n",
    "    \"\"\"\n",
    "    Aggregate and summarize performance metrics across test sets\n",
    "    \n",
    "    Args:\n",
    "        base_results_dict: Dictionary of base model results by category\n",
    "        enhanced_results_dict: Dictionary of enhanced model results by category\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    categories = base_results_dict.keys()\n",
    "    summary = {}\n",
    "    \n",
    "    print(\"\\n=== MODEL PERFORMANCE SUMMARY ===\\n\")\n",
    "    print(\"{:<20} {:<15} {:<15} {:<15} {:<15}\".format(\"Category\", \"Base Det. Rate\", \"Enhanced Det. Rate\", \"Improvement\", \"Avg Conf. Diff\"))\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for category in categories:\n",
    "        base_cat = base_results_dict[category]\n",
    "        enhanced_cat = enhanced_results_dict[category]\n",
    "        \n",
    "        # Calculate detection rates\n",
    "        base_detection = sum(1 for r in base_cat if r['predictions']) / len(base_cat) if base_cat else 0\n",
    "        enhanced_detection = sum(1 for r in enhanced_cat if r['predictions']) / len(enhanced_cat) if enhanced_cat else 0\n",
    "        \n",
    "        # Calculate average confidence\n",
    "        base_conf = sum(list(r['top_3'].values())[0] for r in base_cat) / len(base_cat) if base_cat else 0\n",
    "        enhanced_conf = sum(list(r['top_3'].values())[0] for r in enhanced_cat) / len(enhanced_cat) if enhanced_cat else 0\n",
    "        \n",
    "        # Calculate average confidence difference for common predictions\n",
    "        conf_diffs = []\n",
    "        for b_result, e_result in zip(base_cat, enhanced_cat):\n",
    "            common_classes = set(b_result['predictions'].keys()) & set(e_result['predictions'].keys())\n",
    "            if common_classes:\n",
    "                for cls in common_classes:\n",
    "                    conf_diffs.append(e_result['predictions'][cls] - b_result['predictions'][cls])\n",
    "        \n",
    "        avg_conf_diff = sum(conf_diffs) / len(conf_diffs) if conf_diffs else 0\n",
    "        \n",
    "        # Add to summary\n",
    "        summary[category] = {\n",
    "            'base_detection_rate': base_detection,\n",
    "            'enhanced_detection_rate': enhanced_detection,\n",
    "            'improvement': enhanced_detection - base_detection,\n",
    "            'avg_confidence_diff': avg_conf_diff\n",
    "        }\n",
    "        \n",
    "        # Print summary row\n",
    "        print(\"{:<20} {:<15.2%} {:<15.2%} {:<15.2%} {:<15.4f}\".format(\n",
    "            category, \n",
    "            base_detection, \n",
    "            enhanced_detection, \n",
    "            enhanced_detection - base_detection,\n",
    "            avg_conf_diff\n",
    "        ))\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_attention_across_batches(text, batch_numbers, tokenizer=None):\n",
    "    \"\"\"\n",
    "    Compare attention patterns for the same example across different batch models\n",
    "    \n",
    "    Args:\n",
    "        text: Text example to analyze\n",
    "        batch_numbers: List of batch numbers to compare\n",
    "        tokenizer: Optional tokenizer (will be loaded if not provided)\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from matplotlib.figure import Figure\n",
    "    from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "    \n",
    "    # Truncate long text\n",
    "    if len(text) > 512:\n",
    "        print(\"Warning: Text is too long and will be truncated for visualization\")\n",
    "        text = text[:512]\n",
    "    \n",
    "    if not tokenizer:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    n_batches = len(batch_numbers)\n",
    "    fig, axes = plt.subplots(n_batches, 1, figsize=(12, 2*n_batches), sharex=True)\n",
    "    if n_batches == 1:\n",
    "        axes = [axes]  # Make axes iterable if only one batch\n",
    "    \n",
    "    # Get tokens (same for all models)\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    \n",
    "    # Process each batch\n",
    "    for i, batch_num in enumerate(batch_numbers):\n",
    "        # Load enhanced model\n",
    "        try:\n",
    "            model_path = os.path.join(MODEL_DIR, \"enhanced\", f\"enhanced_pubmedbert_model_batch_{batch_num}.pt\")\n",
    "            thresholds_path = os.path.join(MODEL_DIR, f\"batch_{batch_number}\", \"best_thresholds.json\")\n",
    "            \n",
    "            # Load label columns\n",
    "            with open('label_columns.json', 'r') as f:\n",
    "                label_columns = json.load(f)\n",
    "            \n",
    "            # Initialize model\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model = EnhancedPubMedBERTClassifier(n_classes=len(label_columns)).to(device)\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            model.eval()\n",
    "            \n",
    "            # Get attention weights\n",
    "            with torch.no_grad():\n",
    "                input_ids_device = input_ids.to(device)\n",
    "                attention_mask_device = attention_mask.to(device)\n",
    "                _, attention_weights = model(input_ids_device, attention_mask_device)\n",
    "            \n",
    "            # Convert attention weights to numpy\n",
    "            attention_weights = attention_weights.squeeze().cpu().numpy()\n",
    "            \n",
    "            # Plot heatmap\n",
    "            sns.heatmap(\n",
    "                [attention_weights[1:len(tokens)-1]], \n",
    "                xticklabels=tokens[1:len(tokens)-1],\n",
    "                yticklabels=[f'Batch {batch_num}'],\n",
    "                cmap='viridis',\n",
    "                ax=axes[i],\n",
    "                cbar=(i == 0)  # Only show colorbar for first plot\n",
    "            )\n",
    "            \n",
    "            # Find top 5 attended tokens\n",
    "            top_indices = attention_weights.argsort()[-5:][::-1]\n",
    "            top_tokens = [tokens[i+1] for i in top_indices if i+1 < len(tokens)-1]\n",
    "            \n",
    "            # Add annotation\n",
    "            top_token_text = \", \".join(top_tokens)\n",
    "            axes[i].set_title(f\"Batch {batch_num} - Top: {top_token_text}\", fontsize=10)\n",
    "            \n",
    "        except Exception as e:\n",
    "            axes[i].text(0.5, 0.5, f\"Error loading batch {batch_num}: {str(e)}\", \n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    plt.suptitle(f'Attention Comparison Across Batches for: \"{text}\"', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)  # Make room for suptitle\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_errors(results, category_name, model_type=\"enhanced\"):\n",
    "    \"\"\"\n",
    "    Analyze patterns in misclassifications\n",
    "    \n",
    "    Args:\n",
    "        results: List of prediction results \n",
    "        category_name: Category name for reporting\n",
    "        model_type: Model type (\"base\" or \"enhanced\")\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== ERROR ANALYSIS: {category_name} ({model_type.upper()} MODEL) ===\\n\")\n",
    "    \n",
    "    # For obvious examples with auto terms, we expect the model to detect the class\n",
    "    if category_name == \"Obvious Examples\":\n",
    "        for result in results:\n",
    "            text = result['text']\n",
    "            \n",
    "            # Extract auto-term from text\n",
    "            auto_terms = [word for word in text.lower().split() if word.startswith('auto')]\n",
    "            \n",
    "            if auto_terms:\n",
    "                auto_term = auto_terms[0]\n",
    "                # Check if the corresponding class was detected\n",
    "                expected_class = auto_term.rstrip(',.;:')  # Remove trailing punctuation\n",
    "                \n",
    "                # If expected class was not in top predictions\n",
    "                if expected_class not in result['predictions']:\n",
    "                    print(f\"MISSED: \\\"{text}\\\"\")\n",
    "                    print(f\"  Expected: {expected_class}\")\n",
    "                    print(f\"  Top predictions:\")\n",
    "                    for label, prob in sorted(result['top_3'].items(), key=lambda x: x[1], reverse=True):\n",
    "                        print(f\"    - {label}: {prob:.4f}\")\n",
    "                    print()\n",
    "    \n",
    "    # For negative examples, we expect no autoregulatory classes to be detected\n",
    "    elif category_name == \"Negative Examples\":\n",
    "        for result in results:\n",
    "            auto_predictions = {k: v for k, v in result['predictions'].items() if k.startswith('auto')}\n",
    "            if auto_predictions:\n",
    "                print(f\"FALSE POSITIVE: \\\"{result['text']}\\\"\")\n",
    "                print(f\"  Incorrectly predicted:\")\n",
    "                for label, prob in sorted(auto_predictions.items(), key=lambda x: x[1], reverse=True):\n",
    "                    print(f\"    - {label}: {prob:.4f}\")\n",
    "                print()\n",
    "    \n",
    "    # For less obvious examples, check if the model found relevant classes\n",
    "    elif category_name == \"Less Obvious Examples\":\n",
    "        # Define keywords that suggest certain autoregulatory mechanisms\n",
    "        mechanism_keywords = {\n",
    "            'feedback': ['autoregulation', 'autofeedback'],\n",
    "            'itself': ['autoactivation', 'autophosphorylation', 'autocatalysis'],\n",
    "            'own': ['autoregulation', 'autoinhibition'],\n",
    "            'dimerizes': ['autoactivation', 'autophosphorylation'],\n",
    "            'cross-phosphorylates': ['autophosphorylation']\n",
    "        }\n",
    "        \n",
    "        for result in results:\n",
    "            text = result['text'].lower()\n",
    "            \n",
    "            # Check for expected classes based on keywords\n",
    "            expected_classes = []\n",
    "            for keyword, classes in mechanism_keywords.items():\n",
    "                if keyword in text:\n",
    "                    expected_classes.extend(classes)\n",
    "            \n",
    "            # If no expected classes were predicted\n",
    "            if expected_classes and not any(cls in result['predictions'] for cls in expected_classes):\n",
    "                print(f\"POTENTIAL MISS: \\\"{result['text']}\\\"\")\n",
    "                print(f\"  Expected one of: {', '.join(set(expected_classes))}\")\n",
    "                print(f\"  Top predictions:\")\n",
    "                for label, prob in sorted(result['top_3'].items(), key=lambda x: x[1], reverse=True):\n",
    "                    print(f\"    - {label}: {prob:.4f}\")\n",
    "                print()\n",
    "    \n",
    "    # Count overall detections and non-detections\n",
    "    detection_count = sum(1 for r in results if r['predictions'])\n",
    "    no_detection_count = len(results) - detection_count\n",
    "    print(f\"SUMMARY: {detection_count}/{len(results)} ({detection_count/len(results):.1%}) examples had detections\")\n",
    "    print(f\"         {no_detection_count}/{len(results)} ({no_detection_count/len(results):.1%}) examples had no detections\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d006eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results_to_csv(all_results, batch_number, filename=None):\n",
    "    \"\"\"\n",
    "    Export all test results to CSV for analysis\n",
    "    \n",
    "    Args:\n",
    "        all_results: Dictionary of results by category and model type\n",
    "        batch_number: Batch number for the results\n",
    "        filename: Optional filename (default is based on batch number)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    if filename is None:\n",
    "        filename = f\"model_comparison_results_batch_{batch_number}.csv\"\n",
    "    \n",
    "    # Create a list to hold all result rows\n",
    "    rows = []\n",
    "    \n",
    "    # Process each category and model type\n",
    "    for category, model_dict in all_results.items():\n",
    "        for model_type, results in model_dict.items():\n",
    "            for result in results:\n",
    "                # Create base row\n",
    "                base_row = {\n",
    "                    'batch': batch_number,\n",
    "                    'category': category,\n",
    "                    'model_type': model_type,\n",
    "                    'text': result['text'],\n",
    "                    'predictions_count': len(result['predictions']),\n",
    "                    'has_predictions': len(result['predictions']) > 0,\n",
    "                    'top_class': list(result['top_3'].keys())[0] if result['top_3'] else None,\n",
    "                    'top_confidence': list(result['top_3'].values())[0] if result['top_3'] else 0\n",
    "                }\n",
    "                \n",
    "                # Add top 3 classes and confidences\n",
    "                for i, (cls, conf) in enumerate(result['top_3'].items(), 1):\n",
    "                    base_row[f'class_{i}'] = cls\n",
    "                    base_row[f'conf_{i}'] = conf\n",
    "                \n",
    "                # Add attended tokens for enhanced model\n",
    "                if model_type == 'enhanced' and result['attended_tokens']:\n",
    "                    for i, (token, weight) in enumerate(result['attended_tokens'][:3], 1):\n",
    "                        base_row[f'token_{i}'] = token\n",
    "                        base_row[f'weight_{i}'] = weight\n",
    "                \n",
    "                rows.append(base_row)\n",
    "    \n",
    "    # Convert to DataFrame and save\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Results exported to {filename}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run testing and store results\n",
    "batch_numbers = [1, 2, 3, 4, 5]  # Adjust based on your actual batch numbers\n",
    "all_results = {}\n",
    "\n",
    "for batch_num in batch_numbers:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TESTING BATCH {batch_num}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Collect results for this batch\n",
    "    batch_results = {}\n",
    "    \n",
    "    # Test base model\n",
    "    print(\"Testing base model on obvious examples...\")\n",
    "    obvious_results_base = load_model_and_predict(obvious_examples, batch_number=batch_num, model_type=\"base\")\n",
    "    \n",
    "    print(\"\\nTesting enhanced model on obvious examples...\")\n",
    "    obvious_results_enhanced = load_model_and_predict(obvious_examples, batch_number=batch_num, model_type=\"enhanced\")\n",
    "    \n",
    "    print(\"\\nTesting base model on less obvious examples...\")\n",
    "    less_obvious_results_base = load_model_and_predict(less_obvious_examples, batch_number=batch_num, model_type=\"base\")\n",
    "    \n",
    "    print(\"\\nTesting enhanced model on less obvious examples...\")\n",
    "    less_obvious_results_enhanced = load_model_and_predict(less_obvious_examples, batch_number=batch_num, model_type=\"enhanced\")\n",
    "    \n",
    "    print(\"\\nTesting base model on challenging examples...\")\n",
    "    challenging_results_base = load_model_and_predict(challenging_examples, batch_number=batch_num, model_type=\"base\")\n",
    "    \n",
    "    print(\"\\nTesting enhanced model on challenging examples...\")\n",
    "    challenging_results_enhanced = load_model_and_predict(challenging_examples, batch_number=batch_num, model_type=\"enhanced\")\n",
    "    \n",
    "    print(\"\\nTesting base model on negative examples...\")\n",
    "    negative_results_base = load_model_and_predict(negative_examples, batch_number=batch_num, model_type=\"base\")\n",
    "    \n",
    "    print(\"\\nTesting enhanced model on negative examples...\")\n",
    "    negative_results_enhanced = load_model_and_predict(negative_examples, batch_number=batch_num, model_type=\"enhanced\")\n",
    "    \n",
    "    # Store results\n",
    "    batch_results = {\n",
    "        'Obvious Examples': {\n",
    "            'base': obvious_results_base,\n",
    "            'enhanced': obvious_results_enhanced\n",
    "        },\n",
    "        'Less Obvious Examples': {\n",
    "            'base': less_obvious_results_base,\n",
    "            'enhanced': less_obvious_results_enhanced\n",
    "        },\n",
    "        'Challenging Examples': {\n",
    "            'base': challenging_results_base,\n",
    "            'enhanced': challenging_results_enhanced\n",
    "        },\n",
    "        'Negative Examples': {\n",
    "            'base': negative_results_base,\n",
    "            'enhanced': negative_results_enhanced\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    all_results[batch_num] = batch_results\n",
    "    \n",
    "    # Display results\n",
    "    for category in ['Obvious Examples', 'Less Obvious Examples', 'Challenging Examples', 'Negative Examples']:\n",
    "        display_test_results(batch_results[category]['base'], category, \"base\")\n",
    "        display_test_results(batch_results[category]['enhanced'], category, \"enhanced\")\n",
    "    \n",
    "    # Compare models\n",
    "    for category in ['Obvious Examples', 'Less Obvious Examples', 'Challenging Examples']:\n",
    "        compare_models(batch_results[category]['base'], batch_results[category]['enhanced'], category)\n",
    "    \n",
    "    # Analyze errors\n",
    "    for category in ['Obvious Examples', 'Less Obvious Examples', 'Negative Examples']:\n",
    "        analyze_errors(batch_results[category]['enhanced'], category)\n",
    "    \n",
    "    # Summarize performance\n",
    "    base_results_dict = {k: v['base'] for k, v in batch_results.items()}\n",
    "    enhanced_results_dict = {k: v['enhanced'] for k, v in batch_results.items()}\n",
    "    summarize_model_performance(base_results_dict, enhanced_results_dict)\n",
    "    \n",
    "    # Export results to CSV\n",
    "    export_results_to_csv(batch_results, batch_num)\n",
    "    \n",
    "    # Visualize attention for a couple of examples\n",
    "    if batch_num == 1:  # Only create visualization for first batch to avoid clutter\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "        \n",
    "        # Compare across batches for one obvious and one less obvious example\n",
    "        print(\"\\nComparing attention across batches...\")\n",
    "        compare_attention_across_batches(obvious_examples[0], batch_numbers, tokenizer)\n",
    "        compare_attention_across_batches(less_obvious_examples[0], batch_numbers, tokenizer)\n",
    "\n",
    "print(\"\\nAll testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b55b31a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoregulatory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
