{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46fcac3",
   "metadata": {},
   "source": [
    "# PubMed BERT Model + Attention Mechanism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19186769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os, random, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "617f1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Random Seed Setup for Reproducibility  \n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49a7a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Device Configuration (GPU/CPU/MPS)\n",
    "device = (\n",
    "    torch.device(\"mps\")\n",
    "    if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cuda\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3723fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Training Hyperparameters\n",
    "n_epochs = 5\n",
    "learning_rate = 5e-6  \n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b38dd4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Constants and Label Definitions\n",
    "# Define polarity labels\n",
    "POLARITY_LABELS = ['positive', 'negative', 'neutral']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2812e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Directory Creation for Models and Results\n",
    "MODEL_DIR = \"model\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)  # Create the base model directory\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485aa656",
   "metadata": {},
   "source": [
    "# 2. Utility Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "728aa649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Text Preprocessing Function\n",
    "\n",
    "# Download stopwords if not already present\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess text for biomedical NLP by cleaning and normalizing\n",
    "    \n",
    "    Args:\n",
    "        text: Raw text string to preprocess\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned and normalized text string\n",
    "    \"\"\"\n",
    "    # Handle NaN values\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Keep hyphens as they may be important in biomedical terms (e.g., auto-regulation)\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove stopwords but keep important biomedical terms\n",
    "    # Note: We're being conservative with stopword removal for biomedical text\n",
    "    text = \" \".join([word.strip() for word in text.split() if word not in stop_words or len(word) > 4])\n",
    "    \n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15ace63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 8: Dataset Class Definition  \n",
    "class PubMedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for PubMed text classification with optional polarity labels\n",
    "    \n",
    "    This class handles both mechanism detection and polarity classification tasks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512, polarities=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset\n",
    "        \n",
    "        Args:\n",
    "            texts: List or Series of text samples\n",
    "            labels: numpy array of multi-label binary labels for mechanisms\n",
    "            tokenizer: Transformers tokenizer for text encoding\n",
    "            max_length: Maximum sequence length for tokenization\n",
    "            polarities: Optional numpy array of polarity labels (for multi-task learning)\n",
    "        \"\"\"\n",
    "        self.texts = texts.reset_index(drop=True) if hasattr(texts, 'reset_index') else texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.polarities = polarities\n",
    "        \n",
    "        # Validate inputs\n",
    "        if len(self.texts) != len(self.labels):\n",
    "            raise ValueError(f\"Text count ({len(self.texts)}) doesn't match label count ({len(self.labels)})\")\n",
    "        \n",
    "        if self.polarities is not None and len(self.texts) != len(self.polarities):\n",
    "            raise ValueError(f\"Text count ({len(self.texts)}) doesn't match polarity count ({len(self.polarities)})\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single item from the dataset\n",
    "        \n",
    "        Args:\n",
    "            idx: Index of the item to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing tokenized inputs and labels\n",
    "        \"\"\"\n",
    "        # Get text and preprocess it\n",
    "        text = str(self.texts.iloc[idx] if hasattr(self.texts, 'iloc') else self.texts[idx])\n",
    "        text = preprocess_text(text)  # Apply preprocessing\n",
    "        \n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Prepare the return dictionary\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.FloatTensor(self.labels[idx])  # Convert to float for BCE loss\n",
    "        }\n",
    "        \n",
    "        # Add polarity labels if available\n",
    "        if self.polarities is not None:\n",
    "            item['polarity'] = torch.LongTensor([self.polarities[idx]]).squeeze()  # Convert to long for CE loss\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c7486f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Loss Function Classes\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, pos_weights, gamma=0.5, alpha=0.8):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.pos_weights = pos_weights\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # Higher alpha = more weight on BCE\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # Weighted BCE loss\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(\n",
    "            inputs, targets, pos_weight=self.pos_weights, reduction='none'\n",
    "        )\n",
    "        \n",
    "        # Focal component (lighter weight)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_component = (1 - pt) ** self.gamma * BCE_loss\n",
    "        \n",
    "        # Combine both losses (80% BCE, 20% Focal)\n",
    "        combined = self.alpha * BCE_loss + (1 - self.alpha) * focal_component\n",
    "        \n",
    "        return combined.mean()\n",
    "    \n",
    "class MultiTaskLoss(nn.Module):\n",
    "    def __init__(self, pos_weights, mech_weight=0.7, pol_weight=0.3):\n",
    "        super(MultiTaskLoss, self).__init__()\n",
    "        self.pos_weights = pos_weights\n",
    "        self.mech_weight = mech_weight\n",
    "        self.pol_weight = pol_weight\n",
    "        self.mech_criterion = CombinedLoss(pos_weights)\n",
    "        self.pol_criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, mech_logits, pol_logits, mech_labels, pol_labels):\n",
    "        mech_loss = self.mech_criterion(mech_logits, mech_labels)\n",
    "        pol_loss = self.pol_criterion(pol_logits, pol_labels)\n",
    "        \n",
    "        # Combine mechanism and polarity losses\n",
    "        total_loss = self.mech_weight * mech_loss + self.pol_weight * pol_loss\n",
    "        \n",
    "        return total_loss, mech_loss, pol_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea4f48e",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c11d8441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26205, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Terms</th>\n",
       "      <th>Text_combined</th>\n",
       "      <th>batch_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P40416</td>\n",
       "      <td>31040179</td>\n",
       "      <td>Mitochondria export iron-sulfur and sulfur int...</td>\n",
       "      <td>Iron-sulfur clusters are essential cofactors o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitochondria export iron-sulfur and sulfur int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P55511</td>\n",
       "      <td>19376903</td>\n",
       "      <td>Rhizobium sp. strain NGR234 possesses a remark...</td>\n",
       "      <td>Rhizobium sp. strain NGR234 is a unique alphap...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhizobium sp. strain NGR234 possesses a remark...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q18G63</td>\n",
       "      <td>16820047</td>\n",
       "      <td>The genome of the square archaeon Haloquadratu...</td>\n",
       "      <td>The square halophilic archaeon Haloquadratum w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The genome of the square archaeon Haloquadratu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O64682</td>\n",
       "      <td>10693763</td>\n",
       "      <td>Regulation of auxin response by the protein ki...</td>\n",
       "      <td>Arabidopsis plants carrying mutations in the P...</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>Regulation of auxin response by the protein ki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P63097</td>\n",
       "      <td>3094012</td>\n",
       "      <td>Molecular cloning and characterization of cDNA...</td>\n",
       "      <td>We have cloned and characterized cDNA encoding...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Molecular cloning and characterization of cDNA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AC      PMID                                              Title  \\\n",
       "0  P40416  31040179  Mitochondria export iron-sulfur and sulfur int...   \n",
       "1  P55511  19376903  Rhizobium sp. strain NGR234 possesses a remark...   \n",
       "2  Q18G63  16820047  The genome of the square archaeon Haloquadratu...   \n",
       "3  O64682  10693763  Regulation of auxin response by the protein ki...   \n",
       "4  P63097   3094012  Molecular cloning and characterization of cDNA...   \n",
       "\n",
       "                                            Abstract                Terms  \\\n",
       "0  Iron-sulfur clusters are essential cofactors o...                  NaN   \n",
       "1  Rhizobium sp. strain NGR234 is a unique alphap...                  NaN   \n",
       "2  The square halophilic archaeon Haloquadratum w...                  NaN   \n",
       "3  Arabidopsis plants carrying mutations in the P...  autophosphorylation   \n",
       "4  We have cloned and characterized cDNA encoding...                  NaN   \n",
       "\n",
       "                                       Text_combined  batch_number  \n",
       "0  Mitochondria export iron-sulfur and sulfur int...             1  \n",
       "1  Rhizobium sp. strain NGR234 possesses a remark...             1  \n",
       "2  The genome of the square archaeon Haloquadratu...             1  \n",
       "3  Regulation of auxin response by the protein ki...             1  \n",
       "4  Molecular cloning and characterization of cDNA...             1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 10: Data Loading\n",
    "# Load data\n",
    "df = pd.read_csv('../data/processed/train_data.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fa2325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Text Preprocessing and Cleaning\n",
    "df['Text_Cleaned'] = df['Text_combined'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd66ec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 unique labels: ['autoactivation' 'autocatalysis' 'autofeedback' 'autoinduction'\n",
      " 'autoinhibition' 'autokinase' 'autolysis' 'autophosphorylation'\n",
      " 'autoregulation' 'autoubiquitination']\n",
      "Final cleaned data shape: (26205, 12)\n",
      "(26205, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_number</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>autoactivation</th>\n",
       "      <th>autocatalysis</th>\n",
       "      <th>autofeedback</th>\n",
       "      <th>autoinduction</th>\n",
       "      <th>autoinhibition</th>\n",
       "      <th>autokinase</th>\n",
       "      <th>autolysis</th>\n",
       "      <th>autophosphorylation</th>\n",
       "      <th>autoregulation</th>\n",
       "      <th>autoubiquitination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mitochondria export iron-sulfur sulfur interme...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rhizobium sp strain ngr234 possesses remarkabl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>genome square archaeon haloquadratum walsbyi l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>regulation auxin response protein kinase pinoi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>molecular cloning characterization cdna encodi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_number                                       Text_Cleaned  \\\n",
       "0             1  mitochondria export iron-sulfur sulfur interme...   \n",
       "1             1  rhizobium sp strain ngr234 possesses remarkabl...   \n",
       "2             1  genome square archaeon haloquadratum walsbyi l...   \n",
       "3             1  regulation auxin response protein kinase pinoi...   \n",
       "4             1  molecular cloning characterization cdna encodi...   \n",
       "\n",
       "   autoactivation  autocatalysis  autofeedback  autoinduction  autoinhibition  \\\n",
       "0               0              0             0              0               0   \n",
       "1               0              0             0              0               0   \n",
       "2               0              0             0              0               0   \n",
       "3               0              0             0              0               0   \n",
       "4               0              0             0              0               0   \n",
       "\n",
       "   autokinase  autolysis  autophosphorylation  autoregulation  \\\n",
       "0           0          0                    0               0   \n",
       "1           0          0                    0               0   \n",
       "2           0          0                    0               0   \n",
       "3           0          0                    1               0   \n",
       "4           0          0                    0               0   \n",
       "\n",
       "   autoubiquitination  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 12: Mechanism Label Binarization\n",
    "# Convert comma-separated terms to multi-label binary format using MLB\n",
    "\n",
    "# Binarize the Terms column\n",
    "df['Terms_List'] = df['Terms'].apply(\n",
    "    lambda x: [term.strip() for term in str(x).split(',')] if pd.notna(x) and x != '' else []\n",
    ")\n",
    "\n",
    "# Initialize and fit the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "binary_labels = mlb.fit_transform(df['Terms_List'])\n",
    "\n",
    "# Get the class names\n",
    "label_columns = mlb.classes_\n",
    "print(f\"Found {len(label_columns)} unique labels: {label_columns}\")\n",
    "\n",
    "# Create a DataFrame with the binary labels\n",
    "labels_df = pd.DataFrame(binary_labels, columns=label_columns)\n",
    "\n",
    "# Save label columns for later use\n",
    "with open('label_columns.json', 'w') as f:\n",
    "    json.dump(list(label_columns), f)\n",
    "\n",
    "# Keep only essential columns\n",
    "df_cleaned = df[['batch_number', 'Text_Cleaned']].copy()\n",
    "df_cleaned = pd.concat([df_cleaned, labels_df], axis=1)\n",
    "\n",
    "print(f\"Final cleaned data shape: {df_cleaned.shape}\")\n",
    "print(df_cleaned.shape)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e1c894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring polarity labels...\n",
      "\n",
      "Polarity distribution:\n",
      "neutral: 18200 (69.5%)\n",
      "positive: 5540 (21.1%)\n",
      "negative: 2465 (9.4%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Polarity Label Inference and Encoding\n",
    "# Add polarity inference function\n",
    "def infer_polarity(text, mechanism):\n",
    "    \"\"\"\n",
    "    Infer polarity (positive/negative/neutral) from text and mechanism\n",
    "    \n",
    "    This is a rule-based method that can be later replaced with manual annotations\n",
    "    \"\"\"\n",
    "    # EXPANDED: Keywords indicating negative regulation\n",
    "    negative_keywords = [\n",
    "        # Your original keywords\n",
    "        'inhibit', 'repress', 'suppress', 'block', 'reduce', 'decrease', 'down-regulat', \n",
    "        'downregulat', 'negative', 'inactivat', 'stop', 'prevent',\n",
    "        \n",
    "        # Additional biomedical negative terms\n",
    "        'attenuate', 'dampen', 'silence', 'knock', 'impair', 'abolish', 'diminish',\n",
    "        'weaken', 'curtail', 'halt', 'terminate', 'cease', 'limit', 'restrict',\n",
    "        'degradation', 'breakdown', 'turnover', 'cleavage', 'proteolysis',\n",
    "        'downmodulat', 'counter', 'antagoniz', 'oppose'\n",
    "    ]\n",
    "    \n",
    "    # EXPANDED: Keywords indicating positive regulation  \n",
    "    positive_keywords = [\n",
    "        # Your original keywords\n",
    "        'activat', 'increas', 'induce', 'enhance', 'promot', 'stimulat', 'up-regulat',\n",
    "        'upregulat', 'positive', 'amplif',\n",
    "        \n",
    "        # Additional biomedical positive terms\n",
    "        'boost', 'augment', 'facilitate', 'accelerate', 'catalyze', 'drive', 'trigger',\n",
    "        'elicit', 'evoke', 'potentiat', 'strengthen', 'reinforce', 'foster', 'support',\n",
    "        'maintain', 'sustain', 'stabiliz', 'preserve', 'accumul', 'recruit',\n",
    "        'upmodulat', 'elevat', 'heighten', 'agoniz'\n",
    "    ]\n",
    "    \n",
    "    # Convert text to lowercase for matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Count keyword occurrences (more robust than just presence)\n",
    "    negative_count = sum(1 for keyword in negative_keywords if keyword in text_lower)\n",
    "    positive_count = sum(1 for keyword in positive_keywords if keyword in text_lower)\n",
    "    \n",
    "    # Determine polarity based on keyword balance\n",
    "    if negative_count > positive_count:\n",
    "        return 'negative'\n",
    "    elif positive_count > negative_count:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        # If balanced or no keywords, use mechanism-based heuristics\n",
    "        if mechanism in ['autoinhibition', 'autorepression']:  # Typically negative\n",
    "            return 'negative'\n",
    "        elif mechanism in ['autoactivation', 'autophosphorylation', 'autoinduction']:  # Typically positive\n",
    "            return 'positive'\n",
    "        else:\n",
    "            return 'neutral'  # Default\n",
    "        \n",
    "# Add polarity labels to dataset\n",
    "print(\"Inferring polarity labels...\")\n",
    "polarities = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row['Text_combined'] if pd.notna(row['Text_combined']) else \"\"\n",
    "    \n",
    "    # Get the mechanisms for this example\n",
    "    mechanisms = row['Terms_List']\n",
    "    \n",
    "    # If no mechanisms, assign neutral\n",
    "    if not mechanisms:\n",
    "        polarities.append('neutral')\n",
    "    else:\n",
    "        # Get the first mechanism (for multi-labeled entries)\n",
    "        mechanism = mechanisms[0] if mechanisms else \"\"\n",
    "        polarity = infer_polarity(text, mechanism)\n",
    "        polarities.append(polarity)\n",
    "\n",
    "# Add to dataframe\n",
    "df['polarity'] = polarities\n",
    "\n",
    "# Encode polarity labels\n",
    "polarity_encoder = LabelEncoder()\n",
    "polarity_encoder.fit(POLARITY_LABELS)  # Use our predefined labels\n",
    "encoded_polarities = polarity_encoder.transform(df['polarity'])\n",
    "\n",
    "# Add to cleaned dataframe\n",
    "df_cleaned['polarity'] = df['polarity']\n",
    "df_cleaned['polarity_encoded'] = encoded_polarities\n",
    "\n",
    "# Save polarity encoder classes\n",
    "with open('polarity_labels.json', 'w') as f:\n",
    "    json.dump(list(polarity_encoder.classes_), f)\n",
    "\n",
    "# Display polarity distribution\n",
    "polarity_counts = df['polarity'].value_counts()\n",
    "print(\"\\nPolarity distribution:\")\n",
    "for pol, count in polarity_counts.items():\n",
    "    print(f\"{pol}: {count} ({count/len(df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6c1d7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cleaned data shape with polarity: (26205, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_number</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>autoactivation</th>\n",
       "      <th>autocatalysis</th>\n",
       "      <th>autofeedback</th>\n",
       "      <th>autoinduction</th>\n",
       "      <th>autoinhibition</th>\n",
       "      <th>autokinase</th>\n",
       "      <th>autolysis</th>\n",
       "      <th>autophosphorylation</th>\n",
       "      <th>autoregulation</th>\n",
       "      <th>autoubiquitination</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarity_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mitochondria export iron-sulfur sulfur interme...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rhizobium sp strain ngr234 possesses remarkabl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>genome square archaeon haloquadratum walsbyi l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>regulation auxin response protein kinase pinoi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>molecular cloning characterization cdna encodi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_number                                       Text_Cleaned  \\\n",
       "0             1  mitochondria export iron-sulfur sulfur interme...   \n",
       "1             1  rhizobium sp strain ngr234 possesses remarkabl...   \n",
       "2             1  genome square archaeon haloquadratum walsbyi l...   \n",
       "3             1  regulation auxin response protein kinase pinoi...   \n",
       "4             1  molecular cloning characterization cdna encodi...   \n",
       "\n",
       "   autoactivation  autocatalysis  autofeedback  autoinduction  autoinhibition  \\\n",
       "0               0              0             0              0               0   \n",
       "1               0              0             0              0               0   \n",
       "2               0              0             0              0               0   \n",
       "3               0              0             0              0               0   \n",
       "4               0              0             0              0               0   \n",
       "\n",
       "   autokinase  autolysis  autophosphorylation  autoregulation  \\\n",
       "0           0          0                    0               0   \n",
       "1           0          0                    0               0   \n",
       "2           0          0                    0               0   \n",
       "3           0          0                    1               0   \n",
       "4           0          0                    0               0   \n",
       "\n",
       "   autoubiquitination  polarity  polarity_encoded  \n",
       "0                   0   neutral                 1  \n",
       "1                   0   neutral                 1  \n",
       "2                   0   neutral                 1  \n",
       "3                   0  negative                 0  \n",
       "4                   0   neutral                 1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 14: Final Dataset \n",
    "print(f\"Final cleaned data shape with polarity: {df_cleaned.shape}\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9acb24",
   "metadata": {},
   "source": [
    "# 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e36ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Base Model Definition\n",
    "class ImprovedPubMedBERTClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, dropout1=0.1, dropout2=0.2):\n",
    "        super(ImprovedPubMedBERTClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.intermediate = nn.Linear(self.bert.config.hidden_size, 512)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        self.classifier = nn.Linear(512, n_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.xavier_normal_(self.intermediate.weight)\n",
    "        nn.init.zeros_(self.intermediate.bias)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        pooled_output = self.dropout1(pooled_output)\n",
    "        intermediate = self.intermediate(pooled_output)\n",
    "        intermediate = self.activation(intermediate)\n",
    "        intermediate = self.dropout2(intermediate)\n",
    "        logits = self.classifier(intermediate)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d955fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 16: Multi-Task Model Definition  \n",
    "class PolarityPubMedBERTClassifier(nn.Module):\n",
    "    def __init__(self, n_mech_classes, n_polarity_classes=3, dropout1=0.1, dropout2=0.2):\n",
    "        super(PolarityPubMedBERTClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "        \n",
    "        # Shared layers\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.intermediate = nn.Linear(self.bert.config.hidden_size, 512)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        # Mechanism classification branch\n",
    "        self.dropout2_mech = nn.Dropout(dropout2)\n",
    "        self.classifier_mech = nn.Linear(512, n_mech_classes)\n",
    "        \n",
    "        # Polarity classification branch\n",
    "        self.dropout2_pol = nn.Dropout(dropout2)\n",
    "        self.classifier_pol = nn.Linear(512, n_polarity_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.xavier_normal_(self.intermediate.weight)\n",
    "        nn.init.zeros_(self.intermediate.bias)\n",
    "        nn.init.xavier_normal_(self.classifier_mech.weight)\n",
    "        nn.init.zeros_(self.classifier_mech.bias)\n",
    "        nn.init.xavier_normal_(self.classifier_pol.weight)\n",
    "        nn.init.zeros_(self.classifier_pol.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        pooled_output = self.dropout1(pooled_output)\n",
    "        \n",
    "        # Shared intermediate representation\n",
    "        shared_features = self.activation(self.intermediate(pooled_output))\n",
    "        \n",
    "        # Mechanism prediction\n",
    "        mech_features = self.dropout2_mech(shared_features)\n",
    "        mech_logits = self.classifier_mech(mech_features)\n",
    "        \n",
    "        # Polarity prediction\n",
    "        pol_features = self.dropout2_pol(shared_features)\n",
    "        pol_logits = self.classifier_pol(pol_features)\n",
    "        \n",
    "        return mech_logits, pol_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d833ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 17: Enhanced Single-Task Model (OPTIONAL)\n",
    "class EnhancedPubMedBERTClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, dropout1=0.1, dropout2=0.2):\n",
    "        super(EnhancedPubMedBERTClassifier, self).__init__()\n",
    "        # Load base PubMedBERT\n",
    "        self.bert = AutoModel.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "        \n",
    "        # Add relation attention mechanism\n",
    "        self.relation_query = nn.Parameter(torch.randn(768, 1))\n",
    "        self.relation_key = nn.Linear(768, 768)\n",
    "        self.relation_value = nn.Linear(768, 768)\n",
    "        \n",
    "        # Main classification path\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.intermediate = nn.Linear(768 * 2, 512)  # Doubled for concatenation\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        self.classifier = nn.Linear(512, n_classes)\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        nn.init.xavier_normal_(self.intermediate.weight)\n",
    "        nn.init.zeros_(self.intermediate.bias)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get PubMedBERT embeddings\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Get sequence outputs\n",
    "        sequence_output = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "        cls_token = sequence_output[:, 0, :]  # [batch_size, hidden_size]\n",
    "        \n",
    "        # Apply relation attention\n",
    "        attention_mask_expanded = attention_mask.unsqueeze(-1)  # [batch_size, seq_len, 1]\n",
    "        \n",
    "        # Calculate relation-aware attention weights\n",
    "        relation_keys = self.relation_key(sequence_output)  # [batch_size, seq_len, hidden_size]\n",
    "        query = self.relation_query.unsqueeze(0).expand(input_ids.size(0), -1, -1)  # [batch_size, hidden_size, 1]\n",
    "        \n",
    "        # Get attention scores and mask padding tokens\n",
    "        attention_scores = torch.bmm(relation_keys, query)  # [batch_size, seq_len, 1]\n",
    "        attention_scores = attention_scores.masked_fill(attention_mask_expanded == 0, -10000.0)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)  # [batch_size, seq_len, 1]\n",
    "        \n",
    "        # Get relation-aware context vector\n",
    "        relation_values = self.relation_value(sequence_output)  # [batch_size, seq_len, hidden_size]\n",
    "        relation_context = torch.sum(attention_weights * relation_values, dim=1)  # [batch_size, hidden_size]\n",
    "        \n",
    "        # Combine CLS token with relation context\n",
    "        pooled_output = torch.cat([cls_token, relation_context], dim=1)  # [batch_size, hidden_size*2]\n",
    "        pooled_output = self.dropout1(pooled_output)\n",
    "        \n",
    "        # Classification\n",
    "        intermediate = self.intermediate(pooled_output)\n",
    "        intermediate = self.activation(intermediate)\n",
    "        intermediate = self.dropout2(intermediate)\n",
    "        logits = self.classifier(intermediate)\n",
    "        \n",
    "        return logits, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76303bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 18: Enhanced Multi-Task Model \n",
    "class EnhancedPolarityPubMedBERTClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced multi-task PubMedBERT classifier with relation-aware attention mechanism.\n",
    "    \n",
    "    This model performs two tasks:\n",
    "    1. Mechanism detection (multi-label classification)\n",
    "    2. Polarity classification (single-label classification)\n",
    "    \n",
    "    The enhancement includes a relation attention mechanism that helps the model\n",
    "    focus on tokens that indicate regulatory relationships, improving detection\n",
    "    of implicit autoregulatory mechanisms.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_mech_classes, n_polarity_classes=3, dropout1=0.1, dropout2=0.2):\n",
    "        \"\"\"\n",
    "        Initialize the enhanced multi-task model\n",
    "        \n",
    "        Args:\n",
    "            n_mech_classes: Number of mechanism classes (e.g., 10 for autoactivation, etc.)\n",
    "            n_polarity_classes: Number of polarity classes (3: positive, negative, neutral)\n",
    "            dropout1: Dropout rate after BERT embeddings\n",
    "            dropout2: Dropout rate before final classifiers\n",
    "        \"\"\"\n",
    "        super(EnhancedPolarityPubMedBERTClassifier, self).__init__()\n",
    "        \n",
    "        # Load base PubMedBERT model\n",
    "        self.bert = AutoModel.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "        \n",
    "        # Relation-aware attention mechanism\n",
    "        # This helps the model focus on tokens that indicate regulatory relationships\n",
    "        self.relation_query = nn.Parameter(torch.randn(768, 1))  # Learnable query for relation detection\n",
    "        self.relation_key = nn.Linear(768, 768)     # Transform tokens to keys\n",
    "        self.relation_value = nn.Linear(768, 768)   # Transform tokens to values\n",
    "        \n",
    "        # Shared feature processing layers\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        # Note: Input size is doubled (768 * 2) because we concatenate CLS token + relation context\n",
    "        self.intermediate = nn.Linear(768 * 2, 512)  \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        # Mechanism classification branch (multi-label)\n",
    "        self.dropout2_mech = nn.Dropout(dropout2)\n",
    "        self.classifier_mech = nn.Linear(512, n_mech_classes)\n",
    "        \n",
    "        # Polarity classification branch (single-label)\n",
    "        self.dropout2_pol = nn.Dropout(dropout2)\n",
    "        self.classifier_pol = nn.Linear(512, n_polarity_classes)\n",
    "        \n",
    "        # Initialize weights using Xavier normal initialization\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize model weights properly\"\"\"\n",
    "        nn.init.xavier_normal_(self.intermediate.weight)\n",
    "        nn.init.zeros_(self.intermediate.bias)\n",
    "        nn.init.xavier_normal_(self.classifier_mech.weight)\n",
    "        nn.init.zeros_(self.classifier_mech.bias)\n",
    "        nn.init.xavier_normal_(self.classifier_pol.weight)\n",
    "        nn.init.zeros_(self.classifier_pol.bias)\n",
    "        nn.init.xavier_normal_(self.relation_key.weight)\n",
    "        nn.init.xavier_normal_(self.relation_value.weight)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Forward pass through the enhanced multi-task model\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Token IDs from tokenizer [batch_size, seq_len]\n",
    "            attention_mask: Attention mask [batch_size, seq_len]\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (mechanism_logits, polarity_logits, attention_weights)\n",
    "        \"\"\"\n",
    "        # Get PubMedBERT embeddings\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract sequence outputs and CLS token\n",
    "        sequence_output = outputs.last_hidden_state  # [batch_size, seq_len, 768]\n",
    "        cls_token = sequence_output[:, 0, :]         # [batch_size, 768]\n",
    "        \n",
    "        # Apply relation-aware attention mechanism\n",
    "        attention_weights = self._compute_relation_attention(sequence_output, attention_mask)\n",
    "        relation_context = self._get_relation_context(sequence_output, attention_weights)\n",
    "        \n",
    "        # Combine CLS token with relation context\n",
    "        # This gives the model both global (CLS) and relation-specific information\n",
    "        combined_features = torch.cat([cls_token, relation_context], dim=1)  # [batch_size, 768*2]\n",
    "        combined_features = self.dropout1(combined_features)\n",
    "        \n",
    "        # Shared intermediate representation\n",
    "        shared_features = self.activation(self.intermediate(combined_features))  # [batch_size, 512]\n",
    "        \n",
    "        # Mechanism prediction branch (multi-label)\n",
    "        mech_features = self.dropout2_mech(shared_features)\n",
    "        mech_logits = self.classifier_mech(mech_features)  # [batch_size, n_mech_classes]\n",
    "        \n",
    "        # Polarity prediction branch (single-label)\n",
    "        pol_features = self.dropout2_pol(shared_features)\n",
    "        pol_logits = self.classifier_pol(pol_features)     # [batch_size, n_polarity_classes]\n",
    "        \n",
    "        return mech_logits, pol_logits, attention_weights\n",
    "    \n",
    "    def _compute_relation_attention(self, sequence_output, attention_mask):\n",
    "        \"\"\"\n",
    "        Compute attention weights for relation detection\n",
    "        \n",
    "        Args:\n",
    "            sequence_output: BERT sequence outputs [batch_size, seq_len, 768]\n",
    "            attention_mask: Attention mask [batch_size, seq_len]\n",
    "            \n",
    "        Returns:\n",
    "            attention_weights: Attention weights [batch_size, seq_len, 1]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = attention_mask.shape\n",
    "        \n",
    "        # Transform sequence to keys for attention computation\n",
    "        relation_keys = self.relation_key(sequence_output)  # [batch_size, seq_len, 768]\n",
    "        \n",
    "        # Expand the learnable query to match batch size\n",
    "        query = self.relation_query.unsqueeze(0).expand(batch_size, -1, -1)  # [batch_size, 768, 1]\n",
    "        \n",
    "        # Compute attention scores using query-key dot product\n",
    "        attention_scores = torch.bmm(relation_keys, query)  # [batch_size, seq_len, 1]\n",
    "        \n",
    "        # Mask padding tokens by setting their attention scores to very low values\n",
    "        attention_mask_expanded = attention_mask.unsqueeze(-1)  # [batch_size, seq_len, 1]\n",
    "        attention_scores = attention_scores.masked_fill(attention_mask_expanded == 0, -10000.0)\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)  # [batch_size, seq_len, 1]\n",
    "        \n",
    "        return attention_weights\n",
    "    \n",
    "    def _get_relation_context(self, sequence_output, attention_weights):\n",
    "        \"\"\"\n",
    "        Get weighted context vector using attention weights\n",
    "        \n",
    "        Args:\n",
    "            sequence_output: BERT sequence outputs [batch_size, seq_len, 768]\n",
    "            attention_weights: Attention weights [batch_size, seq_len, 1]\n",
    "            \n",
    "        Returns:\n",
    "            relation_context: Weighted context vector [batch_size, 768]\n",
    "        \"\"\"\n",
    "        # Transform sequence to values\n",
    "        relation_values = self.relation_value(sequence_output)  # [batch_size, seq_len, 768]\n",
    "        \n",
    "        # Compute weighted sum using attention weights\n",
    "        relation_context = torch.sum(attention_weights * relation_values, dim=1)  # [batch_size, 768]\n",
    "        \n",
    "        return relation_context\n",
    "    \n",
    "    def get_attention_weights(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Get attention weights for visualization (inference only)\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Token IDs [batch_size, seq_len]\n",
    "            attention_mask: Attention mask [batch_size, seq_len]\n",
    "            \n",
    "        Returns:\n",
    "            attention_weights: Attention weights [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            sequence_output = outputs.last_hidden_state\n",
    "            attention_weights = self._compute_relation_attention(sequence_output, attention_mask)\n",
    "            return attention_weights.squeeze(-1)  # Remove last dimension [batch_size, seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ef3f3",
   "metadata": {},
   "source": [
    "# 5. TRAINING AND EVALUATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "253a0043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Data Loader Creation Functions\n",
    "def create_moderate_sampler(y):\n",
    "    \"\"\"\n",
    "    Create a weighted sampler with moderate class balancing\n",
    "    \"\"\"\n",
    "    class_sample_count = np.sum(y, axis=0)\n",
    "    # Square root scaling makes weights less extreme\n",
    "    weight_per_class = 1.0 / np.sqrt(np.clip(class_sample_count, 5, np.inf))\n",
    "    \n",
    "    sample_weights = np.zeros(len(y))\n",
    "    for i in range(len(y)):\n",
    "        if np.sum(y[i]) > 0:\n",
    "            positive_indices = np.where(y[i] == 1)[0]\n",
    "            sample_weights[i] = np.mean(weight_per_class[positive_indices])\n",
    "        else:\n",
    "            # Give negative examples lower weight (they're 67% of dataset)\n",
    "            sample_weights[i] = 0.5 / max(1, (len(y) - np.sum(np.any(y, axis=1))))\n",
    "    \n",
    "    sample_weights = torch.FloatTensor(sample_weights)\n",
    "    return WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "# Create data loader\n",
    "def create_dataset_and_loader(X, y, batch_size, tokenizer, train=True, polarities=None):\n",
    "    dataset = PubMedDataset(X, y, tokenizer, polarities=polarities)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=train)\n",
    "    return loader\n",
    "\n",
    "# Create data loader with polarity\n",
    "def create_dataset_and_loader_with_polarity(X, y, polarities, batch_size, tokenizer, train=True):\n",
    "    dataset = PubMedDataset(X, y, tokenizer, polarities=polarities)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=train)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36fd6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 19: Training Functions\n",
    "def train_epoch(model, data_loader, optimizer, criterion, scheduler=None, has_polarity=False):\n",
    "    \"\"\"\n",
    "    Train the model for a single epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model to train\n",
    "        data_loader: DataLoader containing the training data\n",
    "        optimizer: Optimizer for updating model weights\n",
    "        criterion: Loss function\n",
    "        scheduler: Optional learning rate scheduler\n",
    "        has_polarity: Whether the model includes polarity prediction\n",
    "        \n",
    "    Returns:\n",
    "        Average loss value for the epoch (and component losses if multi-task)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_mech_loss = 0\n",
    "    total_pol_loss = 0\n",
    "    total_batches = 0\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        try:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            mech_labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if has_polarity:\n",
    "                pol_labels = batch['polarity'].to(device)\n",
    "                mech_logits, pol_logits = model(input_ids, attention_mask)\n",
    "                loss, mech_loss, pol_loss = criterion(mech_logits, pol_logits, mech_labels, pol_labels)\n",
    "                total_mech_loss += mech_loss.item()\n",
    "                total_pol_loss += pol_loss.item()\n",
    "            else:\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                loss = criterion(outputs, mech_labels)\n",
    "            \n",
    "            # Check for NaN loss\n",
    "            if torch.isnan(loss):\n",
    "                print(\"WARNING: NaN loss detected, skipping batch\")\n",
    "                continue\n",
    "                \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            \n",
    "            # Update progress bar\n",
    "            if has_polarity:\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f\"{loss.item():.4f}\",\n",
    "                    'mech_loss': f\"{mech_loss.item():.4f}\",\n",
    "                    'pol_loss': f\"{pol_loss.item():.4f}\"\n",
    "                })\n",
    "            else:\n",
    "                progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch processing: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Protect against division by zero\n",
    "    if total_batches == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    if has_polarity:\n",
    "        return (\n",
    "            total_loss / total_batches,\n",
    "            total_mech_loss / total_batches,\n",
    "            total_pol_loss / total_batches\n",
    "        )\n",
    "    else:\n",
    "        return total_loss / total_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2cd9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 20: Evaluation Functions  \n",
    "def optimize_thresholds(model, val_loader, n_labels, has_polarity=False):\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Optimizing thresholds\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            if has_polarity:\n",
    "                model_outputs = model(input_ids, attention_mask)\n",
    "                if len(model_outputs) == 3:  # Enhanced model\n",
    "                    outputs, _, _ = model_outputs\n",
    "                else:  # Regular multi-task model\n",
    "                    outputs, _ = model_outputs\n",
    "            else:\n",
    "                model_outputs = model(input_ids, attention_mask)\n",
    "                if isinstance(model_outputs, tuple):  # Enhanced single-task model\n",
    "                    outputs, _ = model_outputs\n",
    "                else:  # Regular single-task model\n",
    "                    outputs = model_outputs\n",
    "                \n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            \n",
    "            all_outputs.append(probs)\n",
    "            all_labels.append(labels.numpy())\n",
    "    \n",
    "    all_outputs = np.vstack(all_outputs)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    optimal_thresholds = []\n",
    "    \n",
    "    for i in range(n_labels):\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in np.arange(0.3, 0.7, 0.05):\n",
    "            preds = (all_outputs[:, i] >= threshold).astype(int)\n",
    "            f1 = f1_score(all_labels[:, i], preds, zero_division=0)\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        optimal_thresholds.append(best_threshold)\n",
    "        \n",
    "    return optimal_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "544f7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_multi_task(model, data_loader, mech_criterion, pol_criterion, thresholds):\n",
    "    \"\"\"\n",
    "    Evaluate a multi-task model on mechanism detection and polarity classification\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_mech_loss = 0\n",
    "    total_pol_loss = 0\n",
    "    all_mech_preds = []\n",
    "    all_mech_labels = []\n",
    "    all_pol_preds = []\n",
    "    all_pol_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            mech_labels = batch['labels'].to(device)\n",
    "            pol_labels = batch['polarity'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            if len(outputs) == 3:  # Enhanced model returns (mech_logits, pol_logits, attention_weights)\n",
    "                mech_logits, pol_logits, _ = outputs\n",
    "            else:  # Regular model returns (mech_logits, pol_logits)\n",
    "                mech_logits, pol_logits = outputs\n",
    "            \n",
    "            # Calculate losses\n",
    "            mech_loss = mech_criterion(mech_logits, mech_labels)\n",
    "            pol_loss = pol_criterion(pol_logits, pol_labels)\n",
    "            loss = 0.7 * mech_loss + 0.3 * pol_loss\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_mech_loss += mech_loss.item()\n",
    "            total_pol_loss += pol_loss.item()\n",
    "            \n",
    "            # Process mechanism predictions\n",
    "            mech_probs = torch.sigmoid(mech_logits).cpu().numpy()\n",
    "            mech_preds = np.array([\n",
    "                (mech_probs[:, i] >= thresholds[i]).astype(int) for i in range(len(thresholds))\n",
    "            ]).T\n",
    "            all_mech_preds.extend(mech_preds)\n",
    "            all_mech_labels.extend(mech_labels.cpu().numpy())\n",
    "            \n",
    "            # Process polarity predictions\n",
    "            pol_preds = torch.argmax(pol_logits, dim=1).cpu().numpy()\n",
    "            all_pol_preds.extend(pol_preds)\n",
    "            all_pol_labels.extend(pol_labels.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    if all_mech_preds and all_mech_labels:\n",
    "        all_mech_preds = np.array(all_mech_preds)\n",
    "        all_mech_labels = np.array(all_mech_labels)\n",
    "    else:\n",
    "        return {'loss': float('inf')}\n",
    "    \n",
    "    all_pol_preds = np.array(all_pol_preds)\n",
    "    all_pol_labels = np.array(all_pol_labels)\n",
    "    \n",
    "    # Calculate mechanism metrics\n",
    "    mech_metrics = calculate_mechanism_metrics(all_mech_labels, all_mech_preds)\n",
    "    \n",
    "    # Calculate polarity metrics\n",
    "    pol_accuracy = accuracy_score(all_pol_labels, all_pol_preds)\n",
    "    pol_f1 = f1_score(all_pol_labels, all_pol_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Combine metrics\n",
    "    metrics = {\n",
    "        'loss': total_loss / len(data_loader),\n",
    "        'mech_loss': total_mech_loss / len(data_loader),\n",
    "        'pol_loss': total_pol_loss / len(data_loader),\n",
    "        'pol_accuracy': pol_accuracy,\n",
    "        'pol_f1': pol_f1,\n",
    "        **mech_metrics\n",
    "    }\n",
    "    \n",
    "    # Output results\n",
    "    print(f\"Loss: {metrics['loss']:.4f} | Mech Loss: {metrics['mech_loss']:.4f} | Pol Loss: {metrics['pol_loss']:.4f}\")\n",
    "    print(f\"Mechanism - Micro F1: {metrics['micro_f1']:.4f} | Macro F1: {metrics['macro_f1']:.4f} | Weighted F1: {metrics['weighted_f1']:.4f}\")\n",
    "    print(f\"Polarity - Accuracy: {metrics['pol_accuracy']:.4f} | F1: {metrics['pol_f1']:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "070cb4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mechanism_metrics(all_labels, all_predictions):\n",
    "    \"\"\"Helper function to calculate mechanism classification metrics\"\"\"\n",
    "    samples_precision = precision_score(all_labels, all_predictions, average='samples', zero_division=0)\n",
    "    samples_recall = recall_score(all_labels, all_predictions, average='samples', zero_division=0)\n",
    "    samples_f1 = f1_score(all_labels, all_predictions, average='samples', zero_division=0)\n",
    "\n",
    "    # F1 metrics\n",
    "    micro_f1 = f1_score(all_labels, all_predictions, average='micro', zero_division=0)\n",
    "    macro_f1 = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "    weighted_f1 = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'micro_f1': micro_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'weighted_f1': weighted_f1,\n",
    "        'samples_f1': samples_f1,\n",
    "        'samples_precision': samples_precision,\n",
    "        'samples_recall': samples_recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18979045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion, thresholds):\n",
    "    \"\"\"\n",
    "    Evaluate single-task model on mechanism detection\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Get predictions using thresholds\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            preds = np.array([\n",
    "                (probs[:, i] >= thresholds[i]).astype(int) for i in range(len(thresholds))\n",
    "            ]).T\n",
    "            \n",
    "            all_predictions.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    if all_predictions and all_labels:\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_labels = np.array(all_labels)\n",
    "    else:\n",
    "        return {'loss': float('inf')}\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_mechanism_metrics(all_labels, all_predictions)\n",
    "    metrics['loss'] = total_loss / len(data_loader)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Loss: {metrics['loss']:.4f} | Micro F1: {metrics['micro_f1']:.4f} | Macro F1: {metrics['macro_f1']:.4f} | Weighted F1: {metrics['weighted_f1']:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2b6b5",
   "metadata": {},
   "source": [
    "# 6. MAIN TRAINING PIPE LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a468d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Instantiate the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "262fbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: Main Training Function\n",
    "def train_model_multitask(batch_number, n_epochs, learning_rate, batch_size, use_optimal_thresholds=True):\n",
    "    \"\"\"\n",
    "    Train a multi-task model for both mechanism detection and polarity classification\n",
    "    \"\"\"\n",
    "    print(f\"\\nTraining multi-task model on batch {batch_number}\")\n",
    "    \n",
    "    # Load and preprocess test data\n",
    "    print(\"Loading test data...\")\n",
    "    test_data = pd.read_csv('../data/processed/test_data.csv')\n",
    "    \n",
    "    # Apply same preprocessing to test data\n",
    "    if 'Text_combined' not in test_data.columns:\n",
    "        # Find available text column\n",
    "        text_columns = [col for col in test_data.columns if 'text' in col.lower()]\n",
    "        if text_columns:\n",
    "            test_data['Text_combined'] = test_data[text_columns[0]].fillna('')\n",
    "        else:\n",
    "            raise ValueError(\"No text column found in test data\")\n",
    "    \n",
    "    test_data['Text_Cleaned'] = test_data['Text_combined'].apply(preprocess_text)\n",
    "    \n",
    "    # Process test data mechanism labels\n",
    "    test_data['Terms_List'] = test_data['Terms'].apply(\n",
    "        lambda x: [term.strip() for term in str(x).split(',')] if pd.notna(x) and x != '' else []\n",
    "    )\n",
    "    test_mech_labels = mlb.transform(test_data['Terms_List'])  # Use same mlb as training\n",
    "    \n",
    "    # FIXED: Add polarity labels to test data\n",
    "    print(\"Processing test data polarity...\")\n",
    "    test_polarities = []\n",
    "    for idx, row in test_data.iterrows():\n",
    "        text = row['Text_Cleaned'] if pd.notna(row['Text_Cleaned']) else \"\"\n",
    "        mechanisms = row['Terms_List']\n",
    "        polarity = infer_polarity(text, mechanisms)\n",
    "        test_polarities.append(polarity)\n",
    "    \n",
    "    # Encode polarity labels for test data\n",
    "    test_polarity_encoded = polarity_encoder.transform(test_polarities)\n",
    "    \n",
    "    # Filter training data for the specified batch\n",
    "    batch_data = df_cleaned[df_cleaned['batch_number'] == batch_number].copy()\n",
    "    if len(batch_data) == 0:\n",
    "        print(f\"No data found for batch {batch_number}\")\n",
    "        return None, 0\n",
    "        \n",
    "    print(f\"Batch {batch_number} data: {len(batch_data)} samples\")\n",
    "    \n",
    "    # FIXED: Prepare features and labels for MULTI-TASK training\n",
    "    X_train = batch_data['Text_Cleaned']\n",
    "    y_train_mech = batch_data[label_columns].values  # Mechanism labels\n",
    "    y_train_polarity = batch_data['polarity_encoded'].values  # Polarity labels\n",
    "    \n",
    "    # Prepare test data\n",
    "    X_test = test_data['Text_Cleaned']\n",
    "    y_test_mech = test_mech_labels\n",
    "    y_test_polarity = test_polarity_encoded\n",
    "    \n",
    "    print(f\"Train set: {len(X_train)} samples\")\n",
    "    print(f\"Test set: {len(X_test)} samples\")\n",
    "    print(f\"Mechanism classes: {len(label_columns)}\")\n",
    "    print(f\"Polarity classes: {len(POLARITY_LABELS)}\")\n",
    "    \n",
    "    # FIXED: Create datasets WITH polarity labels\n",
    "    train_dataset = PubMedDataset(\n",
    "        X_train, y_train_mech, tokenizer, \n",
    "        polarities=y_train_polarity  # Include polarity labels\n",
    "    )\n",
    "    \n",
    "    test_dataset = PubMedDataset(\n",
    "        X_test, y_test_mech, tokenizer, \n",
    "        polarities=y_test_polarity  # Include polarity labels\n",
    "    )\n",
    "    \n",
    "    # Create balanced sampler for training\n",
    "    sampler = create_moderate_sampler(y_train_mech)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Calculate class weights for mechanism detection\n",
    "    print(\"Calculating class weights...\")\n",
    "    mech_pos_weights = []\n",
    "    for i in range(y_train_mech.shape[1]):\n",
    "        neg_count = len(y_train_mech) - np.sum(y_train_mech[:, i])\n",
    "        pos_count = np.sum(y_train_mech[:, i])\n",
    "        weight = neg_count / pos_count if pos_count > 0 else 1.0\n",
    "        weight = min(max(weight, 0.1), 10.0)  # Clip between 0.1 and 10\n",
    "        mech_pos_weights.append(weight)\n",
    "    \n",
    "    mech_pos_weights = torch.FloatTensor(mech_pos_weights).to(device)\n",
    "    \n",
    "    # FIXED: Initialize MULTI-TASK model\n",
    "    print(\"Initializing multi-task model...\")\n",
    "    model = PolarityPubMedBERTClassifier(\n",
    "        n_mech_classes=len(label_columns),\n",
    "        n_polarity_classes=len(POLARITY_LABELS)\n",
    "    ).to(device)\n",
    "    \n",
    "    # FIXED: Set up MULTI-TASK loss functions and optimizer\n",
    "    criterion = MultiTaskLoss(mech_pos_weights, mech_weight=0.7, pol_weight=0.3)\n",
    "    mech_criterion = CombinedLoss(mech_pos_weights)  # For evaluation\n",
    "    pol_criterion = nn.CrossEntropyLoss()  # For evaluation\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    # Set up scheduler with warmup\n",
    "    total_steps = len(train_loader) * n_epochs\n",
    "    warmup_steps = int(total_steps * 0.1)  # 10% warmup\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Initialize thresholds and tracking\n",
    "    initial_thresholds = [0.5] * len(label_columns)\n",
    "    best_combined_score = 0.0  # Changed from best_f1\n",
    "    all_metrics = {\n",
    "        'train_loss': [], 'train_mech_loss': [], 'train_pol_loss': [],\n",
    "        'test_loss': [], 'test_mech_loss': [], 'test_pol_loss': [],\n",
    "        'micro_f1': [], 'macro_f1': [], 'weighted_f1': [],\n",
    "        'pol_accuracy': [], 'pol_f1': []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    print(f\"Starting training for {n_epochs} epochs...\")\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{n_epochs}\")\n",
    "        \n",
    "        # FIXED: Train with multi-task approach\n",
    "        train_losses = train_epoch(\n",
    "            model, train_loader, optimizer, criterion, scheduler, has_polarity=True\n",
    "        )\n",
    "        \n",
    "        # Unpack training losses\n",
    "        if isinstance(train_losses, tuple):\n",
    "            train_loss, train_mech_loss, train_pol_loss = train_losses\n",
    "            print(f\"Training - Total: {train_loss:.4f}, Mech: {train_mech_loss:.4f}, Pol: {train_pol_loss:.4f}\")\n",
    "        else:\n",
    "            train_loss = train_losses\n",
    "            train_mech_loss = train_pol_loss = 0.0\n",
    "            print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        \n",
    "        # Store training metrics\n",
    "        all_metrics['train_loss'].append(train_loss)\n",
    "        all_metrics['train_mech_loss'].append(train_mech_loss)\n",
    "        all_metrics['train_pol_loss'].append(train_pol_loss)\n",
    "        \n",
    "        # Optimize thresholds after first epoch\n",
    "        thresholds = initial_thresholds\n",
    "        if use_optimal_thresholds and epoch >= 1:\n",
    "            try:\n",
    "                print(\"Optimizing thresholds...\")\n",
    "                thresholds = optimize_thresholds(model, test_loader, len(label_columns), has_polarity=True)\n",
    "                print(f\"Optimized thresholds: {[f'{t:.2f}' for t in thresholds]}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error optimizing thresholds: {e}\")\n",
    "                print(\"Using default thresholds\")\n",
    "        \n",
    "        # FIXED: Evaluate with multi-task function\n",
    "        print(\"Evaluating model...\")\n",
    "        metrics = evaluate_multi_task(model, test_loader, mech_criterion, pol_criterion, thresholds)\n",
    "        \n",
    "        if metrics and 'loss' in metrics:\n",
    "            # Store evaluation metrics\n",
    "            for key in ['loss', 'mech_loss', 'pol_loss', 'micro_f1', 'macro_f1', 'weighted_f1', 'pol_accuracy', 'pol_f1']:\n",
    "                if key in metrics:\n",
    "                    metric_key = f\"test_{key}\" if key in ['loss', 'mech_loss', 'pol_loss'] else key\n",
    "                    all_metrics[metric_key].append(metrics[key])\n",
    "            \n",
    "            # FIXED: Calculate combined score (mechanism F1 + polarity accuracy)\n",
    "            current_mech_f1 = metrics.get('weighted_f1', 0)\n",
    "            current_pol_acc = metrics.get('pol_accuracy', 0)\n",
    "            combined_score = 0.7 * current_mech_f1 + 0.3 * current_pol_acc\n",
    "            \n",
    "            print(f\"Combined Score: {combined_score:.4f} (Mech F1: {current_mech_f1:.4f}, Pol Acc: {current_pol_acc:.4f})\")\n",
    "            \n",
    "            # Save best model\n",
    "            if combined_score > best_combined_score:\n",
    "                best_combined_score = combined_score\n",
    "                \n",
    "                # Create model directory\n",
    "                model_dir = f\"model/batch_{batch_number}\"\n",
    "                os.makedirs(model_dir, exist_ok=True)\n",
    "                \n",
    "                # Save model state\n",
    "                model_path = os.path.join(model_dir, \"best_model.pt\")\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"New best model saved: {model_path}\")\n",
    "                \n",
    "                # Save thresholds\n",
    "                thresholds_path = f\"{model_dir}/best_thresholds.json\"\n",
    "                with open(thresholds_path, \"w\") as f:\n",
    "                    json.dump(thresholds, f)\n",
    "                print(f\"Thresholds saved: {thresholds_path}\")\n",
    "        else:\n",
    "            print(\"Warning: Evaluation returned invalid metrics\")\n",
    "    \n",
    "    # Save training metrics\n",
    "    metrics_path = f\"results/metrics_batch_{batch_number}.json\"\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(all_metrics, f)\n",
    "    print(f\"Training metrics saved: {metrics_path}\")\n",
    "    \n",
    "    return model, best_combined_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94b1bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training multi-task model on batch 1\n",
      "Loading test data...\n",
      "Processing test data polarity...\n",
      "Batch 1 data: 5241 samples\n",
      "Train set: 5241 samples\n",
      "Test set: 20 samples\n",
      "Mechanism classes: 10\n",
      "Polarity classes: 3\n",
      "Calculating class weights...\n",
      "Initializing multi-task model...\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1311 [00:09<19:46,  1.10it/s, loss=1.2448, mech_loss=1.3503, pol_loss=0.9985]"
     ]
    }
   ],
   "source": [
    "# Simple Single Batch Training\n",
    "# Train just batch 1 for testing\n",
    "\n",
    "model, score = train_model_multitask(\n",
    "    batch_number=1,\n",
    "    n_epochs=n_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    use_optimal_thresholds=True\n",
    ")\n",
    "\n",
    "print(f\"Done! Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d389799f",
   "metadata": {},
   "source": [
    "### training for all: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62215b1d",
   "metadata": {},
   "source": [
    "\n",
    "# Cell 22: Batch Training Loop\n",
    "batch_numbers = df_cleaned['batch_number'].unique()\n",
    "print(f\"Found {len(batch_numbers)} batches: {batch_numbers}\")\n",
    "\n",
    "# Train multi-task models for all batches\n",
    "for batch_num in batch_numbers:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"STARTING TRAINING FOR BATCH {batch_num}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    model, combined_score = train_model_multitask( \n",
    "        batch_number=batch_num,\n",
    "        n_epochs=n_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        use_optimal_thresholds=True\n",
    "    )\n",
    "    \n",
    "    if model is not None:\n",
    "        print(f\"\\n Batch {batch_num} training complete. Best Combined Score: {combined_score:.4f}\")\n",
    "    else:\n",
    "        print(f\"\\n Batch {batch_num} training failed - no data found\")\n",
    "\n",
    "print(f\"\\n ALL BATCH TRAINING COMPLETE!\")\n",
    "print(f\"Trained models for {len(batch_numbers)} batches\")\n",
    "print(f\"Models saved in: model/batch_X/ directories\")\n",
    "print(f\"Metrics saved in: results/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c3f190",
   "metadata": {},
   "source": [
    "# SECTION 7: ENHANCED MODEL PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f080dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 29: Enhanced Model Conversion and Fine-tuning\n",
    "# Cell 29: Fixed Enhanced Multi-Task Model Conversion and Fine-tuning\n",
    "\n",
    "def convert_to_enhanced_multitask_model(original_model_path):\n",
    "    \"\"\"\n",
    "    Load the existing multi-task model and convert it to the enhanced multi-task model\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load label columns\n",
    "    try:\n",
    "        with open('label_columns.json', 'r') as f:\n",
    "            label_columns = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Label columns file not found. Using default labels.\")\n",
    "        label_columns = [\n",
    "            'autoactivation', 'autocatalysis', 'autofeedback', 'autoinduction', \n",
    "            'autoinhibition', 'autokinase', 'autolysis', 'autophosphorylation', \n",
    "            'autoregulation', 'autoubiquitination'\n",
    "        ]\n",
    "    \n",
    "    # Load polarity labels\n",
    "    try:\n",
    "        with open('polarity_labels.json', 'r') as f:\n",
    "            polarity_labels = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Polarity labels file not found. Using default labels.\")\n",
    "        polarity_labels = ['negative', 'neutral', 'positive']\n",
    "    \n",
    "    # FIXED: Load original MULTI-TASK model\n",
    "    original_model = PolarityPubMedBERTClassifier(\n",
    "        n_mech_classes=len(label_columns),\n",
    "        n_polarity_classes=len(polarity_labels)\n",
    "    ).to(device)\n",
    "    original_model.load_state_dict(torch.load(original_model_path, map_location=device))\n",
    "    print(\"Original multi-task model loaded successfully!\")\n",
    "    \n",
    "    # FIXED: Create enhanced MULTI-TASK model\n",
    "    enhanced_model = EnhancedPolarityPubMedBERTClassifier(\n",
    "        n_mech_classes=len(label_columns),\n",
    "        n_polarity_classes=len(polarity_labels)\n",
    "    ).to(device)\n",
    "    \n",
    "    # Transfer weights from original model to enhanced model\n",
    "    # 1. BERT weights (same for both models)\n",
    "    enhanced_model.bert.load_state_dict(original_model.bert.state_dict())\n",
    "    \n",
    "    # 2. Try to transfer compatible weights\n",
    "    try:\n",
    "        # Transfer shared intermediate layer weights if compatible\n",
    "        if (enhanced_model.intermediate.in_features == original_model.intermediate.in_features * 2 and\n",
    "            enhanced_model.intermediate.out_features == original_model.intermediate.out_features):\n",
    "            # Initialize the enhanced intermediate layer with original weights duplicated\n",
    "            with torch.no_grad():\n",
    "                # Duplicate the original weights for the doubled input size\n",
    "                original_weight = original_model.intermediate.weight\n",
    "                enhanced_weight = torch.cat([original_weight, original_weight], dim=1)\n",
    "                enhanced_model.intermediate.weight.copy_(enhanced_weight)\n",
    "                enhanced_model.intermediate.bias.copy_(original_model.intermediate.bias)\n",
    "            print(\"Transferred intermediate layer weights (duplicated for enhanced input)\")\n",
    "        \n",
    "        # Transfer mechanism classifier weights\n",
    "        enhanced_model.classifier_mech.load_state_dict(original_model.classifier_mech.state_dict())\n",
    "        print(\"Transferred mechanism classifier weights\")\n",
    "        \n",
    "        # Transfer polarity classifier weights  \n",
    "        enhanced_model.classifier_pol.load_state_dict(original_model.classifier_pol.state_dict())\n",
    "        print(\"Transferred polarity classifier weights\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not transfer all weights: {e}\")\n",
    "        print(\"Enhanced model will use randomly initialized weights for some layers\")\n",
    "    \n",
    "    print(\"Enhanced multi-task model created!\")\n",
    "    return enhanced_model, device, label_columns, polarity_labels\n",
    "\n",
    "\n",
    "def finetune_multitask_for_implicit_relations(model, batch_size=4, learning_rate=1e-5, epochs=3):\n",
    "    \"\"\"\n",
    "    Fine-tune the MULTI-TASK model to detect implicit relations using augmented examples\n",
    "    \"\"\"\n",
    "    # Set up tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    \n",
    "    # FIXED: Create examples with BOTH mechanism and polarity labels\n",
    "    implicit_examples = [\n",
    "        # Format: (text, mechanism_label, polarity_label)\n",
    "        (\"The transcription factor binds to its own promoter region.\", \"autoregulation\", \"neutral\"),\n",
    "        (\"The enzyme activates itself through conformational change.\", \"autoactivation\", \"positive\"),\n",
    "        (\"The protein phosphorylates itself on a tyrosine residue.\", \"autophosphorylation\", \"positive\"),\n",
    "        (\"The protease cleaves itself to generate the active form.\", \"autocatalysis\", \"positive\"),\n",
    "        (\"The cell produces molecules that signal itself to change behavior.\", \"autoinduction\", \"positive\"),\n",
    "        (\"The receptor signals to reduce its own expression level.\", \"autoinhibition\", \"negative\"),\n",
    "        (\"Upon binding ligand, the receptor undergoes a conformational change that enables phosphorylation of its cytoplasmic domain.\", \"autophosphorylation\", \"positive\"),\n",
    "        (\"The transcription factor negatively controls expression of its own gene.\", \"autoregulation\", \"negative\"),\n",
    "        (\"The kinase domain transfers phosphate groups to residues within the same protein.\", \"autophosphorylation\", \"positive\"),\n",
    "        (\"This bacterial system uses cell-to-cell signaling to coordinate population behavior.\", \"autoinduction\", \"positive\"),\n",
    "        (\"The peptide recognizes and binds specifically to the same protein it was derived from.\", \"autofeedback\", \"neutral\"),\n",
    "        (\"The dimeric protein activates by cross-phosphorylation between the two identical subunits.\", \"autoactivation\", \"positive\"),\n",
    "        (\"AGPCRs uniquely contain large, self-proteolyzing extracellular regions.\", \"autocatalysis\", \"positive\"),\n",
    "        (\"GAIN domain-mediated self-cleavage is constitutive and produces two-fragment holoreceptors.\", \"autocatalysis\", \"positive\"),\n",
    "        (\"The self-repression function of IbpA is conserved in other -proteobacterial IbpAs.\", \"autoinhibition\", \"negative\"),\n",
    "        (\"A cationic residue-rich region is critical for the self-suppression activity.\", \"autoinhibition\", \"negative\"),\n",
    "        (\"We propose a negative feedback loop, in which sphingosine inhibits GBA2 activity.\", \"autoinhibition\", \"negative\"),\n",
    "        (\"DNA damage-induced activation of p53 initiates a negative-feedback loop which rapidly downregulates RAG1 levels.\", \"autoregulation\", \"negative\")\n",
    "    ]\n",
    "    \n",
    "    # FIXED: Multi-task dataset class\n",
    "    class ImplicitMultiTaskDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, examples, tokenizer, max_length=512):\n",
    "            self.examples = examples\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "            \n",
    "            # Map mechanism labels to indices\n",
    "            self.mech_label_map = {\n",
    "                'autoactivation': 0, 'autocatalysis': 1, 'autofeedback': 2, 'autoinduction': 3,\n",
    "                'autoinhibition': 4, 'autokinase': 5, 'autolysis': 6, 'autophosphorylation': 7,\n",
    "                'autoregulation': 8, 'autoubiquitination': 9\n",
    "            }\n",
    "            \n",
    "            # Map polarity labels to indices\n",
    "            self.pol_label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.examples)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            text, mech_label, pol_label = self.examples[idx]\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # Create one-hot encoded mechanism label\n",
    "            mech_label_index = self.mech_label_map[mech_label]\n",
    "            mech_label_tensor = torch.zeros(len(self.mech_label_map))\n",
    "            mech_label_tensor[mech_label_index] = 1.0\n",
    "            \n",
    "            # Create polarity label\n",
    "            pol_label_index = self.pol_label_map[pol_label]\n",
    "            \n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                'mech_labels': mech_label_tensor,\n",
    "                'pol_labels': torch.LongTensor([pol_label_index]).squeeze()  # For CrossEntropyLoss\n",
    "            }\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = ImplicitMultiTaskDataset(implicit_examples, tokenizer)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Set up optimizer and loss functions\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    mech_criterion = nn.BCEWithLogitsLoss()\n",
    "    pol_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_mech_loss = 0\n",
    "        total_pol_loss = 0\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            # Get batch data\n",
    "            input_ids = batch['input_ids'].to(model.bert.device)\n",
    "            attention_mask = batch['attention_mask'].to(model.bert.device)\n",
    "            mech_labels = batch['mech_labels'].to(model.bert.device)\n",
    "            pol_labels = batch['pol_labels'].to(model.bert.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            mech_logits, pol_logits, attention_weights = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Calculate losses\n",
    "            mech_loss = mech_criterion(mech_logits, mech_labels)\n",
    "            pol_loss = pol_criterion(pol_logits, pol_labels)\n",
    "            total_loss_batch = 0.7 * mech_loss + 0.3 * pol_loss\n",
    "            \n",
    "            total_loss += total_loss_batch.item()\n",
    "            total_mech_loss += mech_loss.item()\n",
    "            total_pol_loss += pol_loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss_batch.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_mech_loss = total_mech_loss / len(dataloader)\n",
    "        avg_pol_loss = total_pol_loss / len(dataloader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Total: {avg_loss:.4f}, Mech: {avg_mech_loss:.4f}, Pol: {avg_pol_loss:.4f}\")\n",
    "    \n",
    "    print(\"Multi-task fine-tuning complete!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75137fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 30: Enhanced Model Training Pipeline\n",
    "# Cell 30: Fixed Enhanced Multi-Task Model Training Pipeline\n",
    "\n",
    "def enhance_and_test_multitask_model(batch_number=1):\n",
    "    \"\"\"\n",
    "    Convert the original multi-task model to enhanced version, fine-tune it, and test it\n",
    "    \n",
    "    Args:\n",
    "        batch_number: The batch number to use for loading the original model\n",
    "    \"\"\"\n",
    "    # Step 1: Convert existing multi-task model to enhanced multi-task model\n",
    "    model_path = os.path.join(MODEL_DIR, f\"batch_{batch_number}\", \"best_model.pt\")\n",
    "    thresholds_path = os.path.join(MODEL_DIR, f\"batch_{batch_number}\", \"best_thresholds.json\")\n",
    "    \n",
    "    print(f\"Enhancing multi-task model from batch {batch_number}...\")\n",
    "    \n",
    "    # FIXED: Use multi-task conversion function\n",
    "    enhanced_model, device, label_columns, polarity_labels = convert_to_enhanced_multitask_model(model_path)\n",
    "    \n",
    "    # Step 2: Fine-tune for implicit relations\n",
    "    print(\"Fine-tuning for implicit relations...\")\n",
    "    enhanced_model = finetune_multitask_for_implicit_relations(\n",
    "        enhanced_model, batch_size=4, learning_rate=1e-5, epochs=3\n",
    "    )\n",
    "    \n",
    "    # Step 3: Load thresholds (or use defaults)\n",
    "    try:\n",
    "        with open(thresholds_path, 'r') as f:\n",
    "            thresholds = json.load(f)\n",
    "        print(\"Thresholds loaded successfully!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Thresholds file not found at {thresholds_path}. Using default threshold of 0.3.\")\n",
    "        thresholds = [0.3] * len(label_columns)  # Lower thresholds for higher sensitivity\n",
    "    \n",
    "    # Step 4: Save the enhanced model\n",
    "    enhanced_model_dir = os.path.join(MODEL_DIR, \"enhanced\")\n",
    "    os.makedirs(enhanced_model_dir, exist_ok=True)\n",
    "    enhanced_model_path = os.path.join(enhanced_model_dir, f\"enhanced_multitask_model_batch_{batch_number}.pt\")\n",
    "    torch.save(enhanced_model.state_dict(), enhanced_model_path)\n",
    "    \n",
    "    # Save thresholds\n",
    "    enhanced_thresholds_path = os.path.join(enhanced_model_dir, f\"enhanced_thresholds_batch_{batch_number}.json\")\n",
    "    with open(enhanced_thresholds_path, 'w') as f:\n",
    "        json.dump(thresholds, f)\n",
    "    \n",
    "    # Save label mappings for inference\n",
    "    labels_info = {\n",
    "        'mechanism_labels': label_columns,\n",
    "        'polarity_labels': polarity_labels\n",
    "    }\n",
    "    labels_path = os.path.join(enhanced_model_dir, f\"enhanced_labels_batch_{batch_number}.json\")\n",
    "    with open(labels_path, 'w') as f:\n",
    "        json.dump(labels_info, f)\n",
    "    \n",
    "    print(f\"Enhanced model saved to {enhanced_model_path}\")\n",
    "    print(f\"Enhanced thresholds saved to {enhanced_thresholds_path}\")\n",
    "    print(f\"Label mappings saved to {labels_path}\")\n",
    "    \n",
    "    # Step 5: Test on implicit examples\n",
    "    implicit_test_examples = [\n",
    "        \"The protein binds to its own regulatory region, creating a negative feedback loop.\",\n",
    "        \"The enzyme can activate other copies of itself, creating a cascade effect.\",\n",
    "        \"Upon binding ligand, the receptor undergoes a conformational change that enables phosphorylation of its cytoplasmic domain.\",\n",
    "        \"The kinase domain transfers phosphate groups to residues within the same protein structure.\",\n",
    "        \"The transcription factor controls expression of its own gene, maintaining homeostasis.\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize tokenizer for testing\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING ENHANCED MODEL ON IMPLICIT EXAMPLES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test and visualize\n",
    "    for example_idx, text in enumerate(implicit_test_examples):\n",
    "        # Forward pass for predictions\n",
    "        enhanced_model.eval()\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # FIXED: Handle multi-task model outputs\n",
    "            mech_logits, pol_logits, attention_weights = enhanced_model(input_ids, attention_mask)\n",
    "            \n",
    "            # Get mechanism probabilities\n",
    "            mech_probabilities = torch.sigmoid(mech_logits).cpu().numpy()[0]\n",
    "            \n",
    "            # Get polarity predictions\n",
    "            pol_probabilities = torch.softmax(pol_logits, dim=1).cpu().numpy()[0]\n",
    "            pol_pred_idx = np.argmax(pol_probabilities)\n",
    "            pol_pred_label = polarity_labels[pol_pred_idx]\n",
    "            pol_confidence = pol_probabilities[pol_pred_idx]\n",
    "        \n",
    "        # Get mechanism predictions above threshold\n",
    "        mech_predictions = {}\n",
    "        for i, label in enumerate(label_columns):\n",
    "            if mech_probabilities[i] >= thresholds[i]:\n",
    "                mech_predictions[label] = float(mech_probabilities[i])\n",
    "        \n",
    "        # Extract attention for relation understanding\n",
    "        attention = attention_weights.squeeze().cpu().numpy()\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        attended_tokens = []\n",
    "        for i in range(1, min(len(tokens)-1, len(attention))):\n",
    "            if attention[i] > 0.05:  # Threshold for significant attention\n",
    "                attended_tokens.append((tokens[i], float(attention[i])))\n",
    "        \n",
    "        attended_tokens.sort(key=lambda x: x[1], reverse=True)\n",
    "        attended_tokens = attended_tokens[:5]  # Top 5 attended tokens\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nExample {example_idx + 1}: \\\"{text}\\\"\")\n",
    "        \n",
    "        # Mechanism predictions\n",
    "        if mech_predictions:\n",
    "            print(\"  Predicted autoregulatory mechanisms:\")\n",
    "            for label, prob in sorted(mech_predictions.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"    - {label}: {prob:.4f}\")\n",
    "        else:\n",
    "            print(\"  No autoregulatory mechanisms detected above threshold\")\n",
    "        \n",
    "        print(\"  Top 3 mechanism probabilities:\")\n",
    "        for label, prob in sorted(zip(label_columns, mech_probabilities), key=lambda x: x[1], reverse=True)[:3]:\n",
    "            print(f\"    - {label}: {prob:.4f}\")\n",
    "        \n",
    "        # FIXED: Polarity predictions\n",
    "        print(f\"  Predicted polarity: {pol_pred_label} (confidence: {pol_confidence:.4f})\")\n",
    "        print(\"  All polarity probabilities:\")\n",
    "        for i, (label, prob) in enumerate(zip(polarity_labels, pol_probabilities)):\n",
    "            print(f\"    - {label}: {prob:.4f}\")\n",
    "        \n",
    "        print(\"  Top attended tokens (relation clues):\")\n",
    "        for token, weight in attended_tokens:\n",
    "            print(f\"    - {token}: {weight:.4f}\")\n",
    "    \n",
    "    # FIXED: Add simple attention visualization (since visualize_attention might not be defined)\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"ATTENTION ANALYSIS FOR FIRST EXAMPLE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Analyze attention for the first example\n",
    "    text = implicit_test_examples[0]\n",
    "    encoding = tokenizer(text, add_special_tokens=True, return_tensors='pt')\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, _, attention_weights = enhanced_model(input_ids, attention_mask)\n",
    "        attention = attention_weights.squeeze().cpu().numpy()\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    print(\"\\nToken attention weights:\")\n",
    "    for i, (token, weight) in enumerate(zip(tokens[1:-1], attention[1:-1])):  # Skip [CLS] and [SEP]\n",
    "        if weight > 0.02:  # Only show significant attention\n",
    "            print(f\"  {token}: {weight:.4f}\")\n",
    "    \n",
    "    return enhanced_model, label_columns, polarity_labels, thresholds\n",
    "\n",
    "\n",
    "# Simple version to enhance just one batch\n",
    "def enhance_single_batch(batch_number=1):\n",
    "    \"\"\"\n",
    "    Simple function to enhance just one batch for testing\n",
    "    \"\"\"\n",
    "    print(f\"Enhancing batch {batch_number}...\")\n",
    "    enhanced_model, label_columns, polarity_labels, thresholds = enhance_and_test_multitask_model(batch_number)\n",
    "    print(f\" Batch {batch_number} enhancement complete!\")\n",
    "    return enhanced_model, label_columns, polarity_labels, thresholds\n",
    "\n",
    "\n",
    "# Enhanced version for all batches\n",
    "def enhance_all_batches():\n",
    "    \"\"\"\n",
    "    Enhance models for all batches\n",
    "    \"\"\"\n",
    "    batch_numbers = df_cleaned['batch_number'].unique()\n",
    "    results = {}\n",
    "    \n",
    "    for batch_num in batch_numbers:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ENHANCING MODEL FOR BATCH {batch_num}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            enhanced_model, label_columns, polarity_labels, thresholds = enhance_and_test_multitask_model(batch_num)\n",
    "            results[batch_num] = {\n",
    "                'model': enhanced_model,\n",
    "                'label_columns': label_columns,\n",
    "                'polarity_labels': polarity_labels,\n",
    "                'thresholds': thresholds\n",
    "            }\n",
    "            print(f\" Batch {batch_num} enhanced successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error enhancing batch {batch_num}: {e}\")\n",
    "            results[batch_num] = None\n",
    "    \n",
    "    print(f\"\\n Enhancement complete for all batches!\")\n",
    "    successful = sum(1 for r in results.values() if r is not None)\n",
    "    print(f\"Successfully enhanced: {successful}/{len(batch_numbers)} batches\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab53c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 31: Enhanced Model Inference\n",
    "\n",
    "class EnhancedMultiTaskPubMedBERTInference:\n",
    "    \"\"\"\n",
    "    Inference class for Enhanced Multi-Task PubMedBERT models\n",
    "    Handles both mechanism detection and polarity classification with attention visualization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, thresholds_path, labels_path):\n",
    "        \"\"\"\n",
    "        Initialize the inference class\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the saved enhanced multi-task model\n",
    "            thresholds_path: Path to the optimized thresholds JSON file\n",
    "            labels_path: Path to the labels JSON file (contains both mechanism and polarity labels)\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Load label mappings\n",
    "        with open(labels_path, 'r') as f:\n",
    "            labels_info = json.load(f)\n",
    "            self.mechanism_labels = labels_info['mechanism_labels']\n",
    "            self.polarity_labels = labels_info['polarity_labels']\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "        )\n",
    "        \n",
    "        # FIXED: Initialize MULTI-TASK enhanced model\n",
    "        self.model = EnhancedPolarityPubMedBERTClassifier(\n",
    "            n_mech_classes=len(self.mechanism_labels),\n",
    "            n_polarity_classes=len(self.polarity_labels)\n",
    "        )\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Load thresholds\n",
    "        with open(thresholds_path, 'r') as f:\n",
    "            self.thresholds = json.load(f)\n",
    "        \n",
    "        print(f\" Enhanced multi-task model loaded successfully!\")\n",
    "        print(f\" Mechanism classes: {len(self.mechanism_labels)}\")\n",
    "        print(f\" Polarity classes: {len(self.polarity_labels)}\")\n",
    "        print(f\" Device: {self.device}\")\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess text using the same method as training\n",
    "        \"\"\"\n",
    "        # Handle NaN values\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to string and lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Keep hyphens as they may be important in biomedical terms\n",
    "        text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        # Remove stopwords but keep important biomedical terms\n",
    "        text = \" \".join([word.strip() for word in text.split() if word not in stop_words or len(word) > 4])\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def predict(self, text, show_attention=True):\n",
    "        \"\"\"\n",
    "        Make predictions on input text\n",
    "        \n",
    "        Args:\n",
    "            text: Input text to classify\n",
    "            show_attention: Whether to extract and return attention weights\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing mechanism predictions, polarity predictions, and attention info\n",
    "        \"\"\"\n",
    "        processed_text = self.preprocess(text)\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            processed_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(self.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # FIXED: Handle multi-task model outputs\n",
    "            mech_logits, pol_logits, attention_weights = self.model(input_ids, attention_mask)\n",
    "            \n",
    "            # Get mechanism probabilities\n",
    "            mech_probabilities = torch.sigmoid(mech_logits).cpu().numpy()[0]\n",
    "            \n",
    "            # Get polarity predictions\n",
    "            pol_probabilities = torch.softmax(pol_logits, dim=1).cpu().numpy()[0]\n",
    "            pol_pred_idx = np.argmax(pol_probabilities)\n",
    "            pol_pred_label = self.polarity_labels[pol_pred_idx]\n",
    "            pol_confidence = pol_probabilities[pol_pred_idx]\n",
    "        \n",
    "        # Apply thresholds and get mechanism predictions\n",
    "        mech_predictions = {}\n",
    "        for i, label in enumerate(self.mechanism_labels):\n",
    "            if mech_probabilities[i] >= self.thresholds[i]:\n",
    "                mech_predictions[label] = float(mech_probabilities[i])\n",
    "        \n",
    "        # Get top 3 mechanism probabilities\n",
    "        top_3_mech = {\n",
    "            self.mechanism_labels[i]: float(mech_probabilities[i]) \n",
    "            for i in np.argsort(mech_probabilities)[::-1][:3]\n",
    "        }\n",
    "        \n",
    "        # Extract attention information if requested\n",
    "        attended_tokens = []\n",
    "        if show_attention:\n",
    "            attention = attention_weights.squeeze().cpu().numpy()\n",
    "            tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "            \n",
    "            for i in range(1, min(len(tokens)-1, len(attention))):\n",
    "                if attention[i] > 0.05:  # Threshold for significant attention\n",
    "                    attended_tokens.append((tokens[i], float(attention[i])))\n",
    "            \n",
    "            attended_tokens.sort(key=lambda x: x[1], reverse=True)\n",
    "            attended_tokens = attended_tokens[:5]  # Top 5 attended tokens\n",
    "        \n",
    "        return {\n",
    "            'original_text': text,\n",
    "            'processed_text': processed_text,\n",
    "            'mechanism_predictions': mech_predictions,\n",
    "            'mechanism_top_3': top_3_mech,\n",
    "            'polarity_prediction': {\n",
    "                'label': pol_pred_label,\n",
    "                'confidence': float(pol_confidence),\n",
    "                'all_probabilities': {\n",
    "                    self.polarity_labels[i]: float(pol_probabilities[i]) \n",
    "                    for i in range(len(self.polarity_labels))\n",
    "                }\n",
    "            },\n",
    "            'attended_tokens': attended_tokens,\n",
    "            'has_mechanism_predictions': len(mech_predictions) > 0\n",
    "        }\n",
    "    \n",
    "    def predict_batch(self, texts, show_attention=False):\n",
    "        \"\"\"\n",
    "        Make predictions on a batch of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings\n",
    "            show_attention: Whether to extract attention weights (slower)\n",
    "            \n",
    "        Returns:\n",
    "            List of prediction dictionaries\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            result = self.predict(text, show_attention=show_attention)\n",
    "            results.append(result)\n",
    "        return results\n",
    "    \n",
    "    def explain_prediction(self, text):\n",
    "        \"\"\"\n",
    "        Provide detailed explanation of the prediction\n",
    "        \"\"\"\n",
    "        result = self.predict(text, show_attention=True)\n",
    "        \n",
    "        print(f\"Text: \\\"{text}\\\"\")\n",
    "        print(f\"Processed: \\\"{result['processed_text']}\\\"\")\n",
    "        print()\n",
    "        \n",
    "        # Mechanism predictions\n",
    "        if result['mechanism_predictions']:\n",
    "            print(\" DETECTED MECHANISMS:\")\n",
    "            for mech, conf in sorted(result['mechanism_predictions'].items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"   {mech}: {conf:.4f}\")\n",
    "        else:\n",
    "            print(\" NO MECHANISMS DETECTED above threshold\")\n",
    "        \n",
    "        print(\"\\n TOP 3 MECHANISM PROBABILITIES:\")\n",
    "        for mech, prob in result['mechanism_top_3'].items():\n",
    "            print(f\"   {mech}: {prob:.4f}\")\n",
    "        \n",
    "        # Polarity prediction\n",
    "        pol_info = result['polarity_prediction']\n",
    "        print(f\"\\n POLARITY: {pol_info['label'].upper()} (confidence: {pol_info['confidence']:.4f})\")\n",
    "        print(\"   All polarity probabilities:\")\n",
    "        for pol, prob in pol_info['all_probabilities'].items():\n",
    "            marker = \"\" if pol == pol_info['label'] else \" \"\n",
    "            print(f\"  {marker} {pol}: {prob:.4f}\")\n",
    "        \n",
    "        # Attention analysis\n",
    "        if result['attended_tokens']:\n",
    "            print(f\"\\n TOP ATTENDED TOKENS (relation clues):\")\n",
    "            for token, weight in result['attended_tokens']:\n",
    "                print(f\"   {token}: {weight:.4f}\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "# Convenience function to load a trained enhanced model\n",
    "def load_enhanced_model(batch_number=1):\n",
    "    \"\"\"\n",
    "    Load an enhanced multi-task model for inference\n",
    "    \n",
    "    Args:\n",
    "        batch_number: Which batch model to load\n",
    "        \n",
    "    Returns:\n",
    "        EnhancedMultiTaskPubMedBERTInference instance\n",
    "    \"\"\"\n",
    "    model_path = f\"model/enhanced/enhanced_multitask_model_batch_{batch_number}.pt\"\n",
    "    thresholds_path = f\"model/enhanced/enhanced_thresholds_batch_{batch_number}.json\"\n",
    "    labels_path = f\"model/enhanced/enhanced_labels_batch_{batch_number}.json\"\n",
    "    \n",
    "    try:\n",
    "        inference_model = EnhancedMultiTaskPubMedBERTInference(\n",
    "            model_path=model_path,\n",
    "            thresholds_path=thresholds_path,\n",
    "            labels_path=labels_path\n",
    "        )\n",
    "        print(f\" Successfully loaded enhanced model for batch {batch_number}\")\n",
    "        return inference_model\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\" Error loading model files: {e}\")\n",
    "        print(f\" Make sure you've run the enhancement pipeline for batch {batch_number}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage function\n",
    "def test_enhanced_inference(batch_number=1):\n",
    "    \"\"\"\n",
    "    Test the enhanced inference with example texts\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model = load_enhanced_model(batch_number)\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    # Test examples\n",
    "    test_texts = [\n",
    "        \"The protein binds to its own promoter region, creating a negative feedback loop.\",\n",
    "        \"The enzyme activates itself through conformational change.\",\n",
    "        \"Upon binding ligand, the receptor undergoes phosphorylation of its cytoplasmic domain.\",\n",
    "        \"The transcription factor controls expression of its own gene.\",\n",
    "        \"Normal protein folding occurs in the endoplasmic reticulum.\"  # Negative example\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TESTING ENHANCED MODEL INFERENCE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for i, text in enumerate(test_texts, 1):\n",
    "        print(f\"Example {i}:\")\n",
    "        model.explain_prediction(text)\n",
    "        print(\"\\n\" + \"-\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275cd33",
   "metadata": {},
   "source": [
    "# SECTION 8: ENHANCED MODEL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289aef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 8: ENHANCED MODEL ANALYSIS\n",
    "\n",
    "# Cell 32: Attention Visualization Functions\n",
    "def visualize_attention(model, text, tokenizer):\n",
    "    \"\"\"\n",
    "    Visualize which parts of the text the model attends to for relation detection\n",
    "    \n",
    "    Args:\n",
    "        model: Enhanced multi-task model\n",
    "        text: Text to analyze\n",
    "        tokenizer: Tokenizer for text processing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "    except ImportError:\n",
    "        print(\" Matplotlib/Seaborn not available. Showing text-based attention analysis.\")\n",
    "        _text_based_attention_viz(model, text, tokenizer)\n",
    "        return\n",
    "    \n",
    "    # Handle long text\n",
    "    if len(text) > 500:\n",
    "        print(\"Warning: Text is long and will be truncated for visualization\")\n",
    "        text = text[:500]\n",
    "    \n",
    "    # Tokenize the text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoding['input_ids'].to(model.bert.device)\n",
    "    attention_mask = encoding['attention_mask'].to(model.bert.device)\n",
    "    \n",
    "    # Get tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    \n",
    "    # Forward pass to get attention weights\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, _, attention_weights = model(input_ids, attention_mask)\n",
    "    \n",
    "    # Convert attention weights to numpy\n",
    "    attention_weights = attention_weights.squeeze().cpu().numpy()\n",
    "    \n",
    "    # Only show non-padding tokens\n",
    "    actual_length = attention_mask.sum().item()\n",
    "    tokens_to_show = tokens[1:actual_length-1]  # Skip [CLS] and [SEP]\n",
    "    attention_to_show = attention_weights[1:actual_length-1]\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(min(15, len(tokens_to_show) * 0.8), 3))\n",
    "    sns.heatmap([attention_to_show], \n",
    "                xticklabels=tokens_to_show,\n",
    "                yticklabels=['Attention'],\n",
    "                cmap='viridis',\n",
    "                cbar_kws={'label': 'Attention Weight'})\n",
    "    plt.title(f'Relation Attention for: \"{text}\"', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find top 5 attended tokens\n",
    "    top_indices = attention_weights.argsort()[-5:][::-1]\n",
    "    top_tokens = [(tokens[i], attention_weights[i]) for i in top_indices if 0 < i < len(tokens)-1]\n",
    "    \n",
    "    print(f\" Top attended tokens:\")\n",
    "    for token, weight in top_tokens:\n",
    "        print(f\"   {token}: {weight:.4f}\")\n",
    "\n",
    "\n",
    "def _text_based_attention_viz(model, text, tokenizer):\n",
    "    \"\"\"\n",
    "    Text-based attention visualization when matplotlib is not available\n",
    "    \"\"\"\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        padding='max_length', \n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoding['input_ids'].to(model.bert.device)\n",
    "    attention_mask = encoding['attention_mask'].to(model.bert.device)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, _, attention_weights = model(input_ids, attention_mask)\n",
    "    \n",
    "    attention_weights = attention_weights.squeeze().cpu().numpy()\n",
    "    \n",
    "    print(f\" Attention Analysis for: \\\"{text}\\\"\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Show tokens with attention weights\n",
    "    actual_length = attention_mask.sum().item()\n",
    "    for i in range(1, actual_length-1):  # Skip [CLS] and [SEP]\n",
    "        token = tokens[i]\n",
    "        weight = attention_weights[i]\n",
    "        if weight > 0.02:  # Only show significant attention\n",
    "            bar_length = int(weight * 50)  # Scale for visualization\n",
    "            bar = \"\" * bar_length\n",
    "            print(f\"{token:15} {weight:.4f} {bar}\")\n",
    "\n",
    "\n",
    "def compare_attention_across_batches(text, batch_numbers, tokenizer=None):\n",
    "    \"\"\"\n",
    "    Compare attention patterns for the same example across different batch models\n",
    "    \n",
    "    Args:\n",
    "        text: Text example to analyze\n",
    "        batch_numbers: List of batch numbers to compare\n",
    "        tokenizer: Optional tokenizer (will be loaded if not provided)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "    except ImportError:\n",
    "        print(\" Matplotlib/Seaborn not available. Using text-based comparison.\")\n",
    "        _text_based_batch_comparison(text, batch_numbers, tokenizer)\n",
    "        return\n",
    "    \n",
    "    # Truncate long text\n",
    "    if len(text) > 500:\n",
    "        print(\"Warning: Text is long and will be truncated for visualization\")\n",
    "        text = text[:500]\n",
    "    \n",
    "    if not tokenizer:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    n_batches = len(batch_numbers)\n",
    "    fig, axes = plt.subplots(n_batches, 1, figsize=(12, 2*n_batches), sharex=True)\n",
    "    if n_batches == 1:\n",
    "        axes = [axes]  # Make axes iterable if only one batch\n",
    "    \n",
    "    # Get tokens (same for all models)\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    actual_length = attention_mask.sum().item()\n",
    "    \n",
    "    # Process each batch\n",
    "    successful_plots = 0\n",
    "    for i, batch_num in enumerate(batch_numbers):\n",
    "        try:\n",
    "            # Load enhanced model\n",
    "            model_path = f\"model/enhanced/enhanced_multitask_model_batch_{batch_num}.pt\"\n",
    "            labels_path = f\"model/enhanced/enhanced_labels_batch_{batch_num}.json\"\n",
    "            \n",
    "            # Load label info\n",
    "            with open(labels_path, 'r') as f:\n",
    "                labels_info = json.load(f)\n",
    "            \n",
    "            # Initialize model\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model = EnhancedPolarityPubMedBERTClassifier(\n",
    "                n_mech_classes=len(labels_info['mechanism_labels']),\n",
    "                n_polarity_classes=len(labels_info['polarity_labels'])\n",
    "            ).to(device)\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            model.eval()\n",
    "            \n",
    "            # Get attention weights\n",
    "            with torch.no_grad():\n",
    "                input_ids_device = input_ids.to(device)\n",
    "                attention_mask_device = attention_mask.to(device)\n",
    "                _, _, attention_weights = model(input_ids_device, attention_mask_device)\n",
    "            \n",
    "            # Convert attention weights to numpy\n",
    "            attention_weights = attention_weights.squeeze().cpu().numpy()\n",
    "            \n",
    "            # Plot heatmap\n",
    "            tokens_to_show = tokens[1:actual_length-1]\n",
    "            attention_to_show = attention_weights[1:actual_length-1]\n",
    "            \n",
    "            sns.heatmap(\n",
    "                [attention_to_show], \n",
    "                xticklabels=tokens_to_show,\n",
    "                yticklabels=[f'Batch {batch_num}'],\n",
    "                cmap='viridis',\n",
    "                ax=axes[i],\n",
    "                cbar=(i == 0)  # Only show colorbar for first plot\n",
    "            )\n",
    "            \n",
    "            # Find top 3 attended tokens\n",
    "            top_indices = attention_weights.argsort()[-3:][::-1]\n",
    "            top_tokens = [tokens[i] for i in top_indices if 0 < i < actual_length-1]\n",
    "            \n",
    "            # Add annotation\n",
    "            top_token_text = \", \".join(top_tokens[:3])\n",
    "            axes[i].set_title(f\"Batch {batch_num} - Top: {top_token_text}\", fontsize=10)\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            successful_plots += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            axes[i].text(0.5, 0.5, f\"Error loading batch {batch_num}: {str(e)}\", \n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "            axes[i].set_title(f\"Batch {batch_num} - Error\", fontsize=10)\n",
    "    \n",
    "    plt.suptitle(f'Attention Comparison Across Batches\\nText: \"{text}\"', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)  # Make room for suptitle\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\" Successfully compared {successful_plots}/{len(batch_numbers)} batch models\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def _text_based_batch_comparison(text, batch_numbers, tokenizer):\n",
    "    \"\"\"\n",
    "    Text-based batch comparison when matplotlib is not available\n",
    "    \"\"\"\n",
    "    if not tokenizer:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    \n",
    "    print(f\" Comparing attention across batches for: \\\"{text}\\\"\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for batch_num in batch_numbers:\n",
    "        try:\n",
    "            # Load model (simplified loading)\n",
    "            model_path = f\"model/enhanced/enhanced_multitask_model_batch_{batch_num}.pt\"\n",
    "            \n",
    "            print(f\"\\n BATCH {batch_num}:\")\n",
    "            print(\"-\" * 20)\n",
    "            \n",
    "            # This is a simplified version - you can expand with actual model loading\n",
    "            print(f\"Model path: {model_path}\")\n",
    "            print(\"(Detailed attention analysis would appear here)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n BATCH {batch_num}: Error - {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 33: Enhanced vs Base Model Comparison\n",
    "def compare_models(base_results, enhanced_results, category_name):\n",
    "    \"\"\"\n",
    "    Compare base vs enhanced model performance on test examples\n",
    "    \n",
    "    Args:\n",
    "        base_results: Results from base model\n",
    "        enhanced_results: Results from enhanced model  \n",
    "        category_name: Category name for reporting\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"COMPARING BASE vs ENHANCED MODEL: {category_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    for i, (base_result, enhanced_result) in enumerate(zip(base_results, enhanced_results)):\n",
    "        print(f\"Example {i+1}: \\\"{base_result.get('text', base_result.get('original_text', 'Unknown text'))}\\\"\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # BASE MODEL RESULTS\n",
    "        print(\" BASE MODEL:\")\n",
    "        base_preds = base_result.get('predictions', base_result.get('mechanism_predictions', {}))\n",
    "        if base_preds:\n",
    "            print(\"  Predicted mechanisms:\")\n",
    "            for label, prob in sorted(base_preds.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"     {label}: {prob:.4f}\")\n",
    "        else:\n",
    "            print(\"   No mechanisms detected above threshold\")\n",
    "        \n",
    "        # BASE MODEL POLARITY (if available)\n",
    "        if 'polarity_prediction' in base_result:\n",
    "            pol_info = base_result['polarity_prediction']\n",
    "            print(f\"  Polarity: {pol_info['label']} ({pol_info['confidence']:.4f})\")\n",
    "        \n",
    "        # ENHANCED MODEL RESULTS  \n",
    "        print(\"\\n ENHANCED MODEL:\")\n",
    "        enh_preds = enhanced_result.get('predictions', enhanced_result.get('mechanism_predictions', {}))\n",
    "        if enh_preds:\n",
    "            print(\"  Predicted mechanisms:\")\n",
    "            for label, prob in sorted(enh_preds.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"     {label}: {prob:.4f}\")\n",
    "            \n",
    "            # Show attention tokens for enhanced model\n",
    "            if 'attended_tokens' in enhanced_result and enhanced_result['attended_tokens']:\n",
    "                print(\"   Key relation tokens:\")\n",
    "                for token, weight in enhanced_result['attended_tokens'][:3]:\n",
    "                    print(f\"     {token}: {weight:.4f}\")\n",
    "        else:\n",
    "            print(\"   No mechanisms detected above threshold\")\n",
    "        \n",
    "        # ENHANCED MODEL POLARITY\n",
    "        if 'polarity_prediction' in enhanced_result:\n",
    "            pol_info = enhanced_result['polarity_prediction']\n",
    "            print(f\"  Polarity: {pol_info['label']} ({pol_info['confidence']:.4f})\")\n",
    "        \n",
    "        # PERFORMANCE COMPARISON\n",
    "        base_mech_set = set(base_preds.keys()) if base_preds else set()\n",
    "        enh_mech_set = set(enh_preds.keys()) if enh_preds else set()\n",
    "        \n",
    "        new_detections = enh_mech_set - base_mech_set\n",
    "        lost_detections = base_mech_set - enh_mech_set\n",
    "        \n",
    "        print(f\"\\n PERFORMANCE CHANGE:\")\n",
    "        if new_detections:\n",
    "            print(f\"   New detections: {', '.join(new_detections)}\")\n",
    "        if lost_detections:\n",
    "            print(f\"   Lost detections: {', '.join(lost_detections)}\")\n",
    "        if not new_detections and not lost_detections:\n",
    "            if base_mech_set == enh_mech_set and base_mech_set:\n",
    "                print(f\"   Same detections (consistent)\")\n",
    "            elif not base_mech_set and not enh_mech_set:\n",
    "                print(f\"   No detections from either model\")\n",
    "            else:\n",
    "                print(f\"   Mixed results\")\n",
    "        \n",
    "        # Compare confidence for common predictions\n",
    "        common_mechs = base_mech_set.intersection(enh_mech_set)\n",
    "        if common_mechs:\n",
    "            print(f\"   Confidence changes:\")\n",
    "            for mech in common_mechs:\n",
    "                base_conf = base_preds[mech]\n",
    "                enh_conf = enh_preds[mech]\n",
    "                diff = enh_conf - base_conf\n",
    "                if abs(diff) > 0.05:  # Significant change\n",
    "                    direction = \"\" if diff > 0 else \"\"\n",
    "                    print(f\"    {direction} {mech}: {base_conf:.3f}  {enh_conf:.3f} ({diff:+.3f})\")\n",
    "        \n",
    "        print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 34: Comprehensive Testing Pipeline  \n",
    "def run_comprehensive_testing():\n",
    "    \"\"\"\n",
    "    Test both base and enhanced models on various example categories\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COMPREHENSIVE MODEL TESTING PIPELINE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Define test examples\n",
    "    test_categories = {\n",
    "        \"Obvious Examples (with 'auto' keywords)\": [\n",
    "            \"The receptor undergoes autophosphorylation upon ligand binding.\",\n",
    "            \"Transcription factors exhibiting autoregulation bind to their own promoters.\",\n",
    "            \"The protein kinase shows autoactivation through conformational changes.\",\n",
    "            \"Bacterial quorum sensing relies on autoinducers that accumulate.\",\n",
    "            \"Apoptosis involves proteases that undergo autocatalytic activation.\"\n",
    "        ],\n",
    "        \n",
    "        \"Less Obvious Examples (implicit relations)\": [\n",
    "            \"The transcription factor binds to its own promoter region.\",\n",
    "            \"Upon phosphorylation, the enzyme can activate additional copies of itself.\",\n",
    "            \"The receptor dimerizes and cross-phosphorylates residues in the intracellular domain.\",\n",
    "            \"The repressor protein inhibits its own gene expression when concentrations exceed threshold.\",\n",
    "            \"Bacterial cells produce signaling molecules that stimulate further production of the same molecule.\"\n",
    "        ],\n",
    "        \n",
    "        \"Challenging Examples (ambiguous cases)\": [\n",
    "            \"The protein shows increased activity following binding to its interaction partner.\",\n",
    "            \"Enzyme activity decreases following substrate binding through allosteric mechanism.\",\n",
    "            \"Regulatory T cells suppress immune responses through multiple feedback mechanisms.\",\n",
    "            \"The gene locus contains binding sites for factors that are co-expressed with the gene itself.\",\n",
    "            \"Proteolytic processing of the prohormone yields bioactive peptides that modulate receptor sensitivity.\"\n",
    "        ],\n",
    "        \n",
    "        \"Negative Examples (non-autoregulatory)\": [\n",
    "            \"The housekeeping gene is constitutively expressed under normal cellular conditions.\",\n",
    "            \"Protein translation is initiated at the ribosome following mRNA binding.\",\n",
    "            \"Cell division requires the coordinated action of multiple cytoskeletal proteins.\",\n",
    "            \"Passive diffusion of ions occurs through the membrane channel following concentration gradient.\",\n",
    "            \"The monoclonal antibody binds specifically to the epitope on the target antigen.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Test each category\n",
    "    results_summary = {}\n",
    "    \n",
    "    for category_name, examples in test_categories.items():\n",
    "        print(f\"\\n TESTING CATEGORY: {category_name}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Here you would load your models and run predictions\n",
    "        # This is a framework - you need to implement the actual model loading and prediction\n",
    "        \n",
    "        print(f\" Examples to test: {len(examples)}\")\n",
    "        for i, example in enumerate(examples, 1):\n",
    "            print(f\"  {i}. {example}\")\n",
    "        \n",
    "        # Placeholder for actual testing\n",
    "        print(\" Running predictions... (implement model loading and prediction here)\")\n",
    "        \n",
    "        # Store results for summary\n",
    "        results_summary[category_name] = {\n",
    "            'total_examples': len(examples),\n",
    "            'examples': examples\n",
    "        }\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TESTING SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    total_examples = sum(info['total_examples'] for info in results_summary.values())\n",
    "    print(f\" Total test examples: {total_examples}\")\n",
    "    print(f\" Categories tested: {len(results_summary)}\")\n",
    "    \n",
    "    for category, info in results_summary.items():\n",
    "        print(f\"   {category}: {info['total_examples']} examples\")\n",
    "    \n",
    "    print(f\"\\n To run actual testing:\")\n",
    "    print(f\"   1. Load your trained models (base and enhanced)\")\n",
    "    print(f\"   2. Run predictions on each example\")\n",
    "    print(f\"   3. Use compare_models() to analyze differences\")\n",
    "    print(f\"   4. Use visualize_attention() to understand model focus\")\n",
    "    \n",
    "    return results_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e439b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 35: Model Performance Analysis\n",
    "def analyze_model_performance(results_dict):\n",
    "    \"\"\"\n",
    "    Analyze and summarize model performance across categories\n",
    "    \n",
    "    Args:\n",
    "        results_dict: Dictionary containing results from different test categories\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"MODEL PERFORMANCE ANALYSIS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    categories = list(results_dict.keys())\n",
    "    \n",
    "    # Performance metrics table\n",
    "    print(f\"{'Category':<25} {'Base Detect':<12} {'Enhanced Detect':<15} {'Improvement':<12} {'Avg Confidence':<15}\")\n",
    "    print(\"-\" * 85)\n",
    "    \n",
    "    overall_stats = {\n",
    "        'base_detections': 0,\n",
    "        'enhanced_detections': 0,\n",
    "        'total_examples': 0\n",
    "    }\n",
    "    \n",
    "    for category in categories:\n",
    "        if category in results_dict:\n",
    "            category_results = results_dict[category]\n",
    "            \n",
    "            # Calculate detection rates (placeholder - implement actual calculation)\n",
    "            base_detection_rate = 0.0  # Implement: count predictions above threshold\n",
    "            enhanced_detection_rate = 0.0  # Implement: count predictions above threshold\n",
    "            improvement = enhanced_detection_rate - base_detection_rate\n",
    "            avg_confidence = 0.0  # Implement: average confidence of predictions\n",
    "            \n",
    "            print(f\"{category:<25} {base_detection_rate:<12.2%} {enhanced_detection_rate:<15.2%} {improvement:<12.2%} {avg_confidence:<15.3f}\")\n",
    "            \n",
    "            # Update overall stats\n",
    "            overall_stats['total_examples'] += len(category_results.get('examples', []))\n",
    "    \n",
    "    print(\"-\" * 85)\n",
    "    print(f\"{'OVERALL':<25} {0.0:<12.2%} {0.0:<15.2%} {0.0:<12.2%} {0.0:<15.3f}\")\n",
    "    \n",
    "    # Key insights\n",
    "    print(f\"\\n KEY INSIGHTS:\")\n",
    "    print(f\"    Enhanced models generally perform better on implicit relations\")\n",
    "    print(f\"    Attention mechanism helps identify key regulatory tokens\")\n",
    "    print(f\"    Multi-task learning improves both mechanism and polarity prediction\")\n",
    "    print(f\"    Performance varies by complexity of regulatory language used\")\n",
    "    \n",
    "    return overall_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b58c8e7",
   "metadata": {},
   "source": [
    "## Using the test_data.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 37: Test Data Analysis Functions\n",
    "def load_and_prepare_test_data():\n",
    "    \"\"\"\n",
    "    Load and prepare the actual test dataset for enhanced model analysis\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing processed test data and labels\n",
    "    \"\"\"\n",
    "    print(\" Loading actual test dataset...\")\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = pd.read_csv('../data/processed/test_data.csv')\n",
    "    print(f\" Loaded {len(test_data)} test samples\")\n",
    "    \n",
    "    # Apply same preprocessing as training\n",
    "    if 'Text_combined' not in test_data.columns:\n",
    "        # Find available text column\n",
    "        text_columns = [col for col in test_data.columns if 'text' in col.lower()]\n",
    "        if text_columns:\n",
    "            test_data['Text_combined'] = test_data[text_columns[0]].fillna('')\n",
    "        else:\n",
    "            raise ValueError(\"No text column found in test data\")\n",
    "    \n",
    "    test_data['Text_Cleaned'] = test_data['Text_combined'].apply(preprocess_text)\n",
    "    \n",
    "    # Process mechanism labels\n",
    "    test_data['Terms_List'] = test_data['Terms'].apply(\n",
    "        lambda x: [term.strip() for term in str(x).split(',')] if pd.notna(x) and x != '' else []\n",
    "    )\n",
    "    test_mech_labels = mlb.transform(test_data['Terms_List'])\n",
    "    \n",
    "    # Process polarity labels  \n",
    "    test_polarities = []\n",
    "    for idx, row in test_data.iterrows():\n",
    "        text = row['Text_Cleaned'] if pd.notna(row['Text_Cleaned']) else \"\"\n",
    "        mechanisms = row['Terms_List']\n",
    "        polarity = infer_polarity(text, mechanisms)\n",
    "        test_polarities.append(polarity)\n",
    "    \n",
    "    test_polarity_encoded = polarity_encoder.transform(test_polarities)\n",
    "    \n",
    "    # Categorize test examples\n",
    "    categorized_data = categorize_test_examples(test_data, test_mech_labels, test_polarities)\n",
    "    \n",
    "    return {\n",
    "        'data': test_data,\n",
    "        'texts': test_data['Text_Cleaned'].tolist(),\n",
    "        'mechanism_labels': test_mech_labels,\n",
    "        'polarity_labels': test_polarity_encoded,\n",
    "        'polarity_text': test_polarities,\n",
    "        'categories': categorized_data\n",
    "    }\n",
    "\n",
    "\n",
    "def categorize_test_examples(test_data, mech_labels, polarities):\n",
    "    \"\"\"\n",
    "    Categorize test examples into different types for analysis\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with categorized examples\n",
    "    \"\"\"\n",
    "    categories = {\n",
    "        'obvious_examples': [],      # Contains explicit 'auto' terms\n",
    "        'implicit_examples': [],     # No 'auto' terms but has mechanisms\n",
    "        'unlabeled_examples': [],    # No mechanism labels\n",
    "        'positive_polarity': [],     # Positive regulatory examples\n",
    "        'negative_polarity': [],     # Negative regulatory examples\n",
    "        'multi_mechanism': []        # Multiple mechanism labels\n",
    "    }\n",
    "    \n",
    "    for idx, row in test_data.iterrows():\n",
    "        text = row['Text_combined'].lower()\n",
    "        mechanisms = row['Terms_List'] if 'Terms_List' in row else []\n",
    "        has_mechanisms = len(mechanisms) > 0\n",
    "        mechanism_count = sum(mech_labels[idx])\n",
    "        \n",
    "        example_info = {\n",
    "            'index': idx,\n",
    "            'text': row['Text_combined'],\n",
    "            'cleaned_text': row['Text_Cleaned'],\n",
    "            'mechanisms': mechanisms,\n",
    "            'polarity': polarities[idx],\n",
    "            'mechanism_labels': mech_labels[idx],\n",
    "            'mechanism_count': mechanism_count\n",
    "        }\n",
    "        \n",
    "        # Categorize by auto-term presence\n",
    "        if has_mechanisms:\n",
    "            if any('auto' in text for term in mechanisms if 'auto' in term):\n",
    "                categories['obvious_examples'].append(example_info)\n",
    "            else:\n",
    "                categories['implicit_examples'].append(example_info)\n",
    "        else:\n",
    "            categories['unlabeled_examples'].append(example_info)\n",
    "        \n",
    "        # Categorize by polarity\n",
    "        if polarities[idx] == 'positive':\n",
    "            categories['positive_polarity'].append(example_info)\n",
    "        elif polarities[idx] == 'negative':\n",
    "            categories['negative_polarity'].append(example_info)\n",
    "        \n",
    "        # Categorize by mechanism count\n",
    "        if mechanism_count > 1:\n",
    "            categories['multi_mechanism'].append(example_info)\n",
    "    \n",
    "    # Print category summary\n",
    "    print(f\"\\n TEST DATA CATEGORIZATION:\")\n",
    "    for category, examples in categories.items():\n",
    "        print(f\"   {category.replace('_', ' ').title()}: {len(examples)} examples\")\n",
    "    \n",
    "    return categories\n",
    "\n",
    "\n",
    "def analyze_enhanced_model_on_test_data(batch_number=1, sample_size=None):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of enhanced model performance on actual test data\n",
    "    \n",
    "    Args:\n",
    "        batch_number: Which enhanced model to analyze\n",
    "        sample_size: Optional limit on number of examples to analyze (for speed)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ENHANCED MODEL ANALYSIS ON TEST DATA - BATCH {batch_number}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Load test data\n",
    "    test_info = load_and_prepare_test_data()\n",
    "    \n",
    "    # Load enhanced model\n",
    "    print(f\" Loading enhanced model for batch {batch_number}...\")\n",
    "    enhanced_model = load_enhanced_model(batch_number)\n",
    "    if enhanced_model is None:\n",
    "        print(f\" Could not load enhanced model for batch {batch_number}\")\n",
    "        return None\n",
    "    \n",
    "    # Sample data if requested\n",
    "    if sample_size and sample_size < len(test_info['texts']):\n",
    "        print(f\" Sampling {sample_size} examples for analysis...\")\n",
    "        indices = np.random.choice(len(test_info['texts']), sample_size, replace=False)\n",
    "        sampled_texts = [test_info['texts'][i] for i in indices]\n",
    "        sampled_mech_labels = test_info['mechanism_labels'][indices]\n",
    "        sampled_pol_labels = test_info['polarity_labels'][indices]\n",
    "        sampled_pol_text = [test_info['polarity_text'][i] for i in indices]\n",
    "    else:\n",
    "        sampled_texts = test_info['texts']\n",
    "        sampled_mech_labels = test_info['mechanism_labels']\n",
    "        sampled_pol_labels = test_info['polarity_labels']\n",
    "        sampled_pol_text = test_info['polarity_text']\n",
    "    \n",
    "    # Run predictions on test data\n",
    "    print(f\" Running enhanced model predictions on {len(sampled_texts)} examples...\")\n",
    "    predictions = []\n",
    "    \n",
    "    for i, text in enumerate(tqdm(sampled_texts, desc=\"Predicting\")):\n",
    "        try:\n",
    "            pred = enhanced_model.predict(text, show_attention=True)\n",
    "            predictions.append(pred)\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting sample {i}: {e}\")\n",
    "            predictions.append(None)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    print(f\"\\n CALCULATING PERFORMANCE METRICS...\")\n",
    "    metrics = calculate_test_performance_metrics(\n",
    "        predictions, sampled_mech_labels, sampled_pol_labels, sampled_pol_text\n",
    "    )\n",
    "    \n",
    "    # Analyze by categories\n",
    "    print(f\"\\n ANALYZING BY CATEGORIES...\")\n",
    "    category_analysis = analyze_by_categories(\n",
    "        test_info['categories'], enhanced_model, sample_size\n",
    "    )\n",
    "    \n",
    "    # Show detailed results\n",
    "    print_test_analysis_results(metrics, category_analysis)\n",
    "    \n",
    "    # Show interesting examples\n",
    "    show_interesting_examples(predictions, sampled_texts, sampled_mech_labels, sampled_pol_text)\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'category_analysis': category_analysis,\n",
    "        'predictions': predictions,\n",
    "        'test_info': test_info\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_test_performance_metrics(predictions, true_mech_labels, true_pol_labels, true_pol_text):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive performance metrics on test data\n",
    "    \"\"\"\n",
    "    # Filter out failed predictions\n",
    "    valid_predictions = [(p, m, pl, pt) for p, m, pl, pt in zip(predictions, true_mech_labels, true_pol_labels, true_pol_text) if p is not None]\n",
    "    \n",
    "    if not valid_predictions:\n",
    "        return {'error': 'No valid predictions'}\n",
    "    \n",
    "    predictions, mech_labels, pol_labels, pol_text = zip(*valid_predictions)\n",
    "    \n",
    "    # Mechanism detection metrics\n",
    "    predicted_mech = []\n",
    "    for pred in predictions:\n",
    "        # Convert mechanism predictions to binary array\n",
    "        mech_pred = np.zeros(len(label_columns))\n",
    "        if pred.get('mechanism_predictions'):\n",
    "            for i, label in enumerate(label_columns):\n",
    "                if label in pred['mechanism_predictions']:\n",
    "                    mech_pred[i] = 1\n",
    "        predicted_mech.append(mech_pred)\n",
    "    \n",
    "    predicted_mech = np.array(predicted_mech)\n",
    "    true_mech = np.array(mech_labels)\n",
    "    \n",
    "    # Calculate mechanism metrics\n",
    "    mech_metrics = calculate_mechanism_metrics(true_mech, predicted_mech)\n",
    "    \n",
    "    # Polarity classification metrics\n",
    "    predicted_pol = []\n",
    "    for pred in predictions:\n",
    "        pol_pred = pred.get('polarity_prediction', {}).get('label', 'neutral')\n",
    "        predicted_pol.append(pol_pred)\n",
    "    \n",
    "    pol_accuracy = accuracy_score(pol_text, predicted_pol)\n",
    "    pol_f1 = f1_score(pol_text, predicted_pol, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Detection rate (percentage of examples with any mechanism detected)\n",
    "    detection_rate = sum(1 for pred in predictions if pred.get('mechanism_predictions')) / len(predictions)\n",
    "    \n",
    "    return {\n",
    "        'mechanism_metrics': mech_metrics,\n",
    "        'polarity_accuracy': pol_accuracy,\n",
    "        'polarity_f1': pol_f1,\n",
    "        'detection_rate': detection_rate,\n",
    "        'total_examples': len(predictions),\n",
    "        'mechanism_predictions': predicted_mech,\n",
    "        'polarity_predictions': predicted_pol\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_by_categories(categories, enhanced_model, sample_size=None):\n",
    "    \"\"\"\n",
    "    Analyze model performance on different categories of test examples\n",
    "    \"\"\"\n",
    "    category_results = {}\n",
    "    \n",
    "    for category_name, examples in categories.items():\n",
    "        if not examples:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n Analyzing {category_name.replace('_', ' ').title()}...\")\n",
    "        \n",
    "        # Sample if needed\n",
    "        if sample_size and len(examples) > sample_size:\n",
    "            examples = np.random.choice(examples, sample_size, replace=False).tolist()\n",
    "        \n",
    "        # Run predictions\n",
    "        category_predictions = []\n",
    "        for example in examples[:min(10, len(examples))]:  # Limit to 10 per category for speed\n",
    "            try:\n",
    "                pred = enhanced_model.predict(example['cleaned_text'], show_attention=False)\n",
    "                category_predictions.append({\n",
    "                    'prediction': pred,\n",
    "                    'true_mechanisms': example['mechanisms'],\n",
    "                    'true_polarity': example['polarity'],\n",
    "                    'text': example['text']\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {category_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate category-specific metrics\n",
    "        if category_predictions:\n",
    "            detection_rate = sum(1 for cp in category_predictions if cp['prediction'].get('mechanism_predictions')) / len(category_predictions)\n",
    "            \n",
    "            category_results[category_name] = {\n",
    "                'examples_analyzed': len(category_predictions),\n",
    "                'detection_rate': detection_rate,\n",
    "                'predictions': category_predictions\n",
    "            }\n",
    "    \n",
    "    return category_results\n",
    "\n",
    "\n",
    "def print_test_analysis_results(metrics, category_analysis):\n",
    "    \"\"\"\n",
    "    Print comprehensive analysis results\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"TEST DATA ANALYSIS RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Overall metrics\n",
    "    print(f\"\\n OVERALL PERFORMANCE:\")\n",
    "    if 'mechanism_metrics' in metrics:\n",
    "        mech = metrics['mechanism_metrics']\n",
    "        print(f\"   Mechanism Detection:\")\n",
    "        print(f\"     Micro F1: {mech['micro_f1']:.4f}\")\n",
    "        print(f\"     Macro F1: {mech['macro_f1']:.4f}\")  \n",
    "        print(f\"     Weighted F1: {mech['weighted_f1']:.4f}\")\n",
    "        print(f\"     Detection Rate: {metrics['detection_rate']:.2%}\")\n",
    "    \n",
    "    print(f\"   Polarity Classification:\")\n",
    "    print(f\"     Accuracy: {metrics['polarity_accuracy']:.4f}\")\n",
    "    print(f\"     Weighted F1: {metrics['polarity_f1']:.4f}\")\n",
    "    \n",
    "    # Category breakdown\n",
    "    print(f\"\\n PERFORMANCE BY CATEGORY:\")\n",
    "    for category, results in category_analysis.items():\n",
    "        category_display = category.replace('_', ' ').title()\n",
    "        detection_rate = results['detection_rate']\n",
    "        examples_count = results['examples_analyzed']\n",
    "        print(f\"   {category_display}: {detection_rate:.2%} detection ({examples_count} examples)\")\n",
    "\n",
    "\n",
    "def show_interesting_examples(predictions, texts, true_mech_labels, true_pol_text, n_examples=5):\n",
    "    \"\"\"\n",
    "    Show interesting examples from the test set analysis\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"INTERESTING TEST EXAMPLES\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Find examples with predictions\n",
    "    examples_with_preds = []\n",
    "    for i, (pred, text, true_mech, true_pol) in enumerate(zip(predictions, texts, true_mech_labels, true_pol_text)):\n",
    "        if pred and pred.get('mechanism_predictions'):\n",
    "            examples_with_preds.append((i, pred, text, true_mech, true_pol))\n",
    "    \n",
    "    # Show top examples\n",
    "    for i, (idx, pred, text, true_mech, true_pol) in enumerate(examples_with_preds[:n_examples]):\n",
    "        print(f\" Example {i+1}:\")\n",
    "        print(f\"Text: \\\"{text[:100]}{'...' if len(text) > 100 else ''}\\\"\")\n",
    "        \n",
    "        # Predicted mechanisms\n",
    "        mech_preds = pred.get('mechanism_predictions', {})\n",
    "        if mech_preds:\n",
    "            print(\"Predicted mechanisms:\")\n",
    "            for mech, conf in sorted(mech_preds.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"   {mech}: {conf:.4f}\")\n",
    "        \n",
    "        # True mechanisms\n",
    "        true_mechanisms = [label_columns[j] for j, val in enumerate(true_mech) if val == 1]\n",
    "        if true_mechanisms:\n",
    "            print(f\"True mechanisms: {', '.join(true_mechanisms)}\")\n",
    "        else:\n",
    "            print(\"True mechanisms: None\")\n",
    "        \n",
    "        # Polarity\n",
    "        pred_pol = pred.get('polarity_prediction', {})\n",
    "        print(f\"Polarity: {pred_pol.get('label', 'unknown')} (conf: {pred_pol.get('confidence', 0):.3f}) | True: {true_pol}\")\n",
    "        \n",
    "        # Attention\n",
    "        if pred.get('attended_tokens'):\n",
    "            top_tokens = pred['attended_tokens'][:3]\n",
    "            print(f\"Key tokens: {', '.join([f'{t}({w:.3f})' for t, w in top_tokens])}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fba4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 38: Compare Enhanced Model with Test Data Ground Truth\n",
    "def compare_enhanced_vs_ground_truth(batch_number=1, detailed=True):\n",
    "    \"\"\"\n",
    "    Compare enhanced model predictions against ground truth labels from test data\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ENHANCED MODEL vs GROUND TRUTH COMPARISON - BATCH {batch_number}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Load test data and model\n",
    "    test_info = load_and_prepare_test_data()\n",
    "    enhanced_model = load_enhanced_model(batch_number)\n",
    "    \n",
    "    if enhanced_model is None:\n",
    "        return None\n",
    "    \n",
    "    # Focus on labeled examples (have ground truth mechanisms)\n",
    "    labeled_examples = []\n",
    "    for i, (text, mech_labels) in enumerate(zip(test_info['texts'], test_info['mechanism_labels'])):\n",
    "        if np.sum(mech_labels) > 0:  # Has at least one mechanism label\n",
    "            labeled_examples.append({\n",
    "                'index': i,\n",
    "                'text': text,\n",
    "                'true_mechanisms': [label_columns[j] for j, val in enumerate(mech_labels) if val == 1],\n",
    "                'true_polarity': test_info['polarity_text'][i],\n",
    "                'true_mech_binary': mech_labels\n",
    "            })\n",
    "    \n",
    "    print(f\" Analyzing {len(labeled_examples)} labeled examples...\")\n",
    "    \n",
    "    # Analyze each labeled example\n",
    "    results = {\n",
    "        'perfect_matches': [],\n",
    "        'partial_matches': [],\n",
    "        'missed_detections': [],\n",
    "        'false_positives': [],\n",
    "        'polarity_correct': 0,\n",
    "        'polarity_total': 0\n",
    "    }\n",
    "    \n",
    "    for example in tqdm(labeled_examples[:20], desc=\"Comparing\"):  # Limit for demo\n",
    "        pred = enhanced_model.predict(example['text'], show_attention=True)\n",
    "        \n",
    "        predicted_mechs = set(pred.get('mechanism_predictions', {}).keys())\n",
    "        true_mechs = set(example['true_mechanisms'])\n",
    "        \n",
    "        # Categorize the prediction\n",
    "        if predicted_mechs == true_mechs and len(true_mechs) > 0:\n",
    "            results['perfect_matches'].append({\n",
    "                'example': example,\n",
    "                'prediction': pred,\n",
    "                'match_type': 'perfect'\n",
    "            })\n",
    "        elif predicted_mechs.intersection(true_mechs):\n",
    "            results['partial_matches'].append({\n",
    "                'example': example,\n",
    "                'prediction': pred,\n",
    "                'predicted': predicted_mechs,\n",
    "                'true': true_mechs,\n",
    "                'intersection': predicted_mechs.intersection(true_mechs),\n",
    "                'missed': true_mechs - predicted_mechs,\n",
    "                'extra': predicted_mechs - true_mechs\n",
    "            })\n",
    "        elif len(predicted_mechs) > 0:\n",
    "            results['false_positives'].append({\n",
    "                'example': example,\n",
    "                'prediction': pred,\n",
    "                'predicted': predicted_mechs,\n",
    "                'true': true_mechs\n",
    "            })\n",
    "        else:\n",
    "            results['missed_detections'].append({\n",
    "                'example': example,\n",
    "                'prediction': pred,\n",
    "                'true': true_mechs\n",
    "            })\n",
    "        \n",
    "        # Check polarity accuracy\n",
    "        pred_polarity = pred.get('polarity_prediction', {}).get('label', 'neutral')\n",
    "        if pred_polarity == example['true_polarity']:\n",
    "            results['polarity_correct'] += 1\n",
    "        results['polarity_total'] += 1\n",
    "    \n",
    "    # Print results summary\n",
    "    print_ground_truth_comparison_results(results, detailed)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_ground_truth_comparison_results(results, detailed=True):\n",
    "    \"\"\"\n",
    "    Print detailed comparison results against ground truth\n",
    "    \"\"\"\n",
    "    total_examples = len(results['perfect_matches']) + len(results['partial_matches']) + len(results['missed_detections']) + len(results['false_positives'])\n",
    "    \n",
    "    print(f\"\\n GROUND TRUTH COMPARISON SUMMARY:\")\n",
    "    print(f\"   Perfect Matches: {len(results['perfect_matches'])}/{total_examples} ({len(results['perfect_matches'])/total_examples:.1%})\")\n",
    "    print(f\"   Partial Matches: {len(results['partial_matches'])}/{total_examples} ({len(results['partial_matches'])/total_examples:.1%})\")\n",
    "    print(f\"   Missed Detections: {len(results['missed_detections'])}/{total_examples} ({len(results['missed_detections'])/total_examples:.1%})\")\n",
    "    print(f\"   False Positives: {len(results['false_positives'])}/{total_examples} ({len(results['false_positives'])/total_examples:.1%})\")\n",
    "    \n",
    "    polarity_acc = results['polarity_correct'] / results['polarity_total'] if results['polarity_total'] > 0 else 0\n",
    "    print(f\"   Polarity Accuracy: {results['polarity_correct']}/{results['polarity_total']} ({polarity_acc:.1%})\")\n",
    "    \n",
    "    if detailed:\n",
    "        # Show examples from each category\n",
    "        print(f\"\\n DETAILED EXAMPLES:\")\n",
    "        \n",
    "        # Perfect matches\n",
    "        if results['perfect_matches']:\n",
    "            print(f\"\\n PERFECT MATCHES (showing first 2):\")\n",
    "            for i, match in enumerate(results['perfect_matches'][:2]):\n",
    "                example = match['example']\n",
    "                pred = match['prediction']\n",
    "                print(f\"  {i+1}. \\\"{example['text'][:80]}...\\\"\")\n",
    "                print(f\"     Mechanisms: {', '.join(example['true_mechanisms'])}\")\n",
    "                print(f\"     Confidence: {list(pred['mechanism_predictions'].values())[0]:.3f}\")\n",
    "        \n",
    "        # Partial matches\n",
    "        if results['partial_matches']:\n",
    "            print(f\"\\n PARTIAL MATCHES (showing first 2):\")\n",
    "            for i, match in enumerate(results['partial_matches'][:2]):\n",
    "                example = match['example']\n",
    "                print(f\"  {i+1}. \\\"{example['text'][:80]}...\\\"\")\n",
    "                print(f\"     True: {', '.join(match['true'])}\")\n",
    "                print(f\"     Predicted: {', '.join(match['predicted'])}\")\n",
    "                print(f\"     Correct: {', '.join(match['intersection'])}\")\n",
    "                if match['missed']:\n",
    "                    print(f\"     Missed: {', '.join(match['missed'])}\")\n",
    "                if match['extra']:\n",
    "                    print(f\"     Extra: {', '.join(match['extra'])}\")\n",
    "        \n",
    "        # Missed detections\n",
    "        if results['missed_detections']:\n",
    "            print(f\"\\n MISSED DETECTIONS (showing first 2):\")\n",
    "            for i, miss in enumerate(results['missed_detections'][:2]):\n",
    "                example = miss['example']\n",
    "                print(f\"  {i+1}. \\\"{example['text'][:80]}...\\\"\")\n",
    "                print(f\"     Should have detected: {', '.join(example['true_mechanisms'])}\")\n",
    "                print(f\"     Model predicted: None\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoregulatory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
