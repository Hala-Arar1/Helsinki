{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46fcac3",
   "metadata": {},
   "source": [
    "# Bio Bert Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19186769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Imports & Seed Setup\n",
    "import os, random, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit  # Added import for this function\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617f1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65c398d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    torch.device(\"mps\")\n",
    "    if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cuda\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485aa656",
   "metadata": {},
   "source": [
    "## 1. Read in Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ef715f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53130, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Terms</th>\n",
       "      <th>Text_combined</th>\n",
       "      <th>batch_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q8NML3</td>\n",
       "      <td>17183211</td>\n",
       "      <td>RamA, the transcriptional regulator of acetate...</td>\n",
       "      <td>The RamA protein represents a LuxR-type transc...</td>\n",
       "      <td>autoregulation</td>\n",
       "      <td>RamA, the transcriptional regulator of acetate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9SCZ4</td>\n",
       "      <td>17673660</td>\n",
       "      <td>The FERONIA receptor-like kinase mediates male...</td>\n",
       "      <td>In flowering plants, signaling between the mal...</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>The FERONIA receptor-like kinase mediates male...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q81WX1</td>\n",
       "      <td>12721629</td>\n",
       "      <td>The genome sequence of Bacillus anthracis Ames...</td>\n",
       "      <td>Bacillus anthracis is an endospore-forming bac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The genome sequence of Bacillus anthracis Ames...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P14410</td>\n",
       "      <td>8521865</td>\n",
       "      <td>Phosphorylation of the N-terminal intracellula...</td>\n",
       "      <td>This paper reports the phosphorylation of the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phosphorylation of the N-terminal intracellula...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P36898</td>\n",
       "      <td>14523231</td>\n",
       "      <td>Mutations in bone morphogenetic protein recept...</td>\n",
       "      <td>Brachydactyly (BD) type A2 is an autosomal dom...</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>Mutations in bone morphogenetic protein recept...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AC      PMID                                              Title  \\\n",
       "0  Q8NML3  17183211  RamA, the transcriptional regulator of acetate...   \n",
       "1  Q9SCZ4  17673660  The FERONIA receptor-like kinase mediates male...   \n",
       "2  Q81WX1  12721629  The genome sequence of Bacillus anthracis Ames...   \n",
       "3  P14410   8521865  Phosphorylation of the N-terminal intracellula...   \n",
       "4  P36898  14523231  Mutations in bone morphogenetic protein recept...   \n",
       "\n",
       "                                            Abstract                Terms  \\\n",
       "0  The RamA protein represents a LuxR-type transc...       autoregulation   \n",
       "1  In flowering plants, signaling between the mal...  autophosphorylation   \n",
       "2  Bacillus anthracis is an endospore-forming bac...                  NaN   \n",
       "3  This paper reports the phosphorylation of the ...                  NaN   \n",
       "4  Brachydactyly (BD) type A2 is an autosomal dom...  autophosphorylation   \n",
       "\n",
       "                                       Text_combined  batch_number  \n",
       "0  RamA, the transcriptional regulator of acetate...             1  \n",
       "1  The FERONIA receptor-like kinase mediates male...             1  \n",
       "2  The genome sequence of Bacillus anthracis Ames...             1  \n",
       "3  Phosphorylation of the N-terminal intracellula...             1  \n",
       "4  Mutations in bone morphogenetic protein recept...             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/processed/shuffled_10_data.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea4f48e",
   "metadata": {},
   "source": [
    "## 2. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c11d8441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/halao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# clean text\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = \" \".join([word.strip() for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['Text_Cleaned'] = df['Text_combined'].apply(clean_text)\n",
    "\n",
    "# Fill nan with 'non-autoregulatory'\n",
    "df['Terms'] = df['Terms'].fillna('non-autoregulatory')\n",
    "\n",
    "# Keep only selected columns\n",
    "columns_to_keep = ['batch_number','Text_Cleaned','Terms']\n",
    "df_cleaned = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac85503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53130, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_number</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rama transcriptional regulator acetate metabol...</td>\n",
       "      <td>autoregulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>feronia receptorlike kinase mediates malefemal...</td>\n",
       "      <td>autophosphorylation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>genome sequence bacillus anthracis ames compar...</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>phosphorylation nterminal intracellular tail s...</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mutations bone morphogenetic protein receptor ...</td>\n",
       "      <td>autophosphorylation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_number                                       Text_Cleaned  \\\n",
       "0             1  rama transcriptional regulator acetate metabol...   \n",
       "1             1  feronia receptorlike kinase mediates malefemal...   \n",
       "2             1  genome sequence bacillus anthracis ames compar...   \n",
       "3             1  phosphorylation nterminal intracellular tail s...   \n",
       "4             1  mutations bone morphogenetic protein receptor ...   \n",
       "\n",
       "                 Terms  \n",
       "0       autoregulation  \n",
       "1  autophosphorylation  \n",
       "2   non-autoregulatory  \n",
       "3   non-autoregulatory  \n",
       "4  autophosphorylation  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_cleaned.shape)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e3083",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e07168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/9tsj9gw15ll9ycvpvm3m3pq80000gn/T/ipykernel_53052/2408803356.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Terms_List'] = df_cleaned['Terms'].apply(\n",
      "/var/folders/n9/9tsj9gw15ll9ycvpvm3m3pq80000gn/T/ipykernel_53052/2408803356.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Terms_List'] = df_cleaned['Terms_List'].apply(lambda x: list(set(x)))\n"
     ]
    }
   ],
   "source": [
    "# Convert terms to list\n",
    "df_cleaned['Terms_List'] = df_cleaned['Terms'].apply(\n",
    "    lambda x: [term.strip() for term in x.split(',')]\n",
    ")\n",
    "df_cleaned['Terms_List'] = df_cleaned['Terms_List'].apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa499d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Binarize multi-labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(df_cleaned['Terms_List'])\n",
    "label_columns = mlb.classes_\n",
    "\n",
    "labels_df = pd.DataFrame(labels, columns=label_columns)\n",
    "existing_columns = [col for col in label_columns if col in df_cleaned.columns]\n",
    "df_cleaned = df_cleaned.drop(columns=existing_columns, errors='ignore')\n",
    "df_cleaned = pd.concat([df_cleaned, labels_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de3ced07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53130, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_number</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Terms</th>\n",
       "      <th>Terms_List</th>\n",
       "      <th>autoactivation</th>\n",
       "      <th>autocatalysis</th>\n",
       "      <th>autocatalytic</th>\n",
       "      <th>autofeedback</th>\n",
       "      <th>autoinducer</th>\n",
       "      <th>autoinduction</th>\n",
       "      <th>autoinhibition</th>\n",
       "      <th>autoinhibitory</th>\n",
       "      <th>autokinase</th>\n",
       "      <th>autolysis</th>\n",
       "      <th>autophosphorylation</th>\n",
       "      <th>autoregulation</th>\n",
       "      <th>autoregulatory</th>\n",
       "      <th>autoubiquitination</th>\n",
       "      <th>non-autoregulatory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rama transcriptional regulator acetate metabol...</td>\n",
       "      <td>autoregulation</td>\n",
       "      <td>[autoregulation]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>feronia receptorlike kinase mediates malefemal...</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>[autophosphorylation]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>genome sequence bacillus anthracis ames compar...</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>[non-autoregulatory]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>phosphorylation nterminal intracellular tail s...</td>\n",
       "      <td>non-autoregulatory</td>\n",
       "      <td>[non-autoregulatory]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mutations bone morphogenetic protein receptor ...</td>\n",
       "      <td>autophosphorylation</td>\n",
       "      <td>[autophosphorylation]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_number                                       Text_Cleaned  \\\n",
       "0             1  rama transcriptional regulator acetate metabol...   \n",
       "1             1  feronia receptorlike kinase mediates malefemal...   \n",
       "2             1  genome sequence bacillus anthracis ames compar...   \n",
       "3             1  phosphorylation nterminal intracellular tail s...   \n",
       "4             1  mutations bone morphogenetic protein receptor ...   \n",
       "\n",
       "                 Terms             Terms_List  autoactivation  autocatalysis  \\\n",
       "0       autoregulation       [autoregulation]               0              0   \n",
       "1  autophosphorylation  [autophosphorylation]               0              0   \n",
       "2   non-autoregulatory   [non-autoregulatory]               0              0   \n",
       "3   non-autoregulatory   [non-autoregulatory]               0              0   \n",
       "4  autophosphorylation  [autophosphorylation]               0              0   \n",
       "\n",
       "   autocatalytic  autofeedback  autoinducer  autoinduction  autoinhibition  \\\n",
       "0              0             0            0              0               0   \n",
       "1              0             0            0              0               0   \n",
       "2              0             0            0              0               0   \n",
       "3              0             0            0              0               0   \n",
       "4              0             0            0              0               0   \n",
       "\n",
       "   autoinhibitory  autokinase  autolysis  autophosphorylation  autoregulation  \\\n",
       "0               0           0          0                    0               1   \n",
       "1               0           0          0                    1               0   \n",
       "2               0           0          0                    0               0   \n",
       "3               0           0          0                    0               0   \n",
       "4               0           0          0                    1               0   \n",
       "\n",
       "   autoregulatory  autoubiquitination  non-autoregulatory  \n",
       "0               0                   0                   0  \n",
       "1               0                   0                   0  \n",
       "2               0                   0                   1  \n",
       "3               0                   0                   1  \n",
       "4               0                   0                   0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_cleaned.shape)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5a6b4",
   "metadata": {},
   "source": [
    "## 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6db7b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Instantiate the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "bert_model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80ebbd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train/Validation Split \n",
    "\n",
    "def split_single_batch_data(batch_number, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data from a single batch into train and test sets using stratified sampling.\n",
    "    Prints Train/Test sizes and Non-auto/Auto counts.\n",
    "    \"\"\"\n",
    "    batch_df = df_cleaned[df_cleaned['batch_number'] == batch_number].copy()\n",
    "    X = batch_df['Text_Cleaned']\n",
    "    y = labels_df.loc[batch_df.index].values  # Ensure indexing alignment\n",
    "    \n",
    "    # Calculate label distribution\n",
    "    non_auto_count = len(batch_df[batch_df['Terms'] == 'non-autoregulatory'])\n",
    "    auto_count = len(batch_df[batch_df['Terms'] != 'non-autoregulatory'])\n",
    "    \n",
    "    # Split data\n",
    "    msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    for train_idx, test_idx in msss.split(X, y):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        X_test = X.iloc[test_idx]\n",
    "        y_train = y[train_idx]\n",
    "        y_test = y[test_idx]\n",
    "    \n",
    "    print(f\"Batch {batch_number} | Train: {len(X_train)}, Test: {len(X_test)} | Non-auto: {non_auto_count}, Auto: {auto_count}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5507bd2",
   "metadata": {},
   "source": [
    "## 3. Split the data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee507758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "def get_data_and_weights(batch_number):\n",
    "    \"\"\"\n",
    "    Get data and calculate class weights for a specific batch.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = split_single_batch_data(batch_number)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    pos_weights = []\n",
    "    for i in range(y_train.shape[1]):\n",
    "        neg_count = len(y_train) - np.sum(y_train[:, i])\n",
    "        pos_count = np.sum(y_train[:, i])\n",
    "        pos_weights.append(neg_count / pos_count if pos_count > 0 else 1.0)\n",
    "    \n",
    "    pos_weights = torch.FloatTensor(pos_weights).to(device)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d8eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset class\n",
    "class BioBERTDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.FloatTensor(label)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05fd9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader\n",
    "def create_dataset_and_loader(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train_dataset = BioBERTDataset(X_train, y_train, tokenizer)\n",
    "    test_dataset = BioBERTDataset(X_test, y_test, tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e29c9d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "class BioBERTClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, dropout=0.1):\n",
    "        super(BioBERTClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "331fc11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train_epoch(model, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a479e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set thresholds for each label\n",
    "def set_thresholds(pos_weights):\n",
    "    \"\"\"\n",
    "    Set thresholds based on normalized pos_weights, scaled to [0.2, 0.8].\n",
    "    \"\"\"\n",
    "    thresholds = []\n",
    "\n",
    "    if len(pos_weights) != len(label_columns):\n",
    "        raise ValueError(f\"Length mismatch: pos_weights ({len(pos_weights)}) vs label_columns ({len(label_columns)})\")\n",
    "\n",
    "    # Calculate min and max weights for normalization\n",
    "    min_weight = pos_weights.min().item()\n",
    "    max_weight = pos_weights.max().item()\n",
    "    weight_range = max_weight - min_weight\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if weight_range == 0:\n",
    "        weight_range = 1\n",
    "\n",
    "    # Calculate thresholds\n",
    "    for weight in pos_weights:\n",
    "        # Normalize to [0, 1]\n",
    "        normalized_weight = (weight.item() - min_weight) / weight_range\n",
    "\n",
    "        # Map to [0.2, 0.8]\n",
    "        threshold = 0.8 - (0.6 * normalized_weight)\n",
    "\n",
    "        # Clamp to [0.2, 0.8]\n",
    "        threshold = max(0.2, min(threshold, 0.8))\n",
    "\n",
    "        thresholds.append(threshold)\n",
    "\n",
    "    # Print thresholds with two decimal places\n",
    "    formatted_thresholds = [f\"{t:.2f}\" for t in thresholds]\n",
    "    print(f\"\\nDynamic Thresholds: {formatted_thresholds}\")\n",
    "    \n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abee906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate(model, data_loader, criterion, thresholds):\n",
    "    \"\"\"\n",
    "    Evaluate the model with focused metrics output.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "            \n",
    "            # Apply thresholds per label\n",
    "            predictions = np.array([\n",
    "                (probabilities[:, i] >= thresholds[i]).astype(int) for i in range(len(thresholds))\n",
    "            ]).T\n",
    "\n",
    "            all_predictions.extend(predictions)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Samples metrics\n",
    "    samples_precision = precision_score(all_labels, all_predictions, average='samples', zero_division=0)\n",
    "    samples_recall = recall_score(all_labels, all_predictions, average='samples', zero_division=0)\n",
    "    samples_f1 = f1_score(all_labels, all_predictions, average='samples', zero_division=0)\n",
    "\n",
    "    # F1 metrics\n",
    "    micro_f1 = f1_score(all_labels, all_predictions, average='micro', zero_division=0)\n",
    "    macro_f1 = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "    weighted_f1 = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    # Average loss\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    metrics = {\n",
    "        'loss': avg_loss,\n",
    "        'micro_f1': micro_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'weighted_f1': weighted_f1,\n",
    "        'samples_f1': samples_f1,\n",
    "        'samples_precision': samples_precision,\n",
    "        'samples_recall': samples_recall\n",
    "    }\n",
    "    \n",
    "    # Output results\n",
    "    print(f\"Loss: {avg_loss:.4f} | Micro F1: {micro_f1:.4f} | Macro F1: {macro_f1:.4f} | Weighted F1: {weighted_f1:.4f} | Samples F1: {samples_f1:.4f}\")\n",
    "    print(f\"Samples Precision: {samples_precision:.4f} | Samples Recall: {samples_recall:.4f}\")\n",
    "    \n",
    "    # Return metrics for further analysis\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7418e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(batch_number, n_epochs, learning_rate, batch_size):\n",
    "    \"\"\"\n",
    "    Training loop for a single batch with dynamic threshold settings.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test, pos_weights = get_data_and_weights(batch_number)\n",
    "    print(f\"\\nProcessing Batch {batch_number} ...\")\n",
    "\n",
    "    # Calculate dynamic thresholds\n",
    "    thresholds = set_thresholds(pos_weights)\n",
    "    \n",
    "    train_loader, test_loader = create_dataset_and_loader(X_train, y_train, X_test, y_test, batch_size)\n",
    "\n",
    "    model = BioBERTClassifier(n_classes=y_train.shape[1]).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_samples_f1 = 0.0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs} | Batch {batch_number}\")\n",
    "\n",
    "        train_epoch(model, train_loader, optimizer, criterion)\n",
    "        metrics = evaluate(model, test_loader, criterion, thresholds)\n",
    "\n",
    "        current_samples_f1 = metrics['samples_f1']\n",
    "\n",
    "        # Save best model and thresholds\n",
    "        if current_samples_f1 > best_samples_f1:\n",
    "            best_samples_f1 = current_samples_f1\n",
    "            model_path = f\"../src/model/best_model_batch_{batch_number}.pt\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"  New best model saved to {model_path}\")\n",
    "\n",
    "            # Save thresholds\n",
    "            thresholds_path = f\"../src/model/best_thresholds_batch_{batch_number}.json\"\n",
    "            with open(thresholds_path, \"w\") as f:\n",
    "                json.dump(thresholds, f)\n",
    "            print(f\"  Thresholds saved to {thresholds_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63737d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 | Train: 4248, Test: 1065 | Non-auto: 3542, Auto: 1771\n",
      "\n",
      "Processing Batch 1 ...\n",
      "\n",
      "Dynamic Thresholds: ['0.60', '0.50', '0.78', '0.44', '0.74', '0.40', '0.77', '0.73', '0.20', '0.74', '0.80', '0.77', '0.75', '0.77', '0.80']\n",
      "Epoch 1/7 | Batch 1\n"
     ]
    }
   ],
   "source": [
    "# Run model for all batches\n",
    "n_epochs = 7\n",
    "learning_rate = 2e-5\n",
    "batch_size = 16\n",
    "\n",
    "for batch_num in range(1, 11):\n",
    "    train_model(batch_number=batch_num, n_epochs=n_epochs, learning_rate=learning_rate, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoregulatory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
